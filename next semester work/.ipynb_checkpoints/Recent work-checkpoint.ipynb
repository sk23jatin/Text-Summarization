{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.summarization.bm25 import get_bm25_weights\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords \n",
    "import sklearn\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min,jaccard_similarity_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosu, euclidean_distances\n",
    "from pylab import savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"a.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=f.name\n",
    "file_name=filename.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.\n",
      "A decision tree is a flowchart-like structure in which each internal node represents a “test” on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.\n",
      "Tree based learning algorithms are considered to be one of the best and mostly used supervised learning methods. Tree based methods empower predictive models with high accuracy, stability and ease of interpretation. Unlike linear models, they map non-linear relationships quite well. They are adaptable at solving any kind of problem at hand (classification or regression). Decision Tree algorithms are referred to as CART (Classification and Regression Trees).\n",
      "“The possible solutions to a given problem emerge as the leaves of a tree, each node representing a point of deliberation and decision.”\n",
      "- Niklaus Wirth (1934 — ), Programming language designer\n",
      "Methods like decision trees, random forest, gradient boosting are being popularly used in all kinds of data science problems. Common terms used with Decision trees:\n",
      "Root Node: It represents entire population or sample and this further gets divided into two or more homogeneous sets.\n",
      "Splitting: It is a process of dividing a node into two or more sub-nodes.\n",
      "Decision Node: When a sub-node splits into further sub-nodes, then it is called decision node.\n",
      "Leaf/ Terminal Node: Nodes do not split is called Leaf or Terminal node.\n",
      "Pruning: When we remove sub-nodes of a decision node, this process is called pruning. You can say opposite process of splitting.\n",
      "Branch / Sub-Tree: A sub section of entire tree is called branch or sub-tree.\n",
      "Parent and Child Node: A node, which is divided into sub-nodes is called parent node of sub-nodes whereas sub-nodes are the child of parent node.\n",
      "Applications for Decision Tree - Decision trees have a natural “if … then … else …” construction that makes it fit easily into a programmatic structure. They also are well suited to categorization problems where attributes or features are systematically checked to determine a final category. For example, a decision tree could be used effectively to determine the species of an animal.\n",
      "As a result, the decision making tree is one of the more popular classification algorithms being used in Data Mining and Machine Learning. Example applications include:\n",
      "· Evaluation of brand expansion opportunities for a business using historical sales data\n",
      "· Determination of likely buyers of a product using demographic data to enable targeting of limited advertisement budget\n",
      "· Prediction of likelihood of default for applicant borrowers using predictive models generated from historical data\n",
      "· Help with prioritization of emergency room patient treatment using a predictive model based on factors such as age, blood pressure, gender, location and severity of pain, and other measurements\n",
      "· Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal.\n",
      "Because of their simplicity, tree diagrams have been used in a broad range of industries and disciplines including civil planning, energy, financial, engineering, healthcare, pharmaceutical, education, law, and business.\n",
      "How does Decision Tree works ?\n",
      "Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input and output variables. In this technique, we split the population or sample into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables.\n",
      "Example:-\n",
      "Let’s say we have a sample of 30 students with three variables Gender (Boy/ Girl), Class (IX/ X) and Height (5 to 6 ft). 15 out of these 30 play cricket in leisure time. Now, we want to create a model to predict who will play cricket during leisure period? In this problem, we need to segregate students who play cricket in their leisure time based on highly significant input variable among all three.\n",
      "This is where decision tree helps, it will segregate the students based on all values of three variable and identify the variable, which creates the best homogeneous sets of students (which are heterogeneous to each other). In the snapshot below, you can see that variable Gender is able to identify best homogeneous sets compared to the other two variables.\n",
      "Decision tree identifies the most significant variable and its value that gives best homogeneous sets of population. To identify the variable and the split, decision tree uses various algorithms.\n",
      "Types of Decision Trees\n",
      "Types of decision tree is based on the type of target variable we have. It can be of two types:\n",
      "Categorical Variable Decision Tree: Decision Tree which has categorical target variable then it called as categorical variable decision tree. E.g.:- In above scenario of student problem, where the target variable was “Student will play cricket or not” i.e. YES or NO.\n",
      "Continuous Variable Decision Tree: Decision Tree has continuous target variable then it is called as Continuous Variable Decision Tree.\n",
      "E.g.:- Let’s say we have a problem to predict whether a customer will pay his renewal premium with an insurance company (yes/ no). Here we know that income of customer is a significant variable but insurance company does not have income details for all customers. Now, as we know this is an important variable, then we can build a decision tree to predict customer income based on occupation, product and various other variables. In this case, we are predicting values for continuous variable.\n",
      "The decision tree algorithm tries to solve the problem, by using tree representation. Each internal node of the tree corresponds to an attribute, and each leaf node corresponds to a class label.\n",
      "Place the best attribute of the dataset at the root of the tree.\n",
      "Split the training set into subsets. Subsets should be made in such a way that each subset contains data with the same value for an attribute.\n",
      "Repeat step 1 and step 2 on each subset until you find leaf nodes in all the branches of the tree.\n",
      "In decision trees, for predicting a class label for a record we start from the root of the tree. We compare the values of the root attribute with record’s attribute. On the basis of comparison, we follow the branch corresponding to that value and jump to the next node.\n",
      "We continue comparing our record’s attribute values with other internal nodes of the tree until we reach a leaf node with predicted class value. The modeled decision tree can be used to predict the target class or the value.\n",
      "Assumptions while creating Decision Tree\n",
      "Some of the assumptions we make while using Decision tree:\n",
      "At the beginning, the whole training set is considered as the root.\n",
      "Feature values are preferred to be categorical. If the values are continuous then they are discretized prior to building the model.\n",
      "Records are distributed recursively on the basis of attribute values.\n",
      "Order to placing attributes as root or internal node of the tree is done by using some statistical approach.\n",
      "Advantages of Decision Tree:\n",
      "Easy to Understand: Decision tree output is very easy to understand even for people from non-analytical background. It does not require any statistical knowledge to read and interpret them. Its graphical representation is very intuitive and users can easily relate their hypothesis.\n",
      "Useful in Data exploration: Decision tree is one of the fastest way to identify most significant variables and relation between two or more variables. With the help of decision trees, we can create new variables / features that has better power to predict target variable. It can also be used in data exploration stage. For e.g., we are working on a problem where we have information available in hundreds of variables, there decision tree will help to identify most significant variable.\n",
      "Decision trees implicitly perform variable screening or feature selection.\n",
      "Decision trees require relatively little effort from users for data preparation.\n",
      "Less data cleaning required: It requires less data cleaning compared to some other modeling techniques. It is not influenced by outliers and missing values to a fair degree.\n",
      "Data type is not a constraint: It can handle both numerical and categorical variables. Can also handle multi-output problems.\n",
      "Non-Parametric Method: Decision tree is considered to be a non-parametric method. This means that decision trees have no assumptions about the space distribution and the classifier structure.\n",
      "Non-linear relationships between parameters do not affect tree performance.\n",
      "The number of hyper-parameters to be tuned is almost null.\n",
      "Disadvantages of Decision Tree:\n",
      "Over fitting: Decision-tree learners can create over-complex trees that do not generalize the data well. This is called overfitting. Over fitting is one of the most practical difficulty for decision tree models. This problem gets solved by setting constraints on model parameters and pruning.\n",
      "Not fit for continuous variables: While working with continuous numerical variables, decision tree loses information, when it categorizes variables in different categories.\n",
      "Decision trees can be unstable because small variations in the data might result in a completely different tree being generated. This is called variance, which needs to be lowered by methods like bagging and boosting.\n",
      "Greedy algorithms cannot guarantee to return the globally optimal decision tree. This can be mitigated by training multiple trees, where the features and samples are randomly sampled with replacement.\n",
      "Decision tree learners create biased trees if some classes dominate. It is therefore recommended to balance the data set prior to fitting with the decision tree.\n",
      "Information gain in a decision tree with categorical variables gives a biased response for attributes with greater no. of categories.\n",
      "Generally, it gives low prediction accuracy for a dataset as compared to other machine learning algorithms.\n",
      "Calculations can become complex when there are many class label.\n",
      "Regression Trees vs Classification Trees\n",
      "The terminal nodes (or leaves) lies at the bottom of the decision tree. This means that decision trees are typically drawn upside down such that leaves are the bottom & roots are the tops.\n",
      "Both the trees work almost similar to each other. The primary differences and similarities between Classification and Regression Trees are:\n",
      "Regression trees are used when dependent variable is continuous. Classification Trees are used when dependent variable is categorical.\n",
      "In case of Regression Tree, the value obtained by terminal nodes in the training data is the mean response of observation falling in that region. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mean value.\n",
      "In case of Classification Tree, the value (class) obtained by terminal node in the training data is the mode of observations falling in that region. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mode value.\n",
      "Both the trees divide the predictor space (independent variables) into distinct and non-overlapping regions.\n",
      "Both the trees follow a top-down greedy approach known as recursive binary splitting. We call it as ‘top-down’ because it begins from the top of tree when all the observations are available in a single region and successively splits the predictor space into two new branches down the tree. It is known as ‘greedy’ because, the algorithm cares (looks for best variable available) about only the current split, and not about future splits which will lead to a better tree.\n",
      "This splitting process is continued until a user defined stopping criteria is reached. For e.g.: we can tell the algorithm to stop once the number of observations per node becomes less than 50.\n",
      "In both the cases, the splitting process results in fully grown trees until the stopping criteria is reached. But, the fully grown tree is likely to over fit data, leading to poor accuracy on unseen data. This bring ‘pruning’. Pruning is one of the technique used tackle overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=(f.read())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "for s in data:\n",
    "    sentences.append(sent_tokenize(s))\n",
    "sentences = [[y] for x in sentences for y in x] # flatten list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'a',\n",
       "  'decision',\n",
       "  'support',\n",
       "  'tool',\n",
       "  'that',\n",
       "  'uses',\n",
       "  'a',\n",
       "  'tree-like',\n",
       "  'graph',\n",
       "  'or',\n",
       "  'model',\n",
       "  'of',\n",
       "  'decisions',\n",
       "  'and',\n",
       "  'their',\n",
       "  'possible',\n",
       "  'consequences',\n",
       "  ',',\n",
       "  'including',\n",
       "  'chance',\n",
       "  'event',\n",
       "  'outcomes',\n",
       "  ',',\n",
       "  'resource',\n",
       "  'costs',\n",
       "  ',',\n",
       "  'and',\n",
       "  'utility',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'is',\n",
       "  'one',\n",
       "  'way',\n",
       "  'to',\n",
       "  'display',\n",
       "  'an',\n",
       "  'algorithm',\n",
       "  'that',\n",
       "  'only',\n",
       "  'contains',\n",
       "  'conditional',\n",
       "  'control',\n",
       "  'statements',\n",
       "  '.'],\n",
       " ['A',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'a',\n",
       "  'flowchart-like',\n",
       "  'structure',\n",
       "  'in',\n",
       "  'which',\n",
       "  'each',\n",
       "  'internal',\n",
       "  'node',\n",
       "  'represents',\n",
       "  'a',\n",
       "  '“',\n",
       "  'test',\n",
       "  '”',\n",
       "  'on',\n",
       "  'an',\n",
       "  'attribute',\n",
       "  '(',\n",
       "  'e.g',\n",
       "  '.'],\n",
       " ['whether',\n",
       "  'a',\n",
       "  'coin',\n",
       "  'flip',\n",
       "  'comes',\n",
       "  'up',\n",
       "  'heads',\n",
       "  'or',\n",
       "  'tails',\n",
       "  ')',\n",
       "  ',',\n",
       "  'each',\n",
       "  'branch',\n",
       "  'represents',\n",
       "  'the',\n",
       "  'outcome',\n",
       "  'of',\n",
       "  'the',\n",
       "  'test',\n",
       "  ',',\n",
       "  'and',\n",
       "  'each',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'represents',\n",
       "  'a',\n",
       "  'class',\n",
       "  'label',\n",
       "  '(',\n",
       "  'decision',\n",
       "  'taken',\n",
       "  'after',\n",
       "  'computing',\n",
       "  'all',\n",
       "  'attributes',\n",
       "  ')',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'paths',\n",
       "  'from',\n",
       "  'root',\n",
       "  'to',\n",
       "  'leaf',\n",
       "  'represent',\n",
       "  'classification',\n",
       "  'rules',\n",
       "  '.'],\n",
       " ['Tree',\n",
       "  'based',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'are',\n",
       "  'considered',\n",
       "  'to',\n",
       "  'be',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'best',\n",
       "  'and',\n",
       "  'mostly',\n",
       "  'used',\n",
       "  'supervised',\n",
       "  'learning',\n",
       "  'methods',\n",
       "  '.'],\n",
       " ['Tree',\n",
       "  'based',\n",
       "  'methods',\n",
       "  'empower',\n",
       "  'predictive',\n",
       "  'models',\n",
       "  'with',\n",
       "  'high',\n",
       "  'accuracy',\n",
       "  ',',\n",
       "  'stability',\n",
       "  'and',\n",
       "  'ease',\n",
       "  'of',\n",
       "  'interpretation',\n",
       "  '.'],\n",
       " ['Unlike',\n",
       "  'linear',\n",
       "  'models',\n",
       "  ',',\n",
       "  'they',\n",
       "  'map',\n",
       "  'non-linear',\n",
       "  'relationships',\n",
       "  'quite',\n",
       "  'well',\n",
       "  '.'],\n",
       " ['They',\n",
       "  'are',\n",
       "  'adaptable',\n",
       "  'at',\n",
       "  'solving',\n",
       "  'any',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'problem',\n",
       "  'at',\n",
       "  'hand',\n",
       "  '(',\n",
       "  'classification',\n",
       "  'or',\n",
       "  'regression',\n",
       "  ')',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'Tree',\n",
       "  'algorithms',\n",
       "  'are',\n",
       "  'referred',\n",
       "  'to',\n",
       "  'as',\n",
       "  'CART',\n",
       "  '(',\n",
       "  'Classification',\n",
       "  'and',\n",
       "  'Regression',\n",
       "  'Trees',\n",
       "  ')',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'The',\n",
       "  'possible',\n",
       "  'solutions',\n",
       "  'to',\n",
       "  'a',\n",
       "  'given',\n",
       "  'problem',\n",
       "  'emerge',\n",
       "  'as',\n",
       "  'the',\n",
       "  'leaves',\n",
       "  'of',\n",
       "  'a',\n",
       "  'tree',\n",
       "  ',',\n",
       "  'each',\n",
       "  'node',\n",
       "  'representing',\n",
       "  'a',\n",
       "  'point',\n",
       "  'of',\n",
       "  'deliberation',\n",
       "  'and',\n",
       "  'decision.',\n",
       "  '”',\n",
       "  '-',\n",
       "  'Niklaus',\n",
       "  'Wirth',\n",
       "  '(',\n",
       "  '1934',\n",
       "  '—',\n",
       "  ')',\n",
       "  ',',\n",
       "  'Programming',\n",
       "  'language',\n",
       "  'designer',\n",
       "  'Methods',\n",
       "  'like',\n",
       "  'decision',\n",
       "  'trees',\n",
       "  ',',\n",
       "  'random',\n",
       "  'forest',\n",
       "  ',',\n",
       "  'gradient',\n",
       "  'boosting',\n",
       "  'are',\n",
       "  'being',\n",
       "  'popularly',\n",
       "  'used',\n",
       "  'in',\n",
       "  'all',\n",
       "  'kinds',\n",
       "  'of',\n",
       "  'data',\n",
       "  'science',\n",
       "  'problems',\n",
       "  '.'],\n",
       " ['Common',\n",
       "  'terms',\n",
       "  'used',\n",
       "  'with',\n",
       "  'Decision',\n",
       "  'trees',\n",
       "  ':',\n",
       "  'Root',\n",
       "  'Node',\n",
       "  ':',\n",
       "  'It',\n",
       "  'represents',\n",
       "  'entire',\n",
       "  'population',\n",
       "  'or',\n",
       "  'sample',\n",
       "  'and',\n",
       "  'this',\n",
       "  'further',\n",
       "  'gets',\n",
       "  'divided',\n",
       "  'into',\n",
       "  'two',\n",
       "  'or',\n",
       "  'more',\n",
       "  'homogeneous',\n",
       "  'sets',\n",
       "  '.'],\n",
       " ['Splitting',\n",
       "  ':',\n",
       "  'It',\n",
       "  'is',\n",
       "  'a',\n",
       "  'process',\n",
       "  'of',\n",
       "  'dividing',\n",
       "  'a',\n",
       "  'node',\n",
       "  'into',\n",
       "  'two',\n",
       "  'or',\n",
       "  'more',\n",
       "  'sub-nodes',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'Node',\n",
       "  ':',\n",
       "  'When',\n",
       "  'a',\n",
       "  'sub-node',\n",
       "  'splits',\n",
       "  'into',\n",
       "  'further',\n",
       "  'sub-nodes',\n",
       "  ',',\n",
       "  'then',\n",
       "  'it',\n",
       "  'is',\n",
       "  'called',\n",
       "  'decision',\n",
       "  'node',\n",
       "  '.'],\n",
       " ['Leaf/',\n",
       "  'Terminal',\n",
       "  'Node',\n",
       "  ':',\n",
       "  'Nodes',\n",
       "  'do',\n",
       "  'not',\n",
       "  'split',\n",
       "  'is',\n",
       "  'called',\n",
       "  'Leaf',\n",
       "  'or',\n",
       "  'Terminal',\n",
       "  'node',\n",
       "  '.'],\n",
       " ['Pruning',\n",
       "  ':',\n",
       "  'When',\n",
       "  'we',\n",
       "  'remove',\n",
       "  'sub-nodes',\n",
       "  'of',\n",
       "  'a',\n",
       "  'decision',\n",
       "  'node',\n",
       "  ',',\n",
       "  'this',\n",
       "  'process',\n",
       "  'is',\n",
       "  'called',\n",
       "  'pruning',\n",
       "  '.'],\n",
       " ['You', 'can', 'say', 'opposite', 'process', 'of', 'splitting', '.'],\n",
       " ['Branch',\n",
       "  '/',\n",
       "  'Sub-Tree',\n",
       "  ':',\n",
       "  'A',\n",
       "  'sub',\n",
       "  'section',\n",
       "  'of',\n",
       "  'entire',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'called',\n",
       "  'branch',\n",
       "  'or',\n",
       "  'sub-tree',\n",
       "  '.'],\n",
       " ['Parent',\n",
       "  'and',\n",
       "  'Child',\n",
       "  'Node',\n",
       "  ':',\n",
       "  'A',\n",
       "  'node',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'divided',\n",
       "  'into',\n",
       "  'sub-nodes',\n",
       "  'is',\n",
       "  'called',\n",
       "  'parent',\n",
       "  'node',\n",
       "  'of',\n",
       "  'sub-nodes',\n",
       "  'whereas',\n",
       "  'sub-nodes',\n",
       "  'are',\n",
       "  'the',\n",
       "  'child',\n",
       "  'of',\n",
       "  'parent',\n",
       "  'node',\n",
       "  '.'],\n",
       " ['Applications',\n",
       "  'for',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  '-',\n",
       "  'Decision',\n",
       "  'trees',\n",
       "  'have',\n",
       "  'a',\n",
       "  'natural',\n",
       "  '“',\n",
       "  'if',\n",
       "  '…',\n",
       "  'then',\n",
       "  '…',\n",
       "  'else',\n",
       "  '…',\n",
       "  '”',\n",
       "  'construction',\n",
       "  'that',\n",
       "  'makes',\n",
       "  'it',\n",
       "  'fit',\n",
       "  'easily',\n",
       "  'into',\n",
       "  'a',\n",
       "  'programmatic',\n",
       "  'structure',\n",
       "  '.'],\n",
       " ['They',\n",
       "  'also',\n",
       "  'are',\n",
       "  'well',\n",
       "  'suited',\n",
       "  'to',\n",
       "  'categorization',\n",
       "  'problems',\n",
       "  'where',\n",
       "  'attributes',\n",
       "  'or',\n",
       "  'features',\n",
       "  'are',\n",
       "  'systematically',\n",
       "  'checked',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'a',\n",
       "  'final',\n",
       "  'category',\n",
       "  '.'],\n",
       " ['For',\n",
       "  'example',\n",
       "  ',',\n",
       "  'a',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'could',\n",
       "  'be',\n",
       "  'used',\n",
       "  'effectively',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'the',\n",
       "  'species',\n",
       "  'of',\n",
       "  'an',\n",
       "  'animal',\n",
       "  '.'],\n",
       " ['As',\n",
       "  'a',\n",
       "  'result',\n",
       "  ',',\n",
       "  'the',\n",
       "  'decision',\n",
       "  'making',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'more',\n",
       "  'popular',\n",
       "  'classification',\n",
       "  'algorithms',\n",
       "  'being',\n",
       "  'used',\n",
       "  'in',\n",
       "  'Data',\n",
       "  'Mining',\n",
       "  'and',\n",
       "  'Machine',\n",
       "  'Learning',\n",
       "  '.'],\n",
       " ['Example',\n",
       "  'applications',\n",
       "  'include',\n",
       "  ':',\n",
       "  '·',\n",
       "  'Evaluation',\n",
       "  'of',\n",
       "  'brand',\n",
       "  'expansion',\n",
       "  'opportunities',\n",
       "  'for',\n",
       "  'a',\n",
       "  'business',\n",
       "  'using',\n",
       "  'historical',\n",
       "  'sales',\n",
       "  'data',\n",
       "  '·',\n",
       "  'Determination',\n",
       "  'of',\n",
       "  'likely',\n",
       "  'buyers',\n",
       "  'of',\n",
       "  'a',\n",
       "  'product',\n",
       "  'using',\n",
       "  'demographic',\n",
       "  'data',\n",
       "  'to',\n",
       "  'enable',\n",
       "  'targeting',\n",
       "  'of',\n",
       "  'limited',\n",
       "  'advertisement',\n",
       "  'budget',\n",
       "  '·',\n",
       "  'Prediction',\n",
       "  'of',\n",
       "  'likelihood',\n",
       "  'of',\n",
       "  'default',\n",
       "  'for',\n",
       "  'applicant',\n",
       "  'borrowers',\n",
       "  'using',\n",
       "  'predictive',\n",
       "  'models',\n",
       "  'generated',\n",
       "  'from',\n",
       "  'historical',\n",
       "  'data',\n",
       "  '·',\n",
       "  'Help',\n",
       "  'with',\n",
       "  'prioritization',\n",
       "  'of',\n",
       "  'emergency',\n",
       "  'room',\n",
       "  'patient',\n",
       "  'treatment',\n",
       "  'using',\n",
       "  'a',\n",
       "  'predictive',\n",
       "  'model',\n",
       "  'based',\n",
       "  'on',\n",
       "  'factors',\n",
       "  'such',\n",
       "  'as',\n",
       "  'age',\n",
       "  ',',\n",
       "  'blood',\n",
       "  'pressure',\n",
       "  ',',\n",
       "  'gender',\n",
       "  ',',\n",
       "  'location',\n",
       "  'and',\n",
       "  'severity',\n",
       "  'of',\n",
       "  'pain',\n",
       "  ',',\n",
       "  'and',\n",
       "  'other',\n",
       "  'measurements',\n",
       "  '·',\n",
       "  'Decision',\n",
       "  'trees',\n",
       "  'are',\n",
       "  'commonly',\n",
       "  'used',\n",
       "  'in',\n",
       "  'operations',\n",
       "  'research',\n",
       "  ',',\n",
       "  'specifically',\n",
       "  'in',\n",
       "  'decision',\n",
       "  'analysis',\n",
       "  ',',\n",
       "  'to',\n",
       "  'help',\n",
       "  'identify',\n",
       "  'a',\n",
       "  'strategy',\n",
       "  'most',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'a',\n",
       "  'goal',\n",
       "  '.'],\n",
       " ['Because',\n",
       "  'of',\n",
       "  'their',\n",
       "  'simplicity',\n",
       "  ',',\n",
       "  'tree',\n",
       "  'diagrams',\n",
       "  'have',\n",
       "  'been',\n",
       "  'used',\n",
       "  'in',\n",
       "  'a',\n",
       "  'broad',\n",
       "  'range',\n",
       "  'of',\n",
       "  'industries',\n",
       "  'and',\n",
       "  'disciplines',\n",
       "  'including',\n",
       "  'civil',\n",
       "  'planning',\n",
       "  ',',\n",
       "  'energy',\n",
       "  ',',\n",
       "  'financial',\n",
       "  ',',\n",
       "  'engineering',\n",
       "  ',',\n",
       "  'healthcare',\n",
       "  ',',\n",
       "  'pharmaceutical',\n",
       "  ',',\n",
       "  'education',\n",
       "  ',',\n",
       "  'law',\n",
       "  ',',\n",
       "  'and',\n",
       "  'business',\n",
       "  '.'],\n",
       " ['How', 'does', 'Decision', 'Tree', 'works', '?'],\n",
       " ['Decision',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'a',\n",
       "  'type',\n",
       "  'of',\n",
       "  'supervised',\n",
       "  'learning',\n",
       "  'algorithm',\n",
       "  '(',\n",
       "  'having',\n",
       "  'a',\n",
       "  'pre-defined',\n",
       "  'target',\n",
       "  'variable',\n",
       "  ')',\n",
       "  'that',\n",
       "  'is',\n",
       "  'mostly',\n",
       "  'used',\n",
       "  'in',\n",
       "  'classification',\n",
       "  'problems',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'works',\n",
       "  'for',\n",
       "  'both',\n",
       "  'categorical',\n",
       "  'and',\n",
       "  'continuous',\n",
       "  'input',\n",
       "  'and',\n",
       "  'output',\n",
       "  'variables',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'this',\n",
       "  'technique',\n",
       "  ',',\n",
       "  'we',\n",
       "  'split',\n",
       "  'the',\n",
       "  'population',\n",
       "  'or',\n",
       "  'sample',\n",
       "  'into',\n",
       "  'two',\n",
       "  'or',\n",
       "  'more',\n",
       "  'homogeneous',\n",
       "  'sets',\n",
       "  '(',\n",
       "  'or',\n",
       "  'sub-populations',\n",
       "  ')',\n",
       "  'based',\n",
       "  'on',\n",
       "  'most',\n",
       "  'significant',\n",
       "  'splitter',\n",
       "  '/',\n",
       "  'differentiator',\n",
       "  'in',\n",
       "  'input',\n",
       "  'variables',\n",
       "  '.'],\n",
       " ['Example',\n",
       "  ':',\n",
       "  '-',\n",
       "  'Let',\n",
       "  '’',\n",
       "  's',\n",
       "  'say',\n",
       "  'we',\n",
       "  'have',\n",
       "  'a',\n",
       "  'sample',\n",
       "  'of',\n",
       "  '30',\n",
       "  'students',\n",
       "  'with',\n",
       "  'three',\n",
       "  'variables',\n",
       "  'Gender',\n",
       "  '(',\n",
       "  'Boy/',\n",
       "  'Girl',\n",
       "  ')',\n",
       "  ',',\n",
       "  'Class',\n",
       "  '(',\n",
       "  'IX/',\n",
       "  'X',\n",
       "  ')',\n",
       "  'and',\n",
       "  'Height',\n",
       "  '(',\n",
       "  '5',\n",
       "  'to',\n",
       "  '6',\n",
       "  'ft',\n",
       "  ')',\n",
       "  '.'],\n",
       " ['15',\n",
       "  'out',\n",
       "  'of',\n",
       "  'these',\n",
       "  '30',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'in',\n",
       "  'leisure',\n",
       "  'time',\n",
       "  '.'],\n",
       " ['Now',\n",
       "  ',',\n",
       "  'we',\n",
       "  'want',\n",
       "  'to',\n",
       "  'create',\n",
       "  'a',\n",
       "  'model',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'who',\n",
       "  'will',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'during',\n",
       "  'leisure',\n",
       "  'period',\n",
       "  '?'],\n",
       " ['In',\n",
       "  'this',\n",
       "  'problem',\n",
       "  ',',\n",
       "  'we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'segregate',\n",
       "  'students',\n",
       "  'who',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'in',\n",
       "  'their',\n",
       "  'leisure',\n",
       "  'time',\n",
       "  'based',\n",
       "  'on',\n",
       "  'highly',\n",
       "  'significant',\n",
       "  'input',\n",
       "  'variable',\n",
       "  'among',\n",
       "  'all',\n",
       "  'three',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'is',\n",
       "  'where',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'helps',\n",
       "  ',',\n",
       "  'it',\n",
       "  'will',\n",
       "  'segregate',\n",
       "  'the',\n",
       "  'students',\n",
       "  'based',\n",
       "  'on',\n",
       "  'all',\n",
       "  'values',\n",
       "  'of',\n",
       "  'three',\n",
       "  'variable',\n",
       "  'and',\n",
       "  'identify',\n",
       "  'the',\n",
       "  'variable',\n",
       "  ',',\n",
       "  'which',\n",
       "  'creates',\n",
       "  'the',\n",
       "  'best',\n",
       "  'homogeneous',\n",
       "  'sets',\n",
       "  'of',\n",
       "  'students',\n",
       "  '(',\n",
       "  'which',\n",
       "  'are',\n",
       "  'heterogeneous',\n",
       "  'to',\n",
       "  'each',\n",
       "  'other',\n",
       "  ')',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'the',\n",
       "  'snapshot',\n",
       "  'below',\n",
       "  ',',\n",
       "  'you',\n",
       "  'can',\n",
       "  'see',\n",
       "  'that',\n",
       "  'variable',\n",
       "  'Gender',\n",
       "  'is',\n",
       "  'able',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'best',\n",
       "  'homogeneous',\n",
       "  'sets',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'the',\n",
       "  'other',\n",
       "  'two',\n",
       "  'variables',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'tree',\n",
       "  'identifies',\n",
       "  'the',\n",
       "  'most',\n",
       "  'significant',\n",
       "  'variable',\n",
       "  'and',\n",
       "  'its',\n",
       "  'value',\n",
       "  'that',\n",
       "  'gives',\n",
       "  'best',\n",
       "  'homogeneous',\n",
       "  'sets',\n",
       "  'of',\n",
       "  'population',\n",
       "  '.'],\n",
       " ['To',\n",
       "  'identify',\n",
       "  'the',\n",
       "  'variable',\n",
       "  'and',\n",
       "  'the',\n",
       "  'split',\n",
       "  ',',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'uses',\n",
       "  'various',\n",
       "  'algorithms',\n",
       "  '.'],\n",
       " ['Types',\n",
       "  'of',\n",
       "  'Decision',\n",
       "  'Trees',\n",
       "  'Types',\n",
       "  'of',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'type',\n",
       "  'of',\n",
       "  'target',\n",
       "  'variable',\n",
       "  'we',\n",
       "  'have',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'can',\n",
       "  'be',\n",
       "  'of',\n",
       "  'two',\n",
       "  'types',\n",
       "  ':',\n",
       "  'Categorical',\n",
       "  'Variable',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  ':',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  'which',\n",
       "  'has',\n",
       "  'categorical',\n",
       "  'target',\n",
       "  'variable',\n",
       "  'then',\n",
       "  'it',\n",
       "  'called',\n",
       "  'as',\n",
       "  'categorical',\n",
       "  'variable',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['E.g', '.'],\n",
       " [':',\n",
       "  '-',\n",
       "  'In',\n",
       "  'above',\n",
       "  'scenario',\n",
       "  'of',\n",
       "  'student',\n",
       "  'problem',\n",
       "  ',',\n",
       "  'where',\n",
       "  'the',\n",
       "  'target',\n",
       "  'variable',\n",
       "  'was',\n",
       "  '“',\n",
       "  'Student',\n",
       "  'will',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'or',\n",
       "  'not',\n",
       "  '”',\n",
       "  'i.e',\n",
       "  '.'],\n",
       " ['YES', 'or', 'NO', '.'],\n",
       " ['Continuous',\n",
       "  'Variable',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  ':',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  'has',\n",
       "  'continuous',\n",
       "  'target',\n",
       "  'variable',\n",
       "  'then',\n",
       "  'it',\n",
       "  'is',\n",
       "  'called',\n",
       "  'as',\n",
       "  'Continuous',\n",
       "  'Variable',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  '.'],\n",
       " ['E.g', '.'],\n",
       " [':',\n",
       "  '-',\n",
       "  'Let',\n",
       "  '’',\n",
       "  's',\n",
       "  'say',\n",
       "  'we',\n",
       "  'have',\n",
       "  'a',\n",
       "  'problem',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'whether',\n",
       "  'a',\n",
       "  'customer',\n",
       "  'will',\n",
       "  'pay',\n",
       "  'his',\n",
       "  'renewal',\n",
       "  'premium',\n",
       "  'with',\n",
       "  'an',\n",
       "  'insurance',\n",
       "  'company',\n",
       "  '(',\n",
       "  'yes/',\n",
       "  'no',\n",
       "  ')',\n",
       "  '.'],\n",
       " ['Here',\n",
       "  'we',\n",
       "  'know',\n",
       "  'that',\n",
       "  'income',\n",
       "  'of',\n",
       "  'customer',\n",
       "  'is',\n",
       "  'a',\n",
       "  'significant',\n",
       "  'variable',\n",
       "  'but',\n",
       "  'insurance',\n",
       "  'company',\n",
       "  'does',\n",
       "  'not',\n",
       "  'have',\n",
       "  'income',\n",
       "  'details',\n",
       "  'for',\n",
       "  'all',\n",
       "  'customers',\n",
       "  '.'],\n",
       " ['Now',\n",
       "  ',',\n",
       "  'as',\n",
       "  'we',\n",
       "  'know',\n",
       "  'this',\n",
       "  'is',\n",
       "  'an',\n",
       "  'important',\n",
       "  'variable',\n",
       "  ',',\n",
       "  'then',\n",
       "  'we',\n",
       "  'can',\n",
       "  'build',\n",
       "  'a',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'customer',\n",
       "  'income',\n",
       "  'based',\n",
       "  'on',\n",
       "  'occupation',\n",
       "  ',',\n",
       "  'product',\n",
       "  'and',\n",
       "  'various',\n",
       "  'other',\n",
       "  'variables',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'this',\n",
       "  'case',\n",
       "  ',',\n",
       "  'we',\n",
       "  'are',\n",
       "  'predicting',\n",
       "  'values',\n",
       "  'for',\n",
       "  'continuous',\n",
       "  'variable',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'algorithm',\n",
       "  'tries',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'the',\n",
       "  'problem',\n",
       "  ',',\n",
       "  'by',\n",
       "  'using',\n",
       "  'tree',\n",
       "  'representation',\n",
       "  '.'],\n",
       " ['Each',\n",
       "  'internal',\n",
       "  'node',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'corresponds',\n",
       "  'to',\n",
       "  'an',\n",
       "  'attribute',\n",
       "  ',',\n",
       "  'and',\n",
       "  'each',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'corresponds',\n",
       "  'to',\n",
       "  'a',\n",
       "  'class',\n",
       "  'label',\n",
       "  '.'],\n",
       " ['Place',\n",
       "  'the',\n",
       "  'best',\n",
       "  'attribute',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dataset',\n",
       "  'at',\n",
       "  'the',\n",
       "  'root',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['Split', 'the', 'training', 'set', 'into', 'subsets', '.'],\n",
       " ['Subsets',\n",
       "  'should',\n",
       "  'be',\n",
       "  'made',\n",
       "  'in',\n",
       "  'such',\n",
       "  'a',\n",
       "  'way',\n",
       "  'that',\n",
       "  'each',\n",
       "  'subset',\n",
       "  'contains',\n",
       "  'data',\n",
       "  'with',\n",
       "  'the',\n",
       "  'same',\n",
       "  'value',\n",
       "  'for',\n",
       "  'an',\n",
       "  'attribute',\n",
       "  '.'],\n",
       " ['Repeat',\n",
       "  'step',\n",
       "  '1',\n",
       "  'and',\n",
       "  'step',\n",
       "  '2',\n",
       "  'on',\n",
       "  'each',\n",
       "  'subset',\n",
       "  'until',\n",
       "  'you',\n",
       "  'find',\n",
       "  'leaf',\n",
       "  'nodes',\n",
       "  'in',\n",
       "  'all',\n",
       "  'the',\n",
       "  'branches',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'decision',\n",
       "  'trees',\n",
       "  ',',\n",
       "  'for',\n",
       "  'predicting',\n",
       "  'a',\n",
       "  'class',\n",
       "  'label',\n",
       "  'for',\n",
       "  'a',\n",
       "  'record',\n",
       "  'we',\n",
       "  'start',\n",
       "  'from',\n",
       "  'the',\n",
       "  'root',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['We',\n",
       "  'compare',\n",
       "  'the',\n",
       "  'values',\n",
       "  'of',\n",
       "  'the',\n",
       "  'root',\n",
       "  'attribute',\n",
       "  'with',\n",
       "  'record',\n",
       "  '’',\n",
       "  's',\n",
       "  'attribute',\n",
       "  '.'],\n",
       " ['On',\n",
       "  'the',\n",
       "  'basis',\n",
       "  'of',\n",
       "  'comparison',\n",
       "  ',',\n",
       "  'we',\n",
       "  'follow',\n",
       "  'the',\n",
       "  'branch',\n",
       "  'corresponding',\n",
       "  'to',\n",
       "  'that',\n",
       "  'value',\n",
       "  'and',\n",
       "  'jump',\n",
       "  'to',\n",
       "  'the',\n",
       "  'next',\n",
       "  'node',\n",
       "  '.'],\n",
       " ['We',\n",
       "  'continue',\n",
       "  'comparing',\n",
       "  'our',\n",
       "  'record',\n",
       "  '’',\n",
       "  's',\n",
       "  'attribute',\n",
       "  'values',\n",
       "  'with',\n",
       "  'other',\n",
       "  'internal',\n",
       "  'nodes',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'until',\n",
       "  'we',\n",
       "  'reach',\n",
       "  'a',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'with',\n",
       "  'predicted',\n",
       "  'class',\n",
       "  'value',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'modeled',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'can',\n",
       "  'be',\n",
       "  'used',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'the',\n",
       "  'target',\n",
       "  'class',\n",
       "  'or',\n",
       "  'the',\n",
       "  'value',\n",
       "  '.'],\n",
       " ['Assumptions',\n",
       "  'while',\n",
       "  'creating',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  'Some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'assumptions',\n",
       "  'we',\n",
       "  'make',\n",
       "  'while',\n",
       "  'using',\n",
       "  'Decision',\n",
       "  'tree',\n",
       "  ':',\n",
       "  'At',\n",
       "  'the',\n",
       "  'beginning',\n",
       "  ',',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'training',\n",
       "  'set',\n",
       "  'is',\n",
       "  'considered',\n",
       "  'as',\n",
       "  'the',\n",
       "  'root',\n",
       "  '.'],\n",
       " ['Feature', 'values', 'are', 'preferred', 'to', 'be', 'categorical', '.'],\n",
       " ['If',\n",
       "  'the',\n",
       "  'values',\n",
       "  'are',\n",
       "  'continuous',\n",
       "  'then',\n",
       "  'they',\n",
       "  'are',\n",
       "  'discretized',\n",
       "  'prior',\n",
       "  'to',\n",
       "  'building',\n",
       "  'the',\n",
       "  'model',\n",
       "  '.'],\n",
       " ['Records',\n",
       "  'are',\n",
       "  'distributed',\n",
       "  'recursively',\n",
       "  'on',\n",
       "  'the',\n",
       "  'basis',\n",
       "  'of',\n",
       "  'attribute',\n",
       "  'values',\n",
       "  '.'],\n",
       " ['Order',\n",
       "  'to',\n",
       "  'placing',\n",
       "  'attributes',\n",
       "  'as',\n",
       "  'root',\n",
       "  'or',\n",
       "  'internal',\n",
       "  'node',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'done',\n",
       "  'by',\n",
       "  'using',\n",
       "  'some',\n",
       "  'statistical',\n",
       "  'approach',\n",
       "  '.'],\n",
       " ['Advantages',\n",
       "  'of',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  ':',\n",
       "  'Easy',\n",
       "  'to',\n",
       "  'Understand',\n",
       "  ':',\n",
       "  'Decision',\n",
       "  'tree',\n",
       "  'output',\n",
       "  'is',\n",
       "  'very',\n",
       "  'easy',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'even',\n",
       "  'for',\n",
       "  'people',\n",
       "  'from',\n",
       "  'non-analytical',\n",
       "  'background',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'does',\n",
       "  'not',\n",
       "  'require',\n",
       "  'any',\n",
       "  'statistical',\n",
       "  'knowledge',\n",
       "  'to',\n",
       "  'read',\n",
       "  'and',\n",
       "  'interpret',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['Its',\n",
       "  'graphical',\n",
       "  'representation',\n",
       "  'is',\n",
       "  'very',\n",
       "  'intuitive',\n",
       "  'and',\n",
       "  'users',\n",
       "  'can',\n",
       "  'easily',\n",
       "  'relate',\n",
       "  'their',\n",
       "  'hypothesis',\n",
       "  '.'],\n",
       " ['Useful',\n",
       "  'in',\n",
       "  'Data',\n",
       "  'exploration',\n",
       "  ':',\n",
       "  'Decision',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'fastest',\n",
       "  'way',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'most',\n",
       "  'significant',\n",
       "  'variables',\n",
       "  'and',\n",
       "  'relation',\n",
       "  'between',\n",
       "  'two',\n",
       "  'or',\n",
       "  'more',\n",
       "  'variables',\n",
       "  '.'],\n",
       " ['With',\n",
       "  'the',\n",
       "  'help',\n",
       "  'of',\n",
       "  'decision',\n",
       "  'trees',\n",
       "  ',',\n",
       "  'we',\n",
       "  'can',\n",
       "  'create',\n",
       "  'new',\n",
       "  'variables',\n",
       "  '/',\n",
       "  'features',\n",
       "  'that',\n",
       "  'has',\n",
       "  'better',\n",
       "  'power',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'target',\n",
       "  'variable',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'can',\n",
       "  'also',\n",
       "  'be',\n",
       "  'used',\n",
       "  'in',\n",
       "  'data',\n",
       "  'exploration',\n",
       "  'stage',\n",
       "  '.'],\n",
       " ['For',\n",
       "  'e.g.',\n",
       "  ',',\n",
       "  'we',\n",
       "  'are',\n",
       "  'working',\n",
       "  'on',\n",
       "  'a',\n",
       "  'problem',\n",
       "  'where',\n",
       "  'we',\n",
       "  'have',\n",
       "  'information',\n",
       "  'available',\n",
       "  'in',\n",
       "  'hundreds',\n",
       "  'of',\n",
       "  'variables',\n",
       "  ',',\n",
       "  'there',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'will',\n",
       "  'help',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'most',\n",
       "  'significant',\n",
       "  'variable',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'trees',\n",
       "  'implicitly',\n",
       "  'perform',\n",
       "  'variable',\n",
       "  'screening',\n",
       "  'or',\n",
       "  'feature',\n",
       "  'selection',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'trees',\n",
       "  'require',\n",
       "  'relatively',\n",
       "  'little',\n",
       "  'effort',\n",
       "  'from',\n",
       "  'users',\n",
       "  'for',\n",
       "  'data',\n",
       "  'preparation',\n",
       "  '.'],\n",
       " ['Less',\n",
       "  'data',\n",
       "  'cleaning',\n",
       "  'required',\n",
       "  ':',\n",
       "  'It',\n",
       "  'requires',\n",
       "  'less',\n",
       "  'data',\n",
       "  'cleaning',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'some',\n",
       "  'other',\n",
       "  'modeling',\n",
       "  'techniques',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'is',\n",
       "  'not',\n",
       "  'influenced',\n",
       "  'by',\n",
       "  'outliers',\n",
       "  'and',\n",
       "  'missing',\n",
       "  'values',\n",
       "  'to',\n",
       "  'a',\n",
       "  'fair',\n",
       "  'degree',\n",
       "  '.'],\n",
       " ['Data',\n",
       "  'type',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'constraint',\n",
       "  ':',\n",
       "  'It',\n",
       "  'can',\n",
       "  'handle',\n",
       "  'both',\n",
       "  'numerical',\n",
       "  'and',\n",
       "  'categorical',\n",
       "  'variables',\n",
       "  '.'],\n",
       " ['Can', 'also', 'handle', 'multi-output', 'problems', '.'],\n",
       " ['Non-Parametric',\n",
       "  'Method',\n",
       "  ':',\n",
       "  'Decision',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'considered',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'non-parametric',\n",
       "  'method',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'means',\n",
       "  'that',\n",
       "  'decision',\n",
       "  'trees',\n",
       "  'have',\n",
       "  'no',\n",
       "  'assumptions',\n",
       "  'about',\n",
       "  'the',\n",
       "  'space',\n",
       "  'distribution',\n",
       "  'and',\n",
       "  'the',\n",
       "  'classifier',\n",
       "  'structure',\n",
       "  '.'],\n",
       " ['Non-linear',\n",
       "  'relationships',\n",
       "  'between',\n",
       "  'parameters',\n",
       "  'do',\n",
       "  'not',\n",
       "  'affect',\n",
       "  'tree',\n",
       "  'performance',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'number',\n",
       "  'of',\n",
       "  'hyper-parameters',\n",
       "  'to',\n",
       "  'be',\n",
       "  'tuned',\n",
       "  'is',\n",
       "  'almost',\n",
       "  'null',\n",
       "  '.'],\n",
       " ['Disadvantages',\n",
       "  'of',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  ':',\n",
       "  'Over',\n",
       "  'fitting',\n",
       "  ':',\n",
       "  'Decision-tree',\n",
       "  'learners',\n",
       "  'can',\n",
       "  'create',\n",
       "  'over-complex',\n",
       "  'trees',\n",
       "  'that',\n",
       "  'do',\n",
       "  'not',\n",
       "  'generalize',\n",
       "  'the',\n",
       "  'data',\n",
       "  'well',\n",
       "  '.'],\n",
       " ['This', 'is', 'called', 'overfitting', '.'],\n",
       " ['Over',\n",
       "  'fitting',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'most',\n",
       "  'practical',\n",
       "  'difficulty',\n",
       "  'for',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'models',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'problem',\n",
       "  'gets',\n",
       "  'solved',\n",
       "  'by',\n",
       "  'setting',\n",
       "  'constraints',\n",
       "  'on',\n",
       "  'model',\n",
       "  'parameters',\n",
       "  'and',\n",
       "  'pruning',\n",
       "  '.'],\n",
       " ['Not',\n",
       "  'fit',\n",
       "  'for',\n",
       "  'continuous',\n",
       "  'variables',\n",
       "  ':',\n",
       "  'While',\n",
       "  'working',\n",
       "  'with',\n",
       "  'continuous',\n",
       "  'numerical',\n",
       "  'variables',\n",
       "  ',',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'loses',\n",
       "  'information',\n",
       "  ',',\n",
       "  'when',\n",
       "  'it',\n",
       "  'categorizes',\n",
       "  'variables',\n",
       "  'in',\n",
       "  'different',\n",
       "  'categories',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'trees',\n",
       "  'can',\n",
       "  'be',\n",
       "  'unstable',\n",
       "  'because',\n",
       "  'small',\n",
       "  'variations',\n",
       "  'in',\n",
       "  'the',\n",
       "  'data',\n",
       "  'might',\n",
       "  'result',\n",
       "  'in',\n",
       "  'a',\n",
       "  'completely',\n",
       "  'different',\n",
       "  'tree',\n",
       "  'being',\n",
       "  'generated',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'is',\n",
       "  'called',\n",
       "  'variance',\n",
       "  ',',\n",
       "  'which',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'be',\n",
       "  'lowered',\n",
       "  'by',\n",
       "  'methods',\n",
       "  'like',\n",
       "  'bagging',\n",
       "  'and',\n",
       "  'boosting',\n",
       "  '.'],\n",
       " ['Greedy',\n",
       "  'algorithms',\n",
       "  'can',\n",
       "  'not',\n",
       "  'guarantee',\n",
       "  'to',\n",
       "  'return',\n",
       "  'the',\n",
       "  'globally',\n",
       "  'optimal',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'can',\n",
       "  'be',\n",
       "  'mitigated',\n",
       "  'by',\n",
       "  'training',\n",
       "  'multiple',\n",
       "  'trees',\n",
       "  ',',\n",
       "  'where',\n",
       "  'the',\n",
       "  'features',\n",
       "  'and',\n",
       "  'samples',\n",
       "  'are',\n",
       "  'randomly',\n",
       "  'sampled',\n",
       "  'with',\n",
       "  'replacement',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'tree',\n",
       "  'learners',\n",
       "  'create',\n",
       "  'biased',\n",
       "  'trees',\n",
       "  'if',\n",
       "  'some',\n",
       "  'classes',\n",
       "  'dominate',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'is',\n",
       "  'therefore',\n",
       "  'recommended',\n",
       "  'to',\n",
       "  'balance',\n",
       "  'the',\n",
       "  'data',\n",
       "  'set',\n",
       "  'prior',\n",
       "  'to',\n",
       "  'fitting',\n",
       "  'with',\n",
       "  'the',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['Information',\n",
       "  'gain',\n",
       "  'in',\n",
       "  'a',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'with',\n",
       "  'categorical',\n",
       "  'variables',\n",
       "  'gives',\n",
       "  'a',\n",
       "  'biased',\n",
       "  'response',\n",
       "  'for',\n",
       "  'attributes',\n",
       "  'with',\n",
       "  'greater',\n",
       "  'no',\n",
       "  '.'],\n",
       " ['of', 'categories', '.'],\n",
       " ['Generally',\n",
       "  ',',\n",
       "  'it',\n",
       "  'gives',\n",
       "  'low',\n",
       "  'prediction',\n",
       "  'accuracy',\n",
       "  'for',\n",
       "  'a',\n",
       "  'dataset',\n",
       "  'as',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'other',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  '.'],\n",
       " ['Calculations',\n",
       "  'can',\n",
       "  'become',\n",
       "  'complex',\n",
       "  'when',\n",
       "  'there',\n",
       "  'are',\n",
       "  'many',\n",
       "  'class',\n",
       "  'label',\n",
       "  '.'],\n",
       " ['Regression',\n",
       "  'Trees',\n",
       "  'vs',\n",
       "  'Classification',\n",
       "  'Trees',\n",
       "  'The',\n",
       "  'terminal',\n",
       "  'nodes',\n",
       "  '(',\n",
       "  'or',\n",
       "  'leaves',\n",
       "  ')',\n",
       "  'lies',\n",
       "  'at',\n",
       "  'the',\n",
       "  'bottom',\n",
       "  'of',\n",
       "  'the',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'means',\n",
       "  'that',\n",
       "  'decision',\n",
       "  'trees',\n",
       "  'are',\n",
       "  'typically',\n",
       "  'drawn',\n",
       "  'upside',\n",
       "  'down',\n",
       "  'such',\n",
       "  'that',\n",
       "  'leaves',\n",
       "  'are',\n",
       "  'the',\n",
       "  'bottom',\n",
       "  '&',\n",
       "  'roots',\n",
       "  'are',\n",
       "  'the',\n",
       "  'tops',\n",
       "  '.'],\n",
       " ['Both',\n",
       "  'the',\n",
       "  'trees',\n",
       "  'work',\n",
       "  'almost',\n",
       "  'similar',\n",
       "  'to',\n",
       "  'each',\n",
       "  'other',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'primary',\n",
       "  'differences',\n",
       "  'and',\n",
       "  'similarities',\n",
       "  'between',\n",
       "  'Classification',\n",
       "  'and',\n",
       "  'Regression',\n",
       "  'Trees',\n",
       "  'are',\n",
       "  ':',\n",
       "  'Regression',\n",
       "  'trees',\n",
       "  'are',\n",
       "  'used',\n",
       "  'when',\n",
       "  'dependent',\n",
       "  'variable',\n",
       "  'is',\n",
       "  'continuous',\n",
       "  '.'],\n",
       " ['Classification',\n",
       "  'Trees',\n",
       "  'are',\n",
       "  'used',\n",
       "  'when',\n",
       "  'dependent',\n",
       "  'variable',\n",
       "  'is',\n",
       "  'categorical',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'case',\n",
       "  'of',\n",
       "  'Regression',\n",
       "  'Tree',\n",
       "  ',',\n",
       "  'the',\n",
       "  'value',\n",
       "  'obtained',\n",
       "  'by',\n",
       "  'terminal',\n",
       "  'nodes',\n",
       "  'in',\n",
       "  'the',\n",
       "  'training',\n",
       "  'data',\n",
       "  'is',\n",
       "  'the',\n",
       "  'mean',\n",
       "  'response',\n",
       "  'of',\n",
       "  'observation',\n",
       "  'falling',\n",
       "  'in',\n",
       "  'that',\n",
       "  'region',\n",
       "  '.'],\n",
       " ['Thus',\n",
       "  ',',\n",
       "  'if',\n",
       "  'an',\n",
       "  'unseen',\n",
       "  'data',\n",
       "  'observation',\n",
       "  'falls',\n",
       "  'in',\n",
       "  'that',\n",
       "  'region',\n",
       "  ',',\n",
       "  'we',\n",
       "  '’',\n",
       "  'll',\n",
       "  'make',\n",
       "  'its',\n",
       "  'prediction',\n",
       "  'with',\n",
       "  'mean',\n",
       "  'value',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'case',\n",
       "  'of',\n",
       "  'Classification',\n",
       "  'Tree',\n",
       "  ',',\n",
       "  'the',\n",
       "  'value',\n",
       "  '(',\n",
       "  'class',\n",
       "  ')',\n",
       "  'obtained',\n",
       "  'by',\n",
       "  'terminal',\n",
       "  'node',\n",
       "  'in',\n",
       "  'the',\n",
       "  'training',\n",
       "  'data',\n",
       "  'is',\n",
       "  'the',\n",
       "  'mode',\n",
       "  'of',\n",
       "  'observations',\n",
       "  'falling',\n",
       "  'in',\n",
       "  'that',\n",
       "  'region',\n",
       "  '.'],\n",
       " ['Thus',\n",
       "  ',',\n",
       "  'if',\n",
       "  'an',\n",
       "  'unseen',\n",
       "  'data',\n",
       "  'observation',\n",
       "  'falls',\n",
       "  'in',\n",
       "  'that',\n",
       "  'region',\n",
       "  ',',\n",
       "  'we',\n",
       "  '’',\n",
       "  'll',\n",
       "  'make',\n",
       "  'its',\n",
       "  'prediction',\n",
       "  'with',\n",
       "  'mode',\n",
       "  'value',\n",
       "  '.'],\n",
       " ['Both',\n",
       "  'the',\n",
       "  'trees',\n",
       "  'divide',\n",
       "  'the',\n",
       "  'predictor',\n",
       "  'space',\n",
       "  '(',\n",
       "  'independent',\n",
       "  'variables',\n",
       "  ')',\n",
       "  'into',\n",
       "  'distinct',\n",
       "  'and',\n",
       "  'non-overlapping',\n",
       "  'regions',\n",
       "  '.'],\n",
       " ['Both',\n",
       "  'the',\n",
       "  'trees',\n",
       "  'follow',\n",
       "  'a',\n",
       "  'top-down',\n",
       "  'greedy',\n",
       "  'approach',\n",
       "  'known',\n",
       "  'as',\n",
       "  'recursive',\n",
       "  'binary',\n",
       "  'splitting',\n",
       "  '.'],\n",
       " ['We',\n",
       "  'call',\n",
       "  'it',\n",
       "  'as',\n",
       "  '‘',\n",
       "  'top-down',\n",
       "  '’',\n",
       "  'because',\n",
       "  'it',\n",
       "  'begins',\n",
       "  'from',\n",
       "  'the',\n",
       "  'top',\n",
       "  'of',\n",
       "  'tree',\n",
       "  'when',\n",
       "  'all',\n",
       "  'the',\n",
       "  'observations',\n",
       "  'are',\n",
       "  'available',\n",
       "  'in',\n",
       "  'a',\n",
       "  'single',\n",
       "  'region',\n",
       "  'and',\n",
       "  'successively',\n",
       "  'splits',\n",
       "  'the',\n",
       "  'predictor',\n",
       "  'space',\n",
       "  'into',\n",
       "  'two',\n",
       "  'new',\n",
       "  'branches',\n",
       "  'down',\n",
       "  'the',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'is',\n",
       "  'known',\n",
       "  'as',\n",
       "  '‘',\n",
       "  'greedy',\n",
       "  '’',\n",
       "  'because',\n",
       "  ',',\n",
       "  'the',\n",
       "  'algorithm',\n",
       "  'cares',\n",
       "  '(',\n",
       "  'looks',\n",
       "  'for',\n",
       "  'best',\n",
       "  'variable',\n",
       "  'available',\n",
       "  ')',\n",
       "  'about',\n",
       "  'only',\n",
       "  'the',\n",
       "  'current',\n",
       "  'split',\n",
       "  ',',\n",
       "  'and',\n",
       "  'not',\n",
       "  'about',\n",
       "  'future',\n",
       "  'splits',\n",
       "  'which',\n",
       "  'will',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'a',\n",
       "  'better',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'splitting',\n",
       "  'process',\n",
       "  'is',\n",
       "  'continued',\n",
       "  'until',\n",
       "  'a',\n",
       "  'user',\n",
       "  'defined',\n",
       "  'stopping',\n",
       "  'criteria',\n",
       "  'is',\n",
       "  'reached',\n",
       "  '.'],\n",
       " ['For', 'e.g', '.'],\n",
       " [':',\n",
       "  'we',\n",
       "  'can',\n",
       "  'tell',\n",
       "  'the',\n",
       "  'algorithm',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'once',\n",
       "  'the',\n",
       "  'number',\n",
       "  'of',\n",
       "  'observations',\n",
       "  'per',\n",
       "  'node',\n",
       "  'becomes',\n",
       "  'less',\n",
       "  'than',\n",
       "  '50',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'both',\n",
       "  'the',\n",
       "  'cases',\n",
       "  ',',\n",
       "  'the',\n",
       "  'splitting',\n",
       "  'process',\n",
       "  'results',\n",
       "  'in',\n",
       "  'fully',\n",
       "  'grown',\n",
       "  'trees',\n",
       "  'until',\n",
       "  'the',\n",
       "  'stopping',\n",
       "  'criteria',\n",
       "  'is',\n",
       "  'reached',\n",
       "  '.'],\n",
       " ['But',\n",
       "  ',',\n",
       "  'the',\n",
       "  'fully',\n",
       "  'grown',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'over',\n",
       "  'fit',\n",
       "  'data',\n",
       "  ',',\n",
       "  'leading',\n",
       "  'to',\n",
       "  'poor',\n",
       "  'accuracy',\n",
       "  'on',\n",
       "  'unseen',\n",
       "  'data',\n",
       "  '.'],\n",
       " ['This', 'bring', '‘', 'pruning', '’', '.'],\n",
       " ['Pruning',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'technique',\n",
       "  'used',\n",
       "  'tackle',\n",
       "  'overfitting',\n",
       "  '.']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sentence=[]\n",
    "for i in sentences:\n",
    "    for j in i:\n",
    "        word_sentence.append(word_tokenize(j))\n",
    "word_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removal of stop words\n",
    "stop_words = set(stopwords.words('english')) \n",
    "line=[]\n",
    "filtered_sentence=[]\n",
    "\n",
    "for i in word_sentence:\n",
    "    for j in i:\n",
    "        if not j in stop_words:\n",
    "            line.append(j)\n",
    "    filtered_sentence.append(line)\n",
    "    line=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'decision',\n",
       " 'support',\n",
       " 'tool',\n",
       " 'uses',\n",
       " 'tree-like',\n",
       " 'graph',\n",
       " 'model',\n",
       " 'decisions',\n",
       " 'possible',\n",
       " 'consequences',\n",
       " ',',\n",
       " 'including',\n",
       " 'chance',\n",
       " 'event',\n",
       " 'outcomes',\n",
       " ',',\n",
       " 'resource',\n",
       " 'costs',\n",
       " ',',\n",
       " 'utility',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming the words\n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer()\n",
    "stemmed_sentences=[]\n",
    "line=[]\n",
    "for i in filtered_sentence:\n",
    "    for j in i:\n",
    "       line.append(ps.stem(j))\n",
    "    stemmed_sentences.append(line)\n",
    "    line=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations, numbers and special characters\n",
    "alphabetic_sentences=[]\n",
    "line=[]\n",
    "for i in stemmed_sentences:\n",
    "    line.append(pd.Series(i).str.replace(\"[^a-zA-Z]\", \" \"))\n",
    "    \n",
    "    \n",
    "    alphabetic_sentences.append(line)\n",
    "    line=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'decis',\n",
       "  'support',\n",
       "  'tool',\n",
       "  'use',\n",
       "  'tree lik',\n",
       "  'graph',\n",
       "  'model',\n",
       "  'decis',\n",
       "  'possibl',\n",
       "  'consequ',\n",
       "  'includ',\n",
       "  'chanc',\n",
       "  'event',\n",
       "  'outcom',\n",
       "  'resourc',\n",
       "  'cost',\n",
       "  'util'],\n",
       " ['it',\n",
       "  'one',\n",
       "  'way',\n",
       "  'display',\n",
       "  'algorithm',\n",
       "  'contain',\n",
       "  'condit',\n",
       "  'control',\n",
       "  'statement'],\n",
       " ['a',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'flowchart lik',\n",
       "  'structur',\n",
       "  'intern',\n",
       "  'node',\n",
       "  'repres',\n",
       "  'test',\n",
       "  'attribut',\n",
       "  'e g'],\n",
       " ['whether',\n",
       "  'coin',\n",
       "  'flip',\n",
       "  'come',\n",
       "  'head',\n",
       "  'tail',\n",
       "  'branch',\n",
       "  'repres',\n",
       "  'outcom',\n",
       "  'test',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'repres',\n",
       "  'class',\n",
       "  'label',\n",
       "  'decis',\n",
       "  'taken',\n",
       "  'comput',\n",
       "  'attribut'],\n",
       " ['the', 'path', 'root', 'leaf', 'repres', 'classif', 'rule'],\n",
       " ['tree',\n",
       "  'base',\n",
       "  'learn',\n",
       "  'algorithm',\n",
       "  'consid',\n",
       "  'one',\n",
       "  'best',\n",
       "  'mostli',\n",
       "  'use',\n",
       "  'supervis',\n",
       "  'learn',\n",
       "  'method'],\n",
       " ['tree',\n",
       "  'base',\n",
       "  'method',\n",
       "  'empow',\n",
       "  'predict',\n",
       "  'model',\n",
       "  'high',\n",
       "  'accuraci',\n",
       "  'stabil',\n",
       "  'eas',\n",
       "  'interpret'],\n",
       " ['unlik',\n",
       "  'linear',\n",
       "  'model',\n",
       "  'map',\n",
       "  'non linear',\n",
       "  'relationship',\n",
       "  'quit',\n",
       "  'well'],\n",
       " ['they', 'adapt', 'solv', 'kind', 'problem', 'hand', 'classif', 'regress'],\n",
       " ['decis', 'tree', 'algorithm', 'refer', 'cart', 'classif', 'regress', 'tree'],\n",
       " ['the',\n",
       "  'possibl',\n",
       "  'solut',\n",
       "  'given',\n",
       "  'problem',\n",
       "  'emerg',\n",
       "  'leav',\n",
       "  'tree',\n",
       "  'node',\n",
       "  'repres',\n",
       "  'point',\n",
       "  'deliber',\n",
       "  'decision ',\n",
       "  'niklau',\n",
       "  'wirth',\n",
       "  '    ',\n",
       "  'program',\n",
       "  'languag',\n",
       "  'design',\n",
       "  'method',\n",
       "  'like',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'gradient',\n",
       "  'boost',\n",
       "  'popularli',\n",
       "  'use',\n",
       "  'kind',\n",
       "  'data',\n",
       "  'scienc',\n",
       "  'problem'],\n",
       " ['common',\n",
       "  'term',\n",
       "  'use',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'root',\n",
       "  'node',\n",
       "  'it',\n",
       "  'repres',\n",
       "  'entir',\n",
       "  'popul',\n",
       "  'sampl',\n",
       "  'get',\n",
       "  'divid',\n",
       "  'two',\n",
       "  'homogen',\n",
       "  'set'],\n",
       " ['split', 'it', 'process', 'divid', 'node', 'two', 'sub nod'],\n",
       " ['decis',\n",
       "  'node',\n",
       "  'when',\n",
       "  'sub nod',\n",
       "  'split',\n",
       "  'sub nod',\n",
       "  'call',\n",
       "  'decis',\n",
       "  'node'],\n",
       " ['leaf ',\n",
       "  'termin',\n",
       "  'node',\n",
       "  'node',\n",
       "  'split',\n",
       "  'call',\n",
       "  'leaf',\n",
       "  'termin',\n",
       "  'node'],\n",
       " ['prune',\n",
       "  'when',\n",
       "  'remov',\n",
       "  'sub nod',\n",
       "  'decis',\n",
       "  'node',\n",
       "  'process',\n",
       "  'call',\n",
       "  'prune'],\n",
       " ['you', 'say', 'opposit', 'process', 'split'],\n",
       " ['branch',\n",
       "  'sub tre',\n",
       "  'a',\n",
       "  'sub',\n",
       "  'section',\n",
       "  'entir',\n",
       "  'tree',\n",
       "  'call',\n",
       "  'branch',\n",
       "  'sub tre'],\n",
       " ['parent',\n",
       "  'child',\n",
       "  'node',\n",
       "  'a',\n",
       "  'node',\n",
       "  'divid',\n",
       "  'sub nod',\n",
       "  'call',\n",
       "  'parent',\n",
       "  'node',\n",
       "  'sub nod',\n",
       "  'wherea',\n",
       "  'sub nod',\n",
       "  'child',\n",
       "  'parent',\n",
       "  'node'],\n",
       " ['applic',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'natur',\n",
       "  'els',\n",
       "  'construct',\n",
       "  'make',\n",
       "  'fit',\n",
       "  'easili',\n",
       "  'programmat',\n",
       "  'structur'],\n",
       " ['they',\n",
       "  'also',\n",
       "  'well',\n",
       "  'suit',\n",
       "  'categor',\n",
       "  'problem',\n",
       "  'attribut',\n",
       "  'featur',\n",
       "  'systemat',\n",
       "  'check',\n",
       "  'determin',\n",
       "  'final',\n",
       "  'categori'],\n",
       " ['for',\n",
       "  'exampl',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'could',\n",
       "  'use',\n",
       "  'effect',\n",
       "  'determin',\n",
       "  'speci',\n",
       "  'anim'],\n",
       " ['as',\n",
       "  'result',\n",
       "  'decis',\n",
       "  'make',\n",
       "  'tree',\n",
       "  'one',\n",
       "  'popular',\n",
       "  'classif',\n",
       "  'algorithm',\n",
       "  'use',\n",
       "  'data',\n",
       "  'mine',\n",
       "  'machin',\n",
       "  'learn'],\n",
       " ['exampl',\n",
       "  'applic',\n",
       "  'includ',\n",
       "  'evalu',\n",
       "  'brand',\n",
       "  'expans',\n",
       "  'opportun',\n",
       "  'busi',\n",
       "  'use',\n",
       "  'histor',\n",
       "  'sale',\n",
       "  'data',\n",
       "  'determin',\n",
       "  'like',\n",
       "  'buyer',\n",
       "  'product',\n",
       "  'use',\n",
       "  'demograph',\n",
       "  'data',\n",
       "  'enabl',\n",
       "  'target',\n",
       "  'limit',\n",
       "  'advertis',\n",
       "  'budget',\n",
       "  'predict',\n",
       "  'likelihood',\n",
       "  'default',\n",
       "  'applic',\n",
       "  'borrow',\n",
       "  'use',\n",
       "  'predict',\n",
       "  'model',\n",
       "  'gener',\n",
       "  'histor',\n",
       "  'data',\n",
       "  'help',\n",
       "  'priorit',\n",
       "  'emerg',\n",
       "  'room',\n",
       "  'patient',\n",
       "  'treatment',\n",
       "  'use',\n",
       "  'predict',\n",
       "  'model',\n",
       "  'base',\n",
       "  'factor',\n",
       "  'age',\n",
       "  'blood',\n",
       "  'pressur',\n",
       "  'gender',\n",
       "  'locat',\n",
       "  'sever',\n",
       "  'pain',\n",
       "  'measur',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'commonli',\n",
       "  'use',\n",
       "  'oper',\n",
       "  'research',\n",
       "  'specif',\n",
       "  'decis',\n",
       "  'analysi',\n",
       "  'help',\n",
       "  'identifi',\n",
       "  'strategi',\n",
       "  'like',\n",
       "  'reach',\n",
       "  'goal'],\n",
       " ['becaus',\n",
       "  'simplic',\n",
       "  'tree',\n",
       "  'diagram',\n",
       "  'use',\n",
       "  'broad',\n",
       "  'rang',\n",
       "  'industri',\n",
       "  'disciplin',\n",
       "  'includ',\n",
       "  'civil',\n",
       "  'plan',\n",
       "  'energi',\n",
       "  'financi',\n",
       "  'engin',\n",
       "  'healthcar',\n",
       "  'pharmaceut',\n",
       "  'educ',\n",
       "  'law',\n",
       "  'busi'],\n",
       " ['how', 'decis', 'tree', 'work'],\n",
       " ['decis',\n",
       "  'tree',\n",
       "  'type',\n",
       "  'supervis',\n",
       "  'learn',\n",
       "  'algorithm',\n",
       "  'pre defin',\n",
       "  'target',\n",
       "  'variabl',\n",
       "  'mostli',\n",
       "  'use',\n",
       "  'classif',\n",
       "  'problem'],\n",
       " ['it', 'work', 'categor', 'continu', 'input', 'output', 'variabl'],\n",
       " ['in',\n",
       "  'techniqu',\n",
       "  'split',\n",
       "  'popul',\n",
       "  'sampl',\n",
       "  'two',\n",
       "  'homogen',\n",
       "  'set',\n",
       "  'sub popul',\n",
       "  'base',\n",
       "  'signific',\n",
       "  'splitter',\n",
       "  'differenti',\n",
       "  'input',\n",
       "  'variabl'],\n",
       " ['exampl',\n",
       "  'let',\n",
       "  'say',\n",
       "  'sampl',\n",
       "  '  ',\n",
       "  'student',\n",
       "  'three',\n",
       "  'variabl',\n",
       "  'gender',\n",
       "  'boy ',\n",
       "  'girl',\n",
       "  'class',\n",
       "  'ix ',\n",
       "  'x',\n",
       "  'height',\n",
       "  'ft'],\n",
       " ['  ', '  ', 'play', 'cricket', 'leisur', 'time'],\n",
       " ['now',\n",
       "  'want',\n",
       "  'creat',\n",
       "  'model',\n",
       "  'predict',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'leisur',\n",
       "  'period'],\n",
       " ['in',\n",
       "  'problem',\n",
       "  'need',\n",
       "  'segreg',\n",
       "  'student',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'leisur',\n",
       "  'time',\n",
       "  'base',\n",
       "  'highli',\n",
       "  'signific',\n",
       "  'input',\n",
       "  'variabl',\n",
       "  'among',\n",
       "  'three'],\n",
       " ['thi',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'help',\n",
       "  'segreg',\n",
       "  'student',\n",
       "  'base',\n",
       "  'valu',\n",
       "  'three',\n",
       "  'variabl',\n",
       "  'identifi',\n",
       "  'variabl',\n",
       "  'creat',\n",
       "  'best',\n",
       "  'homogen',\n",
       "  'set',\n",
       "  'student',\n",
       "  'heterogen'],\n",
       " ['in',\n",
       "  'snapshot',\n",
       "  'see',\n",
       "  'variabl',\n",
       "  'gender',\n",
       "  'abl',\n",
       "  'identifi',\n",
       "  'best',\n",
       "  'homogen',\n",
       "  'set',\n",
       "  'compar',\n",
       "  'two',\n",
       "  'variabl'],\n",
       " ['decis',\n",
       "  'tree',\n",
       "  'identifi',\n",
       "  'signific',\n",
       "  'variabl',\n",
       "  'valu',\n",
       "  'give',\n",
       "  'best',\n",
       "  'homogen',\n",
       "  'set',\n",
       "  'popul'],\n",
       " ['to',\n",
       "  'identifi',\n",
       "  'variabl',\n",
       "  'split',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'use',\n",
       "  'variou',\n",
       "  'algorithm'],\n",
       " ['type',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'type',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'base',\n",
       "  'type',\n",
       "  'target',\n",
       "  'variabl'],\n",
       " ['it',\n",
       "  'two',\n",
       "  'type',\n",
       "  'categor',\n",
       "  'variabl',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'categor',\n",
       "  'target',\n",
       "  'variabl',\n",
       "  'call',\n",
       "  'categor',\n",
       "  'variabl',\n",
       "  'decis',\n",
       "  'tree'],\n",
       " ['e g'],\n",
       " ['in',\n",
       "  'scenario',\n",
       "  'student',\n",
       "  'problem',\n",
       "  'target',\n",
       "  'variabl',\n",
       "  'student',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'i e'],\n",
       " ['ye', 'no'],\n",
       " ['continu',\n",
       "  'variabl',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'continu',\n",
       "  'target',\n",
       "  'variabl',\n",
       "  'call',\n",
       "  'continu',\n",
       "  'variabl',\n",
       "  'decis',\n",
       "  'tree'],\n",
       " ['e g'],\n",
       " ['let',\n",
       "  'say',\n",
       "  'problem',\n",
       "  'predict',\n",
       "  'whether',\n",
       "  'custom',\n",
       "  'pay',\n",
       "  'renew',\n",
       "  'premium',\n",
       "  'insur',\n",
       "  'compani',\n",
       "  'yes '],\n",
       " ['here',\n",
       "  'know',\n",
       "  'incom',\n",
       "  'custom',\n",
       "  'signific',\n",
       "  'variabl',\n",
       "  'insur',\n",
       "  'compani',\n",
       "  'incom',\n",
       "  'detail',\n",
       "  'custom'],\n",
       " ['now',\n",
       "  'know',\n",
       "  'import',\n",
       "  'variabl',\n",
       "  'build',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'predict',\n",
       "  'custom',\n",
       "  'incom',\n",
       "  'base',\n",
       "  'occup',\n",
       "  'product',\n",
       "  'variou',\n",
       "  'variabl'],\n",
       " ['in', 'case', 'predict', 'valu', 'continu', 'variabl'],\n",
       " ['the',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'algorithm',\n",
       "  'tri',\n",
       "  'solv',\n",
       "  'problem',\n",
       "  'use',\n",
       "  'tree',\n",
       "  'represent'],\n",
       " ['each',\n",
       "  'intern',\n",
       "  'node',\n",
       "  'tree',\n",
       "  'correspond',\n",
       "  'attribut',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'correspond',\n",
       "  'class',\n",
       "  'label'],\n",
       " ['place', 'best', 'attribut', 'dataset', 'root', 'tree'],\n",
       " ['split', 'train', 'set', 'subset'],\n",
       " ['subset', 'made', 'way', 'subset', 'contain', 'data', 'valu', 'attribut'],\n",
       " ['repeat',\n",
       "  'step',\n",
       "  'step',\n",
       "  'subset',\n",
       "  'find',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'branch',\n",
       "  'tree'],\n",
       " ['in',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'predict',\n",
       "  'class',\n",
       "  'label',\n",
       "  'record',\n",
       "  'start',\n",
       "  'root',\n",
       "  'tree'],\n",
       " ['we', 'compar', 'valu', 'root', 'attribut', 'record', 'attribut'],\n",
       " ['on',\n",
       "  'basi',\n",
       "  'comparison',\n",
       "  'follow',\n",
       "  'branch',\n",
       "  'correspond',\n",
       "  'valu',\n",
       "  'jump',\n",
       "  'next',\n",
       "  'node'],\n",
       " ['we',\n",
       "  'continu',\n",
       "  'compar',\n",
       "  'record',\n",
       "  'attribut',\n",
       "  'valu',\n",
       "  'intern',\n",
       "  'node',\n",
       "  'tree',\n",
       "  'reach',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'predict',\n",
       "  'class',\n",
       "  'valu'],\n",
       " ['the',\n",
       "  'model',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'use',\n",
       "  'predict',\n",
       "  'target',\n",
       "  'class',\n",
       "  'valu'],\n",
       " ['assumpt',\n",
       "  'creat',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'some',\n",
       "  'assumpt',\n",
       "  'make',\n",
       "  'use',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'at',\n",
       "  'begin',\n",
       "  'whole',\n",
       "  'train',\n",
       "  'set',\n",
       "  'consid',\n",
       "  'root'],\n",
       " ['featur', 'valu', 'prefer', 'categor'],\n",
       " ['if', 'valu', 'continu', 'discret', 'prior', 'build', 'model'],\n",
       " ['record', 'distribut', 'recurs', 'basi', 'attribut', 'valu'],\n",
       " ['order',\n",
       "  'place',\n",
       "  'attribut',\n",
       "  'root',\n",
       "  'intern',\n",
       "  'node',\n",
       "  'tree',\n",
       "  'done',\n",
       "  'use',\n",
       "  'statist',\n",
       "  'approach'],\n",
       " ['advantag',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'easi',\n",
       "  'understand',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'output',\n",
       "  'easi',\n",
       "  'understand',\n",
       "  'even',\n",
       "  'peopl',\n",
       "  'non analyt',\n",
       "  'background'],\n",
       " ['it', 'requir', 'statist', 'knowledg', 'read', 'interpret'],\n",
       " ['it',\n",
       "  'graphic',\n",
       "  'represent',\n",
       "  'intuit',\n",
       "  'user',\n",
       "  'easili',\n",
       "  'relat',\n",
       "  'hypothesi'],\n",
       " ['use',\n",
       "  'data',\n",
       "  'explor',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'one',\n",
       "  'fastest',\n",
       "  'way',\n",
       "  'identifi',\n",
       "  'signific',\n",
       "  'variabl',\n",
       "  'relat',\n",
       "  'two',\n",
       "  'variabl'],\n",
       " ['with',\n",
       "  'help',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'creat',\n",
       "  'new',\n",
       "  'variabl',\n",
       "  'featur',\n",
       "  'better',\n",
       "  'power',\n",
       "  'predict',\n",
       "  'target',\n",
       "  'variabl'],\n",
       " ['it', 'also', 'use', 'data', 'explor', 'stage'],\n",
       " ['for',\n",
       "  'e g ',\n",
       "  'work',\n",
       "  'problem',\n",
       "  'inform',\n",
       "  'avail',\n",
       "  'hundr',\n",
       "  'variabl',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'help',\n",
       "  'identifi',\n",
       "  'signific',\n",
       "  'variabl'],\n",
       " ['decis',\n",
       "  'tree',\n",
       "  'implicitli',\n",
       "  'perform',\n",
       "  'variabl',\n",
       "  'screen',\n",
       "  'featur',\n",
       "  'select'],\n",
       " ['decis',\n",
       "  'tree',\n",
       "  'requir',\n",
       "  'rel',\n",
       "  'littl',\n",
       "  'effort',\n",
       "  'user',\n",
       "  'data',\n",
       "  'prepar'],\n",
       " ['less',\n",
       "  'data',\n",
       "  'clean',\n",
       "  'requir',\n",
       "  'it',\n",
       "  'requir',\n",
       "  'less',\n",
       "  'data',\n",
       "  'clean',\n",
       "  'compar',\n",
       "  'model',\n",
       "  'techniqu'],\n",
       " ['it', 'influenc', 'outlier', 'miss', 'valu', 'fair', 'degre'],\n",
       " ['data', 'type', 'constraint', 'it', 'handl', 'numer', 'categor', 'variabl'],\n",
       " ['can', 'also', 'handl', 'multi output', 'problem'],\n",
       " ['non parametr',\n",
       "  'method',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'consid',\n",
       "  'non parametr',\n",
       "  'method'],\n",
       " ['thi',\n",
       "  'mean',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'assumpt',\n",
       "  'space',\n",
       "  'distribut',\n",
       "  'classifi',\n",
       "  'structur'],\n",
       " ['non linear', 'relationship', 'paramet', 'affect', 'tree', 'perform'],\n",
       " ['the', 'number', 'hyper paramet', 'tune', 'almost', 'null'],\n",
       " ['disadvantag',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'over',\n",
       "  'fit',\n",
       "  'decision tre',\n",
       "  'learner',\n",
       "  'creat',\n",
       "  'over complex',\n",
       "  'tree',\n",
       "  'gener',\n",
       "  'data',\n",
       "  'well'],\n",
       " ['thi', 'call', 'overfit'],\n",
       " ['over', 'fit', 'one', 'practic', 'difficulti', 'decis', 'tree', 'model'],\n",
       " ['thi',\n",
       "  'problem',\n",
       "  'get',\n",
       "  'solv',\n",
       "  'set',\n",
       "  'constraint',\n",
       "  'model',\n",
       "  'paramet',\n",
       "  'prune'],\n",
       " ['not',\n",
       "  'fit',\n",
       "  'continu',\n",
       "  'variabl',\n",
       "  'while',\n",
       "  'work',\n",
       "  'continu',\n",
       "  'numer',\n",
       "  'variabl',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'lose',\n",
       "  'inform',\n",
       "  'categor',\n",
       "  'variabl',\n",
       "  'differ',\n",
       "  'categori'],\n",
       " ['decis',\n",
       "  'tree',\n",
       "  'unstabl',\n",
       "  'small',\n",
       "  'variat',\n",
       "  'data',\n",
       "  'might',\n",
       "  'result',\n",
       "  'complet',\n",
       "  'differ',\n",
       "  'tree',\n",
       "  'gener'],\n",
       " ['thi', 'call', 'varianc', 'need', 'lower', 'method', 'like', 'bag', 'boost'],\n",
       " ['greedi',\n",
       "  'algorithm',\n",
       "  'guarante',\n",
       "  'return',\n",
       "  'global',\n",
       "  'optim',\n",
       "  'decis',\n",
       "  'tree'],\n",
       " ['thi',\n",
       "  'mitig',\n",
       "  'train',\n",
       "  'multipl',\n",
       "  'tree',\n",
       "  'featur',\n",
       "  'sampl',\n",
       "  'randomli',\n",
       "  'sampl',\n",
       "  'replac'],\n",
       " ['decis', 'tree', 'learner', 'creat', 'bias', 'tree', 'class', 'domin'],\n",
       " ['it',\n",
       "  'therefor',\n",
       "  'recommend',\n",
       "  'balanc',\n",
       "  'data',\n",
       "  'set',\n",
       "  'prior',\n",
       "  'fit',\n",
       "  'decis',\n",
       "  'tree'],\n",
       " ['inform',\n",
       "  'gain',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'categor',\n",
       "  'variabl',\n",
       "  'give',\n",
       "  'bias',\n",
       "  'respons',\n",
       "  'attribut',\n",
       "  'greater'],\n",
       " ['categori'],\n",
       " ['gener',\n",
       "  'give',\n",
       "  'low',\n",
       "  'predict',\n",
       "  'accuraci',\n",
       "  'dataset',\n",
       "  'compar',\n",
       "  'machin',\n",
       "  'learn',\n",
       "  'algorithm'],\n",
       " ['calcul', 'becom', 'complex', 'mani', 'class', 'label'],\n",
       " ['regress',\n",
       "  'tree',\n",
       "  'vs',\n",
       "  'classif',\n",
       "  'tree',\n",
       "  'the',\n",
       "  'termin',\n",
       "  'node',\n",
       "  'leav',\n",
       "  'lie',\n",
       "  'bottom',\n",
       "  'decis',\n",
       "  'tree'],\n",
       " ['thi',\n",
       "  'mean',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'typic',\n",
       "  'drawn',\n",
       "  'upsid',\n",
       "  'leav',\n",
       "  'bottom',\n",
       "  'root',\n",
       "  'top'],\n",
       " ['both', 'tree', 'work', 'almost', 'similar'],\n",
       " ['the',\n",
       "  'primari',\n",
       "  'differ',\n",
       "  'similar',\n",
       "  'classif',\n",
       "  'regress',\n",
       "  'tree',\n",
       "  'regress',\n",
       "  'tree',\n",
       "  'use',\n",
       "  'depend',\n",
       "  'variabl',\n",
       "  'continu'],\n",
       " ['classif', 'tree', 'use', 'depend', 'variabl', 'categor'],\n",
       " ['in',\n",
       "  'case',\n",
       "  'regress',\n",
       "  'tree',\n",
       "  'valu',\n",
       "  'obtain',\n",
       "  'termin',\n",
       "  'node',\n",
       "  'train',\n",
       "  'data',\n",
       "  'mean',\n",
       "  'respons',\n",
       "  'observ',\n",
       "  'fall',\n",
       "  'region'],\n",
       " ['thu',\n",
       "  'unseen',\n",
       "  'data',\n",
       "  'observ',\n",
       "  'fall',\n",
       "  'region',\n",
       "  'make',\n",
       "  'predict',\n",
       "  'mean',\n",
       "  'valu'],\n",
       " ['in',\n",
       "  'case',\n",
       "  'classif',\n",
       "  'tree',\n",
       "  'valu',\n",
       "  'class',\n",
       "  'obtain',\n",
       "  'termin',\n",
       "  'node',\n",
       "  'train',\n",
       "  'data',\n",
       "  'mode',\n",
       "  'observ',\n",
       "  'fall',\n",
       "  'region'],\n",
       " ['thu',\n",
       "  'unseen',\n",
       "  'data',\n",
       "  'observ',\n",
       "  'fall',\n",
       "  'region',\n",
       "  'make',\n",
       "  'predict',\n",
       "  'mode',\n",
       "  'valu'],\n",
       " ['both',\n",
       "  'tree',\n",
       "  'divid',\n",
       "  'predictor',\n",
       "  'space',\n",
       "  'independ',\n",
       "  'variabl',\n",
       "  'distinct',\n",
       "  'non overlap',\n",
       "  'region'],\n",
       " ['both',\n",
       "  'tree',\n",
       "  'follow',\n",
       "  'top down',\n",
       "  'greedi',\n",
       "  'approach',\n",
       "  'known',\n",
       "  'recurs',\n",
       "  'binari',\n",
       "  'split'],\n",
       " ['we',\n",
       "  'call',\n",
       "  'top down',\n",
       "  'begin',\n",
       "  'top',\n",
       "  'tree',\n",
       "  'observ',\n",
       "  'avail',\n",
       "  'singl',\n",
       "  'region',\n",
       "  'success',\n",
       "  'split',\n",
       "  'predictor',\n",
       "  'space',\n",
       "  'two',\n",
       "  'new',\n",
       "  'branch',\n",
       "  'tree'],\n",
       " ['it',\n",
       "  'known',\n",
       "  'greedi',\n",
       "  'algorithm',\n",
       "  'care',\n",
       "  'look',\n",
       "  'best',\n",
       "  'variabl',\n",
       "  'avail',\n",
       "  'current',\n",
       "  'split',\n",
       "  'futur',\n",
       "  'split',\n",
       "  'lead',\n",
       "  'better',\n",
       "  'tree'],\n",
       " ['thi',\n",
       "  'split',\n",
       "  'process',\n",
       "  'continu',\n",
       "  'user',\n",
       "  'defin',\n",
       "  'stop',\n",
       "  'criteria',\n",
       "  'reach'],\n",
       " ['for', 'e g'],\n",
       " ['tell',\n",
       "  'algorithm',\n",
       "  'stop',\n",
       "  'number',\n",
       "  'observ',\n",
       "  'per',\n",
       "  'node',\n",
       "  'becom',\n",
       "  'less',\n",
       "  '  '],\n",
       " ['in',\n",
       "  'case',\n",
       "  'split',\n",
       "  'process',\n",
       "  'result',\n",
       "  'fulli',\n",
       "  'grown',\n",
       "  'tree',\n",
       "  'stop',\n",
       "  'criteria',\n",
       "  'reach'],\n",
       " ['but',\n",
       "  'fulli',\n",
       "  'grown',\n",
       "  'tree',\n",
       "  'like',\n",
       "  'fit',\n",
       "  'data',\n",
       "  'lead',\n",
       "  'poor',\n",
       "  'accuraci',\n",
       "  'unseen',\n",
       "  'data'],\n",
       " ['thi', 'bring', 'prune'],\n",
       " ['prune', 'one', 'techniqu', 'use', 'tackl', 'overfit']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = []\n",
    "\n",
    "for i in alphabetic_sentences:\n",
    "   \n",
    "    for j in i:\n",
    "        l=[]\n",
    "        for x in j.values:\n",
    "            if not x ==' ':\n",
    "                l.append(x.lower())\n",
    "        line.append(l)\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "words=[y for x in line for y in x ]\n",
    "\n",
    "#Taking all distinct words in an array\n",
    "Distinct_Words=[y for y in set(words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Distinct_Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1239"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visulaizaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 gender\n",
      "1 null\n",
      "2 basi\n",
      "3 broad\n",
      "4 multipl\n",
      "5 buyer\n",
      "6 comparison\n",
      "7 scenario\n",
      "8 output\n",
      "9 set\n",
      "10 applic\n",
      "11 demograph\n",
      "12 to\n",
      "13 easi\n",
      "14 peopl\n",
      "15 but\n",
      "16 cost\n",
      "17 compar\n",
      "18 event\n",
      "19 differenti\n",
      "20 affect\n",
      "21 non analyt\n",
      "22 highli\n",
      "23 accuraci\n",
      "24 poor\n",
      "25 oper\n",
      "26 scienc\n",
      "27 step\n",
      "28 creat\n",
      "29 program\n",
      "30 build\n",
      "31 numer\n",
      "32 default\n",
      "33 as\n",
      "34 tool\n",
      "35 play\n",
      "36 gener\n",
      "37 patient\n",
      "38 tell\n",
      "39 bring\n",
      "40 expans\n",
      "41 not\n",
      "42 each\n",
      "43 snapshot\n",
      "44 control\n",
      "45 they\n",
      "46 background\n",
      "47 industri\n",
      "48 requir\n",
      "49 care\n",
      "50 tackl\n",
      "51 custom\n",
      "52 sub nod\n",
      "53 pain\n",
      "54 difficulti\n",
      "55 classifi\n",
      "56 perform\n",
      "57 brand\n",
      "58 multi output\n",
      "59 enabl\n",
      "60 boy \n",
      "61 adapt\n",
      "62 explor\n",
      "63 record\n",
      "64 dataset\n",
      "65 degre\n",
      "66 strategi\n",
      "67 complex\n",
      "68 a\n",
      "69 high\n",
      "70 get\n",
      "71 law\n",
      "72 programmat\n",
      "73 segreg\n",
      "74 non overlap\n",
      "75 gradient\n",
      "76 known\n",
      "77 among\n",
      "78 order\n",
      "79 speci\n",
      "80 anim\n",
      "81 likelihood\n",
      "82 pre defin\n",
      "83 machin\n",
      "84 reach\n",
      "85 also\n",
      "86 if\n",
      "87 it\n",
      "88 train\n",
      "89 lower\n",
      "90 typic\n",
      "91 two\n",
      "92 leaf \n",
      "93 heterogen\n",
      "94 space\n",
      "95 hyper paramet\n",
      "96 per\n",
      "97 ft\n",
      "98 label\n",
      "99 well\n",
      "100 test\n",
      "101 with\n",
      "102 fit\n",
      "103 decision \n",
      "104 stabil\n",
      "105 wirth\n",
      "106 disciplin\n",
      "107 natur\n",
      "108 can\n",
      "109 head\n",
      "110 comput\n",
      "111 child\n",
      "112 region\n",
      "113 construct\n",
      "114 product\n",
      "115 for\n",
      "116 check\n",
      "117 distinct\n",
      "118 solut\n",
      "119 interpret\n",
      "120 yes \n",
      "121 even\n",
      "122 sampl\n",
      "123   \n",
      "124 top\n",
      "125 approach\n",
      "126 treatment\n",
      "127 criteria\n",
      "128 analysi\n",
      "129 next\n",
      "130 structur\n",
      "131 new\n",
      "132 financi\n",
      "133 start\n",
      "134 divid\n",
      "135 classif\n",
      "136 mine\n",
      "137 pressur\n",
      "138 work\n",
      "139 graphic\n",
      "140 becom\n",
      "141 done\n",
      "142 quit\n",
      "143 parent\n",
      "144 algorithm\n",
      "145 ix \n",
      "146 flip\n",
      "147 techniqu\n",
      "148 problem\n",
      "149 educ\n",
      "150 whole\n",
      "151 we\n",
      "152 import\n",
      "153 lead\n",
      "154 decision tre\n",
      "155 condit\n",
      "156 relat\n",
      "157 paramet\n",
      "158 like\n",
      "159 engin\n",
      "160 you\n",
      "161 miss\n",
      "162 popular\n",
      "163 disadvantag\n",
      "164 jump\n",
      "165 overfit\n",
      "166 easili\n",
      "167 littl\n",
      "168 civil\n",
      "169 sub tre\n",
      "170 statement\n",
      "171 age\n",
      "172 optim\n",
      "173 solv\n",
      "174 one\n",
      "175 constraint\n",
      "176 assumpt\n",
      "177 empow\n",
      "178 when\n",
      "179 on\n",
      "180 split\n",
      "181 mode\n",
      "182 implicitli\n",
      "183 gain\n",
      "184 subset\n",
      "185 tri\n",
      "186 non linear\n",
      "187 boost\n",
      "188 way\n",
      "189 advertis\n",
      "190 variabl\n",
      "191 grown\n",
      "192 includ\n",
      "193 popularli\n",
      "194 lie\n",
      "195 singl\n",
      "196 recurs\n",
      "197 calcul\n",
      "198 recommend\n",
      "199 healthcar\n",
      "200 sub\n",
      "201 repeat\n",
      "202 learner\n",
      "203 display\n",
      "204 unlik\n",
      "205 read\n",
      "206 research\n",
      "207 variou\n",
      "208 detail\n",
      "209 how\n",
      "210 i e\n",
      "211 fastest\n",
      "212 place\n",
      "213 fulli\n",
      "214 time\n",
      "215 root\n",
      "216 at\n",
      "217 guarante\n",
      "218 pay\n",
      "219 popul\n",
      "220 input\n",
      "221 x\n",
      "222 begin\n",
      "223 non parametr\n",
      "224 contain\n",
      "225 observ\n",
      "226 no\n",
      "227 fair\n",
      "228 bias\n",
      "229 three\n",
      "230 wherea\n",
      "231 handl\n",
      "232 whether\n",
      "233 cricket\n",
      "234 intern\n",
      "235 say\n",
      "236 determin\n",
      "237 incom\n",
      "238 process\n",
      "239 bottom\n",
      "240 room\n",
      "241 global\n",
      "242 thi\n",
      "243 kind\n",
      "244 distribut\n",
      "245 attribut\n",
      "246 varianc\n",
      "247 unseen\n",
      "248 categori\n",
      "249 might\n",
      "250 chanc\n",
      "251 linear\n",
      "252 flowchart lik\n",
      "253 consid\n",
      "254 discret\n",
      "255 systemat\n",
      "256 avail\n",
      "257 number\n",
      "258 opposit\n",
      "259 locat\n",
      "260 final\n",
      "261 futur\n",
      "262 need\n",
      "263 section\n",
      "264 blood\n",
      "265 class\n",
      "266 power\n",
      "267 call\n",
      "268 bag\n",
      "269 measur\n",
      "270 forest\n",
      "271 occup\n",
      "272 respons\n",
      "273 given\n",
      "274 want\n",
      "275 therefor\n",
      "276 data\n",
      "277 variat\n",
      "278 limit\n",
      "279 make\n",
      "280 clean\n",
      "281 prune\n",
      "282 base\n",
      "283 premium\n",
      "284 better\n",
      "285 complet\n",
      "286 knowledg\n",
      "287 energi\n",
      "288 regress\n",
      "289 find\n",
      "290 in\n",
      "291 use\n",
      "292 sub popul\n",
      "293 entir\n",
      "294 practic\n",
      "295 emerg\n",
      "296 method\n",
      "297 repres\n",
      "298 prepar\n",
      "299 fall\n",
      "300 stop\n",
      "301 depend\n",
      "302 evalu\n",
      "303 sever\n",
      "304 refer\n",
      "305 predict\n",
      "306 some\n",
      "307 point\n",
      "308 current\n",
      "309 less\n",
      "310 suit\n",
      "311 factor\n",
      "312 rule\n",
      "313 graph\n",
      "314 common\n",
      "315 tree\n",
      "316 remov\n",
      "317 result\n",
      "318 here\n",
      "319 see\n",
      "320 select\n",
      "321 e g \n",
      "322 look\n",
      "323 randomli\n",
      "324 mitig\n",
      "325 over\n",
      "326 model\n",
      "327 the\n",
      "328 balanc\n",
      "329 abl\n",
      "330 cart\n",
      "331 replac\n",
      "332 prior\n",
      "333 could\n",
      "334 best\n",
      "335 let\n",
      "336 categor\n",
      "337 languag\n",
      "338 student\n",
      "339 differ\n",
      "340 term\n",
      "341 renew\n",
      "342 predictor\n",
      "343 outlier\n",
      "344 coin\n",
      "345 path\n",
      "346 branch\n",
      "347 girl\n",
      "348 similar\n",
      "349 give\n",
      "350 mani\n",
      "351 user\n",
      "352 hand\n",
      "353 effort\n",
      "354 compani\n",
      "355 made\n",
      "356 vs\n",
      "357 decis\n",
      "358 commonli\n",
      "359 supervis\n",
      "360 becaus\n",
      "361 support\n",
      "362 leisur\n",
      "363 come\n",
      "364 diagram\n",
      "365 deliber\n",
      "366 return\n",
      "367 hypothesi\n",
      "368 splitter\n",
      "369 unstabl\n",
      "370 rel\n",
      "371 priorit\n",
      "372 histor\n",
      "373 taken\n",
      "374 obtain\n",
      "375 help\n",
      "376 upsid\n",
      "377 borrow\n",
      "378 statist\n",
      "379 featur\n",
      "380 lose\n",
      "381 prefer\n",
      "382 mostli\n",
      "383 almost\n",
      "384 drawn\n",
      "385 primari\n",
      "386 node\n",
      "387 advantag\n",
      "388 intuit\n",
      "389 effect\n",
      "390 sale\n",
      "391 binari\n",
      "392 screen\n",
      "393 inform\n",
      "394 learn\n",
      "395 goal\n",
      "396 while\n",
      "397     \n",
      "398 budget\n",
      "399 e g\n",
      "400 els\n",
      "401 tune\n",
      "402 defin\n",
      "403 homogen\n",
      "404 rang\n",
      "405 domin\n",
      "406 outcom\n",
      "407 type\n",
      "408 mean\n",
      "409 possibl\n",
      "410 signific\n",
      "411 correspond\n",
      "412 both\n",
      "413 case\n",
      "414 util\n",
      "415 represent\n",
      "416 small\n",
      "417 leav\n",
      "418 greater\n",
      "419 tail\n",
      "420 hundr\n",
      "421 resourc\n",
      "422 leaf\n",
      "423 continu\n",
      "424 ye\n",
      "425 design\n",
      "426 know\n",
      "427 tree lik\n",
      "428 eas\n",
      "429 pharmaceut\n",
      "430 understand\n",
      "431 success\n",
      "432 identifi\n",
      "433 low\n",
      "434 opportun\n",
      "435 map\n",
      "436 plan\n",
      "437 greedi\n",
      "438 insur\n",
      "439 exampl\n",
      "440 stage\n",
      "441 top down\n",
      "442 target\n",
      "443 relationship\n",
      "444 influenc\n",
      "445 period\n",
      "446 consequ\n",
      "447 thu\n",
      "448 niklau\n",
      "449 independ\n",
      "450 busi\n",
      "451 valu\n",
      "452 random\n",
      "453 over complex\n",
      "454 simplic\n",
      "455 height\n",
      "456 termin\n",
      "457 now\n",
      "458 follow\n",
      "459 specif\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Distinct_Words)):\n",
    "    print (i,Distinct_Words[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_Count_matrix=np.empty(shape=(len(line),len(Distinct_Words)))\n",
    "word_Count_matrix.fill(0)\n",
    "\n",
    "for i in range(len(line)):\n",
    "    for j in range(len(line[i])):\n",
    "        for x in range(len(Distinct_Words)):\n",
    "            if (Distinct_Words[x]==line[i][j]):\n",
    "                word_Count_matrix[i][x] = word_Count_matrix[i][x] +1\n",
    "                continue\n",
    "                \n",
    "word_Count_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM_25_weight=np.empty(shape=(len(line),len(Distinct_Words)))\n",
    "BM_25_weight.fill(0)\n",
    "    \n",
    "    \n",
    "avg_length=np.mean(word_Count_matrix.sum(axis=1))\n",
    "    \n",
    "length_size=np.array(1.5*word_Count_matrix.sum(axis=1)/avg_length)\n",
    "    \n",
    "isf=np.array(np.log(len(line)/np.count_nonzero(word_Count_matrix,axis=0)))\n",
    "\n",
    "denominator=np.empty(shape=(len(line),len(Distinct_Words)))\n",
    "for i in range(len(line)):\n",
    "    denominator[i,:]=(word_Count_matrix[i,:]+length_size[i]+0.5)\n",
    "    \n",
    "BM_25_weight=(word_Count_matrix*isf)/(denominator)\n",
    "BM_25_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_weight=np.empty(shape=(len(line),len(Distinct_Words)))\n",
    "tfidf_weight.fill(0)\n",
    "\n",
    "tfidf_weight = word_Count_matrix*isf\n",
    "tfidf_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_binary_matrix=np.empty(shape=(len(line),len(Distinct_Words)))\n",
    "word_binary_matrix.fill(0)\n",
    "\n",
    "for i in range(len(line)):\n",
    "    for j in range(len(line[i])):\n",
    "        for x in range(len(Distinct_Words)):\n",
    "            if (Distinct_Words[x]==line[i][j]):\n",
    "                word_binary_matrix[i][x] = 1\n",
    "                continue\n",
    "word_binary_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Euclidean with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.09698036 0.22188399 ... 0.14395208 0.19859701 0.16649267]\n",
      " [0.09698036 1.         0.15848007 ... 0.11287815 0.16630175 0.16424629]\n",
      " [0.22188399 0.15848007 1.         ... 0.20945314 0.26859172 0.22354598]\n",
      " ...\n",
      " [0.14395208 0.11287815 0.20945314 ... 1.         0.21655412 0.17434256]\n",
      " [0.19859701 0.16630175 0.26859172 ... 0.21655412 1.         0.31453428]\n",
      " [0.16649267 0.16424629 0.22354598 ... 0.17434256 0.31453428 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "euclidean_bm25 =euclidean_distances(BM_25_weight)\n",
    "euclidean_bm25 = (1-(euclidean_bm25/np.max(euclidean_bm25)))\n",
    "print(euclidean_bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Cosine with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.07716111, ..., 0.00185534, 0.        ,\n",
       "        0.02179388],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.08534227],\n",
       "       [0.07716111, 0.        , 1.        , ..., 0.00309712, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.00185534, 0.        , 0.00309712, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.20468351],\n",
       "       [0.02179388, 0.08534227, 0.        , ..., 0.        , 0.20468351,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_bm25=np.empty(shape=(len(line),len(line)))\n",
    "\n",
    "for i in range(len(line)):\n",
    "    for j in range(len(line)):\n",
    "        dot_product = np.dot(BM_25_weight[i], BM_25_weight[j])\n",
    "        norm_i = np.linalg.norm(BM_25_weight[i])\n",
    "        norm_j = np.linalg.norm(BM_25_weight[j])\n",
    "        cosine_bm25[i, j] = dot_product/(norm_i*norm_j)\n",
    "cosine_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Euclidean with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.50875844 0.54453759 ... 0.49966453 0.56724457 0.54941814]\n",
      " [0.50875844 1.         0.63325454 ... 0.59779666 0.68650326 0.67134303]\n",
      " [0.54453759 0.63325454 1.         ... 0.62116027 0.71634312 0.68411107]\n",
      " ...\n",
      " [0.49966453 0.59779666 0.62116027 ... 1.         0.67178282 0.6435577 ]\n",
      " [0.56724457 0.68650326 0.71634312 ... 0.67178282 1.         0.77379396]\n",
      " [0.54941814 0.67134303 0.68411107 ... 0.6435577  0.77379396 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "euclidean_tfidf =euclidean_distances(tfidf_weight)\n",
    "euclidean_tfidf = (1-(euclidean_tfidf/np.max(euclidean_tfidf)))\n",
    "print(euclidean_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Cosine with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.08177021, ..., 0.00180392, 0.        ,\n",
       "        0.02162267],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.08534227],\n",
       "       [0.08177021, 0.        , 1.        , ..., 0.00303513, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.00180392, 0.        , 0.00303513, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.20468351],\n",
       "       [0.02162267, 0.08534227, 0.        , ..., 0.        , 0.20468351,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_tfidf=np.empty(shape=(len(line),len(line)))\n",
    "\n",
    "for i in range(len(line)):\n",
    "    for j in range(len(line)):\n",
    "        dot_product = np.dot(tfidf_weight[i], tfidf_weight[j])\n",
    "        norm_i = np.linalg.norm(tfidf_weight[i])\n",
    "        norm_j = np.linalg.norm(tfidf_weight[j])\n",
    "        cosine_tfidf[i, j] = dot_product/(norm_i*norm_j)\n",
    "cosine_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Euclidean with count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.52480904 0.58263499 ... 0.50486235 0.56745315 0.56005865]\n",
      " [0.52480904 1.         0.6407894  ... 0.61478954 0.72175666 0.71039515]\n",
      " [0.58263499 0.6407894  1.         ... 0.61478954 0.69946285 0.66882419]\n",
      " ...\n",
      " [0.50486235 0.61478954 0.61478954 ... 1.         0.66882419 0.6407894 ]\n",
      " [0.56745315 0.72175666 0.69946285 ... 0.66882419 1.         0.78748814]\n",
      " [0.56005865 0.71039515 0.66882419 ... 0.6407894  0.78748814 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "euclidean_count =euclidean_distances(word_Count_matrix)\n",
    "euclidean_count = (1-(euclidean_count/np.max(euclidean_count)))\n",
    "print(euclidean_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Cosine with count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.2956562 , ..., 0.05241424, 0.        ,\n",
       "        0.08006408],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.13608276],\n",
       "       [0.2956562 , 0.        , 1.        , ..., 0.0805823 , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.05241424, 0.        , 0.0805823 , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.23570226],\n",
       "       [0.08006408, 0.13608276, 0.        , ..., 0.        , 0.23570226,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_count=np.empty(shape=(len(line),len(line)))\n",
    "\n",
    "for i in range(len(line)):\n",
    "    for j in range(len(line)):\n",
    "        dot_product = np.dot(word_Count_matrix[i], word_Count_matrix[j])\n",
    "        norm_i = np.linalg.norm(word_Count_matrix[i])\n",
    "        norm_j = np.linalg.norm(word_Count_matrix[j])\n",
    "        cosine_count[i, j] = dot_product/(norm_i*norm_j)\n",
    "cosine_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Euclidean with binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.39595955 0.44249591 ... 0.39595955 0.4672864  0.45475024]\n",
      " [0.39595955 1.         0.48012476 ... 0.48012476 0.59730637 0.58086318]\n",
      " [0.44249591 0.48012476 1.         ... 0.48012476 0.56504116 0.52069871]\n",
      " ...\n",
      " [0.39595955 0.48012476 0.48012476 ... 1.         0.56504116 0.52069871]\n",
      " [0.4672864  0.59730637 0.56504116 ... 0.56504116 1.         0.69243766]\n",
      " [0.45475024 0.58086318 0.52069871 ... 0.52069871 0.69243766 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "euclidean_binary =euclidean_distances(word_binary_matrix)\n",
    "euclidean_binary = (1-(euclidean_binary/np.max(euclidean_binary)))\n",
    "print(euclidean_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Cosine with binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.21320072, ..., 0.07106691, 0.        ,\n",
       "        0.09622504],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.13608276],\n",
       "       [0.21320072, 0.        , 1.        , ..., 0.09090909, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.07106691, 0.        , 0.09090909, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.23570226],\n",
       "       [0.09622504, 0.13608276, 0.        , ..., 0.        , 0.23570226,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_binary=np.empty(shape=(len(line),len(line)))\n",
    "\n",
    "for i in range(len(line)):\n",
    "    for j in range(len(line)):\n",
    "        dot_product = np.dot(word_binary_matrix[i], word_binary_matrix[j])\n",
    "        norm_i = np.linalg.norm(word_binary_matrix[i])\n",
    "        norm_j = np.linalg.norm(word_binary_matrix[j])\n",
    "        cosine_binary[i, j] = dot_product/(norm_i*norm_j)\n",
    "cosine_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Jaccard with binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_jaccard(X):\n",
    "    \"\"\"Computes the Jaccard distance between the rows of `X`.\n",
    "    \"\"\"\n",
    "    X = X.astype(bool).astype(int)\n",
    "\n",
    "    intrsct = X.dot(X.T)\n",
    "    row_sums = intrsct.diagonal()\n",
    "    unions = row_sums[:,None] + row_sums - intrsct\n",
    "    dist = intrsct / unions\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.11538462 ... 0.03571429 0.         0.04347826]\n",
      " [0.         1.         0.         ... 0.         0.         0.07142857]\n",
      " [0.11538462 0.         1.         ... 0.04761905 0.         0.        ]\n",
      " ...\n",
      " [0.03571429 0.         0.04761905 ... 1.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         1.         0.125     ]\n",
      " [0.04347826 0.07142857 0.         ... 0.         0.125      1.        ]]\n"
     ]
    }
   ],
   "source": [
    "jaccard_binary = pairwise_jaccard(word_binary_matrix)\n",
    "print(jaccard_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,15):\n",
    "\n",
    "    knn = KNeighborsClassifier(i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    \n",
    "    train_scores.append(knn.score(X_train,y_train))\n",
    "    test_scores.append(knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attepmt for 20 kmeans clusters and agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=\"\"\n",
    "\n",
    "no_of_iteration=50\n",
    "n_clusters = int(np.ceil(len(line)**0.5))\n",
    "sentences_cluster_check=np.empty(shape=(len(line),len(line)))\n",
    "sse=[]\n",
    "iter_run=[]\n",
    "\n",
    "for i in range(no_of_iteration):\n",
    "    kmeans= (KMeans(n_clusters=n_clusters, random_state=i))\n",
    "    kmeans = kmeans.fit(cosine_bm25)\n",
    "#   storing everyweight in matrix\n",
    "\n",
    "    sse.append(kmeans.inertia_)\n",
    "    iter_run.append(kmeans.n_iter_)\n",
    "    for i in range(len(kmeans.labels_)):\n",
    "        for j in range(len(kmeans.labels_)):\n",
    "            if kmeans.labels_[i] == kmeans.labels_[j] and i!=j:\n",
    "                sentences_cluster_check[i][j]+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_k = list(range(no_of_iteration))\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(list_k, sse, '-o')\n",
    "plt.xlabel(r'Number of clusters *k*')\n",
    "plt.ylabel('Sum of squared distance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-11ea208c9262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_cluster_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'.2f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"YlGnBu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfigure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'svm_conf.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function install_repl_displayhook.<locals>.post_execute at 0x7f6b2a2bf170> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mpost_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mpost_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mdraw_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# IPython >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/_pylab_helpers.py\u001b[0m in \u001b[0;36mdraw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf_mgr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1912\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_cursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1707\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1709\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    716\u001b[0m                     textrenderer.draw_text(gc, x, y, clean_line,\n\u001b[1;32m    717\u001b[0m                                            \u001b[0mtextobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                                            ismath=ismath, mtext=mtext)\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw_text\u001b[0;34m(self, gc, x, y, s, prop, angle, ismath, mtext)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;31m# space) in the following call to draw_text_image).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_glyphs_to_bitmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mantialiased\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text.antialiased'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m64.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# The descent needs to be adjusted for the angle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f,ax = plt.subplots(figsize=(40, 40))\n",
    "fig=sns.heatmap(sentences_cluster_check, annot=True, linewidths=.5, fmt= '.2f', cmap=\"YlGnBu\")\n",
    "\n",
    "figure = fig.get_figure()    \n",
    "figure.savefig('sse.png', dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_clusters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-79cd5bea9d61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclosest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_clusters' is not defined"
     ]
    }
   ],
   "source": [
    "avg = []\n",
    "closest = []\n",
    "for j in range(n_clusters):\n",
    "    idx = np.where(kmeans.labels_ == j)[0]\n",
    "    avg.append(np.mean(idx))\n",
    "closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_,similarity_matrix)\n",
    "ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
    "summary = ' '.join([sentences[closest[idx]][0] for idx in ordering])\n",
    "return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 25 125\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_func(similarity_matrix):\n",
    "    summary=\"\"\n",
    "    n_clusters = int(np.ceil(len(similarity_matrix)**0.5))\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans = kmeans.fit(similarity_matrix)\n",
    "    avg = []\n",
    "    closest = []\n",
    "    for j in range(n_clusters):\n",
    "        idx = np.where(kmeans.labels_ == j)[0]\n",
    "        avg.append(np.mean(idx))\n",
    "    closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_,similarity_matrix)\n",
    "    ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
    "    summary = ' '.join([sentences[closest[idx]][0] for idx in ordering])\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## euclidean BM25 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 out of these 30 play cricket in leisure time. Advantages of Decision Tree:\n",
      "Easy to Understand: Decision tree output is very easy to understand even for people from non-analytical background. To identify the variable and the split, decision tree uses various algorithms. Repeat step 1 and step 2 on each subset until you find leaf nodes in all the branches of the tree. :- Let’s say we have a problem to predict whether a customer will pay his renewal premium with an insurance company (yes/ no). Decision Tree algorithms are referred to as CART (Classification and Regression Trees). It can be of two types:\n",
      "Categorical Variable Decision Tree: Decision Tree which has categorical target variable then it called as categorical variable decision tree. Less data cleaning required: It requires less data cleaning compared to some other modeling techniques. Over fitting is one of the most practical difficulty for decision tree models. This means that decision trees have no assumptions about the space distribution and the classifier structure. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mean value.\n"
     ]
    }
   ],
   "source": [
    "euclidean_BM25_summary=summary_func(euclidean_bm25)\n",
    "print(euclidean_BM25_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine BM25 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this problem, we need to segregate students who play cricket in their leisure time based on highly significant input variable among all three. Splitting: It is a process of dividing a node into two or more sub-nodes. E.g. We compare the values of the root attribute with record’s attribute. Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. For e.g., we are working on a problem where we have information available in hundreds of variables, there decision tree will help to identify most significant variable. If the values are continuous then they are discretized prior to building the model. This means that decision trees are typically drawn upside down such that leaves are the bottom & roots are the tops. It is known as ‘greedy’ because, the algorithm cares (looks for best variable available) about only the current split, and not about future splits which will lead to a better tree. In case of Classification Tree, the value (class) obtained by terminal node in the training data is the mode of observations falling in that region.\n"
     ]
    }
   ],
   "source": [
    "cosine_BM25_summary=summary_func(cosine_bm25)\n",
    "print(cosine_BM25_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## euclidean tfidf summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The possible solutions to a given problem emerge as the leaves of a tree, each node representing a point of deliberation and decision.”\n",
      "- Niklaus Wirth (1934 — ), Programming language designer\n",
      "Methods like decision trees, random forest, gradient boosting are being popularly used in all kinds of data science problems. Parent and Child Node: A node, which is divided into sub-nodes is called parent node of sub-nodes whereas sub-nodes are the child of parent node. Example applications include:\n",
      "· Evaluation of brand expansion opportunities for a business using historical sales data\n",
      "· Determination of likely buyers of a product using demographic data to enable targeting of limited advertisement budget\n",
      "· Prediction of likelihood of default for applicant borrowers using predictive models generated from historical data\n",
      "· Help with prioritization of emergency room patient treatment using a predictive model based on factors such as age, blood pressure, gender, location and severity of pain, and other measurements\n",
      "· Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal. Because of their simplicity, tree diagrams have been used in a broad range of industries and disciplines including civil planning, energy, financial, engineering, healthcare, pharmaceutical, education, law, and business. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). Each internal node of the tree corresponds to an attribute, and each leaf node corresponds to a class label. Now, as we know this is an important variable, then we can build a decision tree to predict customer income based on occupation, product and various other variables. It can also be used in data exploration stage. This is called variance, which needs to be lowered by methods like bagging and boosting. Decision trees implicitly perform variable screening or feature selection. For e.g.\n"
     ]
    }
   ],
   "source": [
    "euclidean_tfidf_summary=summary_func(euclidean_tfidf)\n",
    "print(euclidean_tfidf_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine tfidf summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Node: When a sub-node splits into further sub-nodes, then it is called decision node. Decision tree identifies the most significant variable and its value that gives best homogeneous sets of population. “The possible solutions to a given problem emerge as the leaves of a tree, each node representing a point of deliberation and decision.”\n",
      "- Niklaus Wirth (1934 — ), Programming language designer\n",
      "Methods like decision trees, random forest, gradient boosting are being popularly used in all kinds of data science problems. Types of Decision Trees\n",
      "Types of decision tree is based on the type of target variable we have. E.g. Not fit for continuous variables: While working with continuous numerical variables, decision tree loses information, when it categorizes variables in different categories. We compare the values of the root attribute with record’s attribute. The primary differences and similarities between Classification and Regression Trees are:\n",
      "Regression trees are used when dependent variable is continuous. Pruning is one of the technique used tackle overfitting. Decision trees require relatively little effort from users for data preparation. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mode value.\n"
     ]
    }
   ],
   "source": [
    "cosine_tfidf_summary=summary_func(cosine_tfidf)\n",
    "print(cosine_tfidf_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## euclidean count summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent and Child Node: A node, which is divided into sub-nodes is called parent node of sub-nodes whereas sub-nodes are the child of parent node. Example applications include:\n",
      "· Evaluation of brand expansion opportunities for a business using historical sales data\n",
      "· Determination of likely buyers of a product using demographic data to enable targeting of limited advertisement budget\n",
      "· Prediction of likelihood of default for applicant borrowers using predictive models generated from historical data\n",
      "· Help with prioritization of emergency room patient treatment using a predictive model based on factors such as age, blood pressure, gender, location and severity of pain, and other measurements\n",
      "· Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal. Each internal node of the tree corresponds to an attribute, and each leaf node corresponds to a class label. It can be of two types:\n",
      "Categorical Variable Decision Tree: Decision Tree which has categorical target variable then it called as categorical variable decision tree. :- Let’s say we have a problem to predict whether a customer will pay his renewal premium with an insurance company (yes/ no). Advantages of Decision Tree:\n",
      "Easy to Understand: Decision tree output is very easy to understand even for people from non-analytical background. It does not require any statistical knowledge to read and interpret them. Decision tree learners create biased trees if some classes dominate. Unlike linear models, they map non-linear relationships quite well. YES or NO. Applications for Decision Tree - Decision trees have a natural “if … then … else …” construction that makes it fit easily into a programmatic structure.\n"
     ]
    }
   ],
   "source": [
    "euclidean_count_summary=summary_func(euclidean_count)\n",
    "print(euclidean_count_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine count summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent and Child Node: A node, which is divided into sub-nodes is called parent node of sub-nodes whereas sub-nodes are the child of parent node. In this problem, we need to segregate students who play cricket in their leisure time based on highly significant input variable among all three. A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. Records are distributed recursively on the basis of attribute values. With the help of decision trees, we can create new variables / features that has better power to predict target variable. Decision tree learners create biased trees if some classes dominate. YES or NO. E.g. Both the trees follow a top-down greedy approach known as recursive binary splitting. It can also be used in data exploration stage. In case of Regression Tree, the value obtained by terminal nodes in the training data is the mean response of observation falling in that region.\n"
     ]
    }
   ],
   "source": [
    "cosine_count_summary=summary_func(cosine_count)\n",
    "print(cosine_count_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## euclidean binary summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. “The possible solutions to a given problem emerge as the leaves of a tree, each node representing a point of deliberation and decision.”\n",
      "- Niklaus Wirth (1934 — ), Programming language designer\n",
      "Methods like decision trees, random forest, gradient boosting are being popularly used in all kinds of data science problems. Example applications include:\n",
      "· Evaluation of brand expansion opportunities for a business using historical sales data\n",
      "· Determination of likely buyers of a product using demographic data to enable targeting of limited advertisement budget\n",
      "· Prediction of likelihood of default for applicant borrowers using predictive models generated from historical data\n",
      "· Help with prioritization of emergency room patient treatment using a predictive model based on factors such as age, blood pressure, gender, location and severity of pain, and other measurements\n",
      "· Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal. Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. In this technique, we split the population or sample into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables. Can also handle multi-output problems. Greedy algorithms cannot guarantee to return the globally optimal decision tree. Its graphical representation is very intuitive and users can easily relate their hypothesis. In case of Classification Tree, the value (class) obtained by terminal node in the training data is the mode of observations falling in that region. YES or NO. Advantages of Decision Tree:\n",
      "Easy to Understand: Decision tree output is very easy to understand even for people from non-analytical background.\n"
     ]
    }
   ],
   "source": [
    "euclidean_binary_summary=summary_func(euclidean_binary)\n",
    "print(euclidean_binary_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine binary summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaf/ Terminal Node: Nodes do not split is called Leaf or Terminal node. :- In above scenario of student problem, where the target variable was “Student will play cricket or not” i.e. Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. Its graphical representation is very intuitive and users can easily relate their hypothesis. Each internal node of the tree corresponds to an attribute, and each leaf node corresponds to a class label. Decision trees implicitly perform variable screening or feature selection. Decision tree learners create biased trees if some classes dominate. E.g. Records are distributed recursively on the basis of attribute values. Both the trees follow a top-down greedy approach known as recursive binary splitting. This bring ‘pruning’.\n"
     ]
    }
   ],
   "source": [
    "cosine_binary_summary=summary_func(cosine_binary)\n",
    "print(cosine_binary_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jaccard binary summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each internal node of the tree corresponds to an attribute, and each leaf node corresponds to a class label. 15 out of these 30 play cricket in leisure time. Splitting: It is a process of dividing a node into two or more sub-nodes. Decision Tree algorithms are referred to as CART (Classification and Regression Trees). Records are distributed recursively on the basis of attribute values. Data type is not a constraint: It can handle both numerical and categorical variables. Types of Decision Trees\n",
      "Types of decision tree is based on the type of target variable we have. This problem gets solved by setting constraints on model parameters and pruning. E.g. Applications for Decision Tree - Decision trees have a natural “if … then … else …” construction that makes it fit easily into a programmatic structure. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mean value.\n"
     ]
    }
   ],
   "source": [
    "jaccard_binary_summary=summary_func(jaccard_binary)\n",
    "print(jaccard_binary_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=open(file_name[0]+\"_summary.\"+file_name[1],\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.write(\"euclidean BM25 summary\\n\\n\"+euclidean_BM25_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n cosine BM25 summary \\n\\n\"+cosine_BM25_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n euclidean tfidf summary \\n\\n\"+euclidean_tfidf_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n cosine tfidf summary \\n\\n\"+cosine_tfidf_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n euclidean count summary \\n\\n\"+euclidean_count_summary +\"\\n\\n\\n\\n\\n\\n\\n\\n cosine count summary \\n\\n\"+cosine_count_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n euclidean binary summary \\n\\n\"+euclidean_binary_summary +\"\\n\\n\\n\\n\\n\\n\\n\\n cosine binary summary \\n\\n\"+cosine_binary_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n jaccard binary summary \\n\\n\"+jaccard_binary_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n\"+data[0])\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
