{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Module for E-mail Summarization\n",
    "*****************************************************************************\n",
    "Input Parameters:\n",
    "    emails: A list of strings containing the emails\n",
    "Returns:\n",
    "    summary: A list of strings containing the summaries.\n",
    "*****************************************************************************\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ***************************************************************************\n",
    "import numpy as np\n",
    "from talon.signature.bruteforce import extract_signature\n",
    "from langdetect import detect\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import skipthoughts\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "# ***************************************************************************\n",
    "\n",
    "\n",
    "def preprocess(emails):\n",
    "    \"\"\"\n",
    "    Performs preprocessing operations such as:\n",
    "        1. Removing signature lines (only English emails are supported)\n",
    "        2. Removing new line characters.\n",
    "    \"\"\"\n",
    "    n_emails = len(emails)\n",
    "    for i in range(n_emails):\n",
    "        email = emails[i]\n",
    "        email, _ = extract_signature(email)\n",
    "        lines = email.split('\\n')\n",
    "        for j in reversed(range(len(lines))):\n",
    "            lines[j] = lines[j].strip()\n",
    "            if lines[j] == '':\n",
    "                lines.pop(j)\n",
    "        emails[i] = ' '.join(lines)\n",
    "        \n",
    "        \n",
    "def split_sentences(emails):\n",
    "    \"\"\"\n",
    "    Splits the emails into individual sentences\n",
    "    \"\"\"\n",
    "    n_emails = len(emails)\n",
    "    for i in range(n_emails):\n",
    "        email = emails[i]\n",
    "        sentences = sent_tokenize(email)\n",
    "        for j in reversed(range(len(sentences))):\n",
    "            sent = sentences[j]\n",
    "            sentences[j] = sent.strip()\n",
    "            if sent == '':\n",
    "                sentences.pop(j)\n",
    "        emails[i] = sentences\n",
    "        \n",
    "        \n",
    "def skipthought_encode(emails):\n",
    "    \"\"\"\n",
    "    Obtains sentence embeddings for each sentence in the emails\n",
    "    \"\"\"\n",
    "    enc_emails = [None]*len(emails)\n",
    "    cum_sum_sentences = [0]\n",
    "    sent_count = 0\n",
    "    for email in emails:\n",
    "        sent_count += len(email)\n",
    "        cum_sum_sentences.append(sent_count)\n",
    "\n",
    "    all_sentences = [sent for email in emails for sent in email]\n",
    "    print('Loading pre-trained models...')\n",
    "    model = skipthoughts.load_model()\n",
    "    encoder = skipthoughts.Encoder(model)\n",
    "    print('Encoding sentences...')\n",
    "    enc_sentences = encoder.encode(all_sentences, verbose=False)\n",
    "\n",
    "    for i in range(len(emails)):\n",
    "        begin = cum_sum_sentences[i]\n",
    "        end = cum_sum_sentences[i+1]\n",
    "        enc_emails[i] = enc_sentences[begin:end]\n",
    "    return enc_emails\n",
    "        \n",
    "    \n",
    "def summarize(emails):\n",
    "    \"\"\"\n",
    "    Performs summarization of emails\n",
    "    \"\"\"\n",
    "    n_emails = len(emails)\n",
    "    print( \"number of emails = \" ,n_emails )\n",
    "    \n",
    "    summary = [None]*n_emails\n",
    "    print(summary)\n",
    "    print('Preprecesing...')\n",
    "    preprocess(emails)\n",
    "    print(\"preprocessed emails\\n\\n\",emails)\n",
    "    print('Splitting into sentences...')\n",
    "    split_sentences(emails)\n",
    "    \n",
    "    print(\"\\n\\n split emails\\n\\n\",emails)\n",
    "    print('Starting to encode...')\n",
    "    enc_emails = skipthought_encode(emails)\n",
    "    print('Encoding Finished')\n",
    "    for i in range(n_emails):\n",
    "        enc_email = enc_emails[i]\n",
    "        n_clusters = int(np.ceil(len(enc_email)**0.5))\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "        kmeans = kmeans.fit(enc_email)\n",
    "        avg = []\n",
    "        closest = []\n",
    "        for j in range(n_clusters):\n",
    "            idx = np.where(kmeans.labels_ == j)[0]\n",
    "            avg.append(np.mean(idx))\n",
    "        closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_,\\\n",
    "                                                   enc_email)\n",
    "        ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
    "        summary[i] = ' '.join([sentences[closest[idx]] for idx in ordering])\n",
    "    print('Clustering Finished')\n",
    "    return summary\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mail= \"Hi Jane,Thank you for keeping me updated on this issue. I'm happy to hear that the issue got resolved after all and you can now use the app in its full functionality again. Also many thanks for your suggestions. We hope to improve this feature in the future. In case you experience any further problems with the app, please don't hesitate to contact me again. Best regards, John DoeCustomer Support 1600 Amphitheatre Parkway Mountain View, CA United States\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[mail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of emails =  1\n",
      "[None]\n",
      "Preprecesing...\n",
      "preprocessed emails\n",
      "\n",
      " [\"Hi Jane,Thank you for keeping me updated on this issue. I'm happy to hear that the issue got resolved after all and you can now use the app in its full functionality again. Also many thanks for your suggestions. We hope to improve this feature in the future. In case you experience any further problems with the app, please don't hesitate to contact me again. Best regards, John DoeCustomer Support 1600 Amphitheatre Parkway Mountain View, CA United States\"]\n",
      "Splitting into sentences...\n",
      "\n",
      "\n",
      " split emails\n",
      "\n",
      " [['Hi Jane,Thank you for keeping me updated on this issue.', \"I'm happy to hear that the issue got resolved after all and you can now use the app in its full functionality again.\", 'Also many thanks for your suggestions.', 'We hope to improve this feature in the future.', \"In case you experience any further problems with the app, please don't hesitate to contact me again.\", 'Best regards, John DoeCustomer Support 1600 Amphitheatre Parkway Mountain View, CA United States']]\n",
      "Starting to encode...\n",
      "Loading pre-trained models...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'skipthoughts' has no attribute 'load_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1104d3b78d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-3e2986e9ef8f>\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(emails)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n split emails\\n\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting to encode...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0menc_emails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskipthought_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Encoding Finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_emails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-3e2986e9ef8f>\u001b[0m in \u001b[0;36mskipthought_encode\u001b[0;34m(emails)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mall_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msent\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0memail\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memails\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memail\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading pre-trained models...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskipthoughts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskipthoughts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Encoding sentences...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'skipthoughts' has no attribute 'load_model'"
     ]
    }
   ],
   "source": [
    "summarize(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
