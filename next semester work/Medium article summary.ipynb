{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.summarization.bm25 import get_bm25_weights\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords \n",
    "import sklearn\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min,jaccard_similarity_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cosu, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"a.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=f.name\n",
    "file_name=filename.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.\n",
      "A decision tree is a flowchart-like structure in which each internal node represents a “test” on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.\n",
      "Tree based learning algorithms are considered to be one of the best and mostly used supervised learning methods. Tree based methods empower predictive models with high accuracy, stability and ease of interpretation. Unlike linear models, they map non-linear relationships quite well. They are adaptable at solving any kind of problem at hand (classification or regression). Decision Tree algorithms are referred to as CART (Classification and Regression Trees).\n",
      "“The possible solutions to a given problem emerge as the leaves of a tree, each node representing a point of deliberation and decision.”\n",
      "- Niklaus Wirth (1934 — ), Programming language designer\n",
      "Methods like decision trees, random forest, gradient boosting are being popularly used in all kinds of data science problems. Common terms used with Decision trees:\n",
      "Root Node: It represents entire population or sample and this further gets divided into two or more homogeneous sets.\n",
      "Splitting: It is a process of dividing a node into two or more sub-nodes.\n",
      "Decision Node: When a sub-node splits into further sub-nodes, then it is called decision node.\n",
      "Leaf/ Terminal Node: Nodes do not split is called Leaf or Terminal node.\n",
      "Pruning: When we remove sub-nodes of a decision node, this process is called pruning. You can say opposite process of splitting.\n",
      "Branch / Sub-Tree: A sub section of entire tree is called branch or sub-tree.\n",
      "Parent and Child Node: A node, which is divided into sub-nodes is called parent node of sub-nodes whereas sub-nodes are the child of parent node.\n",
      "Applications for Decision Tree - Decision trees have a natural “if … then … else …” construction that makes it fit easily into a programmatic structure. They also are well suited to categorization problems where attributes or features are systematically checked to determine a final category. For example, a decision tree could be used effectively to determine the species of an animal.\n",
      "As a result, the decision making tree is one of the more popular classification algorithms being used in Data Mining and Machine Learning. Example applications include:\n",
      "· Evaluation of brand expansion opportunities for a business using historical sales data\n",
      "· Determination of likely buyers of a product using demographic data to enable targeting of limited advertisement budget\n",
      "· Prediction of likelihood of default for applicant borrowers using predictive models generated from historical data\n",
      "· Help with prioritization of emergency room patient treatment using a predictive model based on factors such as age, blood pressure, gender, location and severity of pain, and other measurements\n",
      "· Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal.\n",
      "Because of their simplicity, tree diagrams have been used in a broad range of industries and disciplines including civil planning, energy, financial, engineering, healthcare, pharmaceutical, education, law, and business.\n",
      "How does Decision Tree works ?\n",
      "Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input and output variables. In this technique, we split the population or sample into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables.\n",
      "Example:-\n",
      "Let’s say we have a sample of 30 students with three variables Gender (Boy/ Girl), Class (IX/ X) and Height (5 to 6 ft). 15 out of these 30 play cricket in leisure time. Now, we want to create a model to predict who will play cricket during leisure period? In this problem, we need to segregate students who play cricket in their leisure time based on highly significant input variable among all three.\n",
      "This is where decision tree helps, it will segregate the students based on all values of three variable and identify the variable, which creates the best homogeneous sets of students (which are heterogeneous to each other). In the snapshot below, you can see that variable Gender is able to identify best homogeneous sets compared to the other two variables.\n",
      "Decision tree identifies the most significant variable and its value that gives best homogeneous sets of population. To identify the variable and the split, decision tree uses various algorithms.\n",
      "Types of Decision Trees\n",
      "Types of decision tree is based on the type of target variable we have. It can be of two types:\n",
      "Categorical Variable Decision Tree: Decision Tree which has categorical target variable then it called as categorical variable decision tree. E.g.:- In above scenario of student problem, where the target variable was “Student will play cricket or not” i.e. YES or NO.\n",
      "Continuous Variable Decision Tree: Decision Tree has continuous target variable then it is called as Continuous Variable Decision Tree.\n",
      "E.g.:- Let’s say we have a problem to predict whether a customer will pay his renewal premium with an insurance company (yes/ no). Here we know that income of customer is a significant variable but insurance company does not have income details for all customers. Now, as we know this is an important variable, then we can build a decision tree to predict customer income based on occupation, product and various other variables. In this case, we are predicting values for continuous variable.\n",
      "The decision tree algorithm tries to solve the problem, by using tree representation. Each internal node of the tree corresponds to an attribute, and each leaf node corresponds to a class label.\n",
      "Place the best attribute of the dataset at the root of the tree.\n",
      "Split the training set into subsets. Subsets should be made in such a way that each subset contains data with the same value for an attribute.\n",
      "Repeat step 1 and step 2 on each subset until you find leaf nodes in all the branches of the tree.\n",
      "In decision trees, for predicting a class label for a record we start from the root of the tree. We compare the values of the root attribute with record’s attribute. On the basis of comparison, we follow the branch corresponding to that value and jump to the next node.\n",
      "We continue comparing our record’s attribute values with other internal nodes of the tree until we reach a leaf node with predicted class value. The modeled decision tree can be used to predict the target class or the value.\n",
      "Assumptions while creating Decision Tree\n",
      "Some of the assumptions we make while using Decision tree:\n",
      "At the beginning, the whole training set is considered as the root.\n",
      "Feature values are preferred to be categorical. If the values are continuous then they are discretized prior to building the model.\n",
      "Records are distributed recursively on the basis of attribute values.\n",
      "Order to placing attributes as root or internal node of the tree is done by using some statistical approach.\n",
      "Advantages of Decision Tree:\n",
      "Easy to Understand: Decision tree output is very easy to understand even for people from non-analytical background. It does not require any statistical knowledge to read and interpret them. Its graphical representation is very intuitive and users can easily relate their hypothesis.\n",
      "Useful in Data exploration: Decision tree is one of the fastest way to identify most significant variables and relation between two or more variables. With the help of decision trees, we can create new variables / features that has better power to predict target variable. It can also be used in data exploration stage. For e.g., we are working on a problem where we have information available in hundreds of variables, there decision tree will help to identify most significant variable.\n",
      "Decision trees implicitly perform variable screening or feature selection.\n",
      "Decision trees require relatively little effort from users for data preparation.\n",
      "Less data cleaning required: It requires less data cleaning compared to some other modeling techniques. It is not influenced by outliers and missing values to a fair degree.\n",
      "Data type is not a constraint: It can handle both numerical and categorical variables. Can also handle multi-output problems.\n",
      "Non-Parametric Method: Decision tree is considered to be a non-parametric method. This means that decision trees have no assumptions about the space distribution and the classifier structure.\n",
      "Non-linear relationships between parameters do not affect tree performance.\n",
      "The number of hyper-parameters to be tuned is almost null.\n",
      "Disadvantages of Decision Tree:\n",
      "Over fitting: Decision-tree learners can create over-complex trees that do not generalize the data well. This is called overfitting. Over fitting is one of the most practical difficulty for decision tree models. This problem gets solved by setting constraints on model parameters and pruning.\n",
      "Not fit for continuous variables: While working with continuous numerical variables, decision tree loses information, when it categorizes variables in different categories.\n",
      "Decision trees can be unstable because small variations in the data might result in a completely different tree being generated. This is called variance, which needs to be lowered by methods like bagging and boosting.\n",
      "Greedy algorithms cannot guarantee to return the globally optimal decision tree. This can be mitigated by training multiple trees, where the features and samples are randomly sampled with replacement.\n",
      "Decision tree learners create biased trees if some classes dominate. It is therefore recommended to balance the data set prior to fitting with the decision tree.\n",
      "Information gain in a decision tree with categorical variables gives a biased response for attributes with greater no. of categories.\n",
      "Generally, it gives low prediction accuracy for a dataset as compared to other machine learning algorithms.\n",
      "Calculations can become complex when there are many class label.\n",
      "Regression Trees vs Classification Trees\n",
      "The terminal nodes (or leaves) lies at the bottom of the decision tree. This means that decision trees are typically drawn upside down such that leaves are the bottom & roots are the tops.\n",
      "Both the trees work almost similar to each other. The primary differences and similarities between Classification and Regression Trees are:\n",
      "Regression trees are used when dependent variable is continuous. Classification Trees are used when dependent variable is categorical.\n",
      "In case of Regression Tree, the value obtained by terminal nodes in the training data is the mean response of observation falling in that region. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mean value.\n",
      "In case of Classification Tree, the value (class) obtained by terminal node in the training data is the mode of observations falling in that region. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mode value.\n",
      "Both the trees divide the predictor space (independent variables) into distinct and non-overlapping regions.\n",
      "Both the trees follow a top-down greedy approach known as recursive binary splitting. We call it as ‘top-down’ because it begins from the top of tree when all the observations are available in a single region and successively splits the predictor space into two new branches down the tree. It is known as ‘greedy’ because, the algorithm cares (looks for best variable available) about only the current split, and not about future splits which will lead to a better tree.\n",
      "This splitting process is continued until a user defined stopping criteria is reached. For e.g.: we can tell the algorithm to stop once the number of observations per node becomes less than 50.\n",
      "In both the cases, the splitting process results in fully grown trees until the stopping criteria is reached. But, the fully grown tree is likely to over fit data, leading to poor accuracy on unseen data. This bring ‘pruning’. Pruning is one of the technique used tackle overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=(f.read())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "for s in data:\n",
    "    sentences.append(sent_tokenize(s))\n",
    "sentences = [[y] for x in sentences for y in x] # flatten list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'a',\n",
       "  'decision',\n",
       "  'support',\n",
       "  'tool',\n",
       "  'that',\n",
       "  'uses',\n",
       "  'a',\n",
       "  'tree-like',\n",
       "  'graph',\n",
       "  'or',\n",
       "  'model',\n",
       "  'of',\n",
       "  'decisions',\n",
       "  'and',\n",
       "  'their',\n",
       "  'possible',\n",
       "  'consequences',\n",
       "  ',',\n",
       "  'including',\n",
       "  'chance',\n",
       "  'event',\n",
       "  'outcomes',\n",
       "  ',',\n",
       "  'resource',\n",
       "  'costs',\n",
       "  ',',\n",
       "  'and',\n",
       "  'utility',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'is',\n",
       "  'one',\n",
       "  'way',\n",
       "  'to',\n",
       "  'display',\n",
       "  'an',\n",
       "  'algorithm',\n",
       "  'that',\n",
       "  'only',\n",
       "  'contains',\n",
       "  'conditional',\n",
       "  'control',\n",
       "  'statements',\n",
       "  '.'],\n",
       " ['A',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'a',\n",
       "  'flowchart-like',\n",
       "  'structure',\n",
       "  'in',\n",
       "  'which',\n",
       "  'each',\n",
       "  'internal',\n",
       "  'node',\n",
       "  'represents',\n",
       "  'a',\n",
       "  '“',\n",
       "  'test',\n",
       "  '”',\n",
       "  'on',\n",
       "  'an',\n",
       "  'attribute',\n",
       "  '(',\n",
       "  'e.g',\n",
       "  '.'],\n",
       " ['whether',\n",
       "  'a',\n",
       "  'coin',\n",
       "  'flip',\n",
       "  'comes',\n",
       "  'up',\n",
       "  'heads',\n",
       "  'or',\n",
       "  'tails',\n",
       "  ')',\n",
       "  ',',\n",
       "  'each',\n",
       "  'branch',\n",
       "  'represents',\n",
       "  'the',\n",
       "  'outcome',\n",
       "  'of',\n",
       "  'the',\n",
       "  'test',\n",
       "  ',',\n",
       "  'and',\n",
       "  'each',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'represents',\n",
       "  'a',\n",
       "  'class',\n",
       "  'label',\n",
       "  '(',\n",
       "  'decision',\n",
       "  'taken',\n",
       "  'after',\n",
       "  'computing',\n",
       "  'all',\n",
       "  'attributes',\n",
       "  ')',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'paths',\n",
       "  'from',\n",
       "  'root',\n",
       "  'to',\n",
       "  'leaf',\n",
       "  'represent',\n",
       "  'classification',\n",
       "  'rules',\n",
       "  '.'],\n",
       " ['Tree',\n",
       "  'based',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  'are',\n",
       "  'considered',\n",
       "  'to',\n",
       "  'be',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'best',\n",
       "  'and',\n",
       "  'mostly',\n",
       "  'used',\n",
       "  'supervised',\n",
       "  'learning',\n",
       "  'methods',\n",
       "  '.'],\n",
       " ['Tree',\n",
       "  'based',\n",
       "  'methods',\n",
       "  'empower',\n",
       "  'predictive',\n",
       "  'models',\n",
       "  'with',\n",
       "  'high',\n",
       "  'accuracy',\n",
       "  ',',\n",
       "  'stability',\n",
       "  'and',\n",
       "  'ease',\n",
       "  'of',\n",
       "  'interpretation',\n",
       "  '.'],\n",
       " ['Unlike',\n",
       "  'linear',\n",
       "  'models',\n",
       "  ',',\n",
       "  'they',\n",
       "  'map',\n",
       "  'non-linear',\n",
       "  'relationships',\n",
       "  'quite',\n",
       "  'well',\n",
       "  '.'],\n",
       " ['They',\n",
       "  'are',\n",
       "  'adaptable',\n",
       "  'at',\n",
       "  'solving',\n",
       "  'any',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'problem',\n",
       "  'at',\n",
       "  'hand',\n",
       "  '(',\n",
       "  'classification',\n",
       "  'or',\n",
       "  'regression',\n",
       "  ')',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'Tree',\n",
       "  'algorithms',\n",
       "  'are',\n",
       "  'referred',\n",
       "  'to',\n",
       "  'as',\n",
       "  'CART',\n",
       "  '(',\n",
       "  'Classification',\n",
       "  'and',\n",
       "  'Regression',\n",
       "  'Trees',\n",
       "  ')',\n",
       "  '.'],\n",
       " ['“',\n",
       "  'The',\n",
       "  'possible',\n",
       "  'solutions',\n",
       "  'to',\n",
       "  'a',\n",
       "  'given',\n",
       "  'problem',\n",
       "  'emerge',\n",
       "  'as',\n",
       "  'the',\n",
       "  'leaves',\n",
       "  'of',\n",
       "  'a',\n",
       "  'tree',\n",
       "  ',',\n",
       "  'each',\n",
       "  'node',\n",
       "  'representing',\n",
       "  'a',\n",
       "  'point',\n",
       "  'of',\n",
       "  'deliberation',\n",
       "  'and',\n",
       "  'decision.',\n",
       "  '”',\n",
       "  '-',\n",
       "  'Niklaus',\n",
       "  'Wirth',\n",
       "  '(',\n",
       "  '1934',\n",
       "  '—',\n",
       "  ')',\n",
       "  ',',\n",
       "  'Programming',\n",
       "  'language',\n",
       "  'designer',\n",
       "  'Methods',\n",
       "  'like',\n",
       "  'decision',\n",
       "  'trees',\n",
       "  ',',\n",
       "  'random',\n",
       "  'forest',\n",
       "  ',',\n",
       "  'gradient',\n",
       "  'boosting',\n",
       "  'are',\n",
       "  'being',\n",
       "  'popularly',\n",
       "  'used',\n",
       "  'in',\n",
       "  'all',\n",
       "  'kinds',\n",
       "  'of',\n",
       "  'data',\n",
       "  'science',\n",
       "  'problems',\n",
       "  '.'],\n",
       " ['Common',\n",
       "  'terms',\n",
       "  'used',\n",
       "  'with',\n",
       "  'Decision',\n",
       "  'trees',\n",
       "  ':',\n",
       "  'Root',\n",
       "  'Node',\n",
       "  ':',\n",
       "  'It',\n",
       "  'represents',\n",
       "  'entire',\n",
       "  'population',\n",
       "  'or',\n",
       "  'sample',\n",
       "  'and',\n",
       "  'this',\n",
       "  'further',\n",
       "  'gets',\n",
       "  'divided',\n",
       "  'into',\n",
       "  'two',\n",
       "  'or',\n",
       "  'more',\n",
       "  'homogeneous',\n",
       "  'sets',\n",
       "  '.'],\n",
       " ['Splitting',\n",
       "  ':',\n",
       "  'It',\n",
       "  'is',\n",
       "  'a',\n",
       "  'process',\n",
       "  'of',\n",
       "  'dividing',\n",
       "  'a',\n",
       "  'node',\n",
       "  'into',\n",
       "  'two',\n",
       "  'or',\n",
       "  'more',\n",
       "  'sub-nodes',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'Node',\n",
       "  ':',\n",
       "  'When',\n",
       "  'a',\n",
       "  'sub-node',\n",
       "  'splits',\n",
       "  'into',\n",
       "  'further',\n",
       "  'sub-nodes',\n",
       "  ',',\n",
       "  'then',\n",
       "  'it',\n",
       "  'is',\n",
       "  'called',\n",
       "  'decision',\n",
       "  'node',\n",
       "  '.'],\n",
       " ['Leaf/',\n",
       "  'Terminal',\n",
       "  'Node',\n",
       "  ':',\n",
       "  'Nodes',\n",
       "  'do',\n",
       "  'not',\n",
       "  'split',\n",
       "  'is',\n",
       "  'called',\n",
       "  'Leaf',\n",
       "  'or',\n",
       "  'Terminal',\n",
       "  'node',\n",
       "  '.'],\n",
       " ['Pruning',\n",
       "  ':',\n",
       "  'When',\n",
       "  'we',\n",
       "  'remove',\n",
       "  'sub-nodes',\n",
       "  'of',\n",
       "  'a',\n",
       "  'decision',\n",
       "  'node',\n",
       "  ',',\n",
       "  'this',\n",
       "  'process',\n",
       "  'is',\n",
       "  'called',\n",
       "  'pruning',\n",
       "  '.'],\n",
       " ['You', 'can', 'say', 'opposite', 'process', 'of', 'splitting', '.'],\n",
       " ['Branch',\n",
       "  '/',\n",
       "  'Sub-Tree',\n",
       "  ':',\n",
       "  'A',\n",
       "  'sub',\n",
       "  'section',\n",
       "  'of',\n",
       "  'entire',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'called',\n",
       "  'branch',\n",
       "  'or',\n",
       "  'sub-tree',\n",
       "  '.'],\n",
       " ['Parent',\n",
       "  'and',\n",
       "  'Child',\n",
       "  'Node',\n",
       "  ':',\n",
       "  'A',\n",
       "  'node',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'divided',\n",
       "  'into',\n",
       "  'sub-nodes',\n",
       "  'is',\n",
       "  'called',\n",
       "  'parent',\n",
       "  'node',\n",
       "  'of',\n",
       "  'sub-nodes',\n",
       "  'whereas',\n",
       "  'sub-nodes',\n",
       "  'are',\n",
       "  'the',\n",
       "  'child',\n",
       "  'of',\n",
       "  'parent',\n",
       "  'node',\n",
       "  '.'],\n",
       " ['Applications',\n",
       "  'for',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  '-',\n",
       "  'Decision',\n",
       "  'trees',\n",
       "  'have',\n",
       "  'a',\n",
       "  'natural',\n",
       "  '“',\n",
       "  'if',\n",
       "  '…',\n",
       "  'then',\n",
       "  '…',\n",
       "  'else',\n",
       "  '…',\n",
       "  '”',\n",
       "  'construction',\n",
       "  'that',\n",
       "  'makes',\n",
       "  'it',\n",
       "  'fit',\n",
       "  'easily',\n",
       "  'into',\n",
       "  'a',\n",
       "  'programmatic',\n",
       "  'structure',\n",
       "  '.'],\n",
       " ['They',\n",
       "  'also',\n",
       "  'are',\n",
       "  'well',\n",
       "  'suited',\n",
       "  'to',\n",
       "  'categorization',\n",
       "  'problems',\n",
       "  'where',\n",
       "  'attributes',\n",
       "  'or',\n",
       "  'features',\n",
       "  'are',\n",
       "  'systematically',\n",
       "  'checked',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'a',\n",
       "  'final',\n",
       "  'category',\n",
       "  '.'],\n",
       " ['For',\n",
       "  'example',\n",
       "  ',',\n",
       "  'a',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'could',\n",
       "  'be',\n",
       "  'used',\n",
       "  'effectively',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'the',\n",
       "  'species',\n",
       "  'of',\n",
       "  'an',\n",
       "  'animal',\n",
       "  '.'],\n",
       " ['As',\n",
       "  'a',\n",
       "  'result',\n",
       "  ',',\n",
       "  'the',\n",
       "  'decision',\n",
       "  'making',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'more',\n",
       "  'popular',\n",
       "  'classification',\n",
       "  'algorithms',\n",
       "  'being',\n",
       "  'used',\n",
       "  'in',\n",
       "  'Data',\n",
       "  'Mining',\n",
       "  'and',\n",
       "  'Machine',\n",
       "  'Learning',\n",
       "  '.'],\n",
       " ['Example',\n",
       "  'applications',\n",
       "  'include',\n",
       "  ':',\n",
       "  '·',\n",
       "  'Evaluation',\n",
       "  'of',\n",
       "  'brand',\n",
       "  'expansion',\n",
       "  'opportunities',\n",
       "  'for',\n",
       "  'a',\n",
       "  'business',\n",
       "  'using',\n",
       "  'historical',\n",
       "  'sales',\n",
       "  'data',\n",
       "  '·',\n",
       "  'Determination',\n",
       "  'of',\n",
       "  'likely',\n",
       "  'buyers',\n",
       "  'of',\n",
       "  'a',\n",
       "  'product',\n",
       "  'using',\n",
       "  'demographic',\n",
       "  'data',\n",
       "  'to',\n",
       "  'enable',\n",
       "  'targeting',\n",
       "  'of',\n",
       "  'limited',\n",
       "  'advertisement',\n",
       "  'budget',\n",
       "  '·',\n",
       "  'Prediction',\n",
       "  'of',\n",
       "  'likelihood',\n",
       "  'of',\n",
       "  'default',\n",
       "  'for',\n",
       "  'applicant',\n",
       "  'borrowers',\n",
       "  'using',\n",
       "  'predictive',\n",
       "  'models',\n",
       "  'generated',\n",
       "  'from',\n",
       "  'historical',\n",
       "  'data',\n",
       "  '·',\n",
       "  'Help',\n",
       "  'with',\n",
       "  'prioritization',\n",
       "  'of',\n",
       "  'emergency',\n",
       "  'room',\n",
       "  'patient',\n",
       "  'treatment',\n",
       "  'using',\n",
       "  'a',\n",
       "  'predictive',\n",
       "  'model',\n",
       "  'based',\n",
       "  'on',\n",
       "  'factors',\n",
       "  'such',\n",
       "  'as',\n",
       "  'age',\n",
       "  ',',\n",
       "  'blood',\n",
       "  'pressure',\n",
       "  ',',\n",
       "  'gender',\n",
       "  ',',\n",
       "  'location',\n",
       "  'and',\n",
       "  'severity',\n",
       "  'of',\n",
       "  'pain',\n",
       "  ',',\n",
       "  'and',\n",
       "  'other',\n",
       "  'measurements',\n",
       "  '·',\n",
       "  'Decision',\n",
       "  'trees',\n",
       "  'are',\n",
       "  'commonly',\n",
       "  'used',\n",
       "  'in',\n",
       "  'operations',\n",
       "  'research',\n",
       "  ',',\n",
       "  'specifically',\n",
       "  'in',\n",
       "  'decision',\n",
       "  'analysis',\n",
       "  ',',\n",
       "  'to',\n",
       "  'help',\n",
       "  'identify',\n",
       "  'a',\n",
       "  'strategy',\n",
       "  'most',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'reach',\n",
       "  'a',\n",
       "  'goal',\n",
       "  '.'],\n",
       " ['Because',\n",
       "  'of',\n",
       "  'their',\n",
       "  'simplicity',\n",
       "  ',',\n",
       "  'tree',\n",
       "  'diagrams',\n",
       "  'have',\n",
       "  'been',\n",
       "  'used',\n",
       "  'in',\n",
       "  'a',\n",
       "  'broad',\n",
       "  'range',\n",
       "  'of',\n",
       "  'industries',\n",
       "  'and',\n",
       "  'disciplines',\n",
       "  'including',\n",
       "  'civil',\n",
       "  'planning',\n",
       "  ',',\n",
       "  'energy',\n",
       "  ',',\n",
       "  'financial',\n",
       "  ',',\n",
       "  'engineering',\n",
       "  ',',\n",
       "  'healthcare',\n",
       "  ',',\n",
       "  'pharmaceutical',\n",
       "  ',',\n",
       "  'education',\n",
       "  ',',\n",
       "  'law',\n",
       "  ',',\n",
       "  'and',\n",
       "  'business',\n",
       "  '.'],\n",
       " ['How', 'does', 'Decision', 'Tree', 'works', '?'],\n",
       " ['Decision',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'a',\n",
       "  'type',\n",
       "  'of',\n",
       "  'supervised',\n",
       "  'learning',\n",
       "  'algorithm',\n",
       "  '(',\n",
       "  'having',\n",
       "  'a',\n",
       "  'pre-defined',\n",
       "  'target',\n",
       "  'variable',\n",
       "  ')',\n",
       "  'that',\n",
       "  'is',\n",
       "  'mostly',\n",
       "  'used',\n",
       "  'in',\n",
       "  'classification',\n",
       "  'problems',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'works',\n",
       "  'for',\n",
       "  'both',\n",
       "  'categorical',\n",
       "  'and',\n",
       "  'continuous',\n",
       "  'input',\n",
       "  'and',\n",
       "  'output',\n",
       "  'variables',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'this',\n",
       "  'technique',\n",
       "  ',',\n",
       "  'we',\n",
       "  'split',\n",
       "  'the',\n",
       "  'population',\n",
       "  'or',\n",
       "  'sample',\n",
       "  'into',\n",
       "  'two',\n",
       "  'or',\n",
       "  'more',\n",
       "  'homogeneous',\n",
       "  'sets',\n",
       "  '(',\n",
       "  'or',\n",
       "  'sub-populations',\n",
       "  ')',\n",
       "  'based',\n",
       "  'on',\n",
       "  'most',\n",
       "  'significant',\n",
       "  'splitter',\n",
       "  '/',\n",
       "  'differentiator',\n",
       "  'in',\n",
       "  'input',\n",
       "  'variables',\n",
       "  '.'],\n",
       " ['Example',\n",
       "  ':',\n",
       "  '-',\n",
       "  'Let',\n",
       "  '’',\n",
       "  's',\n",
       "  'say',\n",
       "  'we',\n",
       "  'have',\n",
       "  'a',\n",
       "  'sample',\n",
       "  'of',\n",
       "  '30',\n",
       "  'students',\n",
       "  'with',\n",
       "  'three',\n",
       "  'variables',\n",
       "  'Gender',\n",
       "  '(',\n",
       "  'Boy/',\n",
       "  'Girl',\n",
       "  ')',\n",
       "  ',',\n",
       "  'Class',\n",
       "  '(',\n",
       "  'IX/',\n",
       "  'X',\n",
       "  ')',\n",
       "  'and',\n",
       "  'Height',\n",
       "  '(',\n",
       "  '5',\n",
       "  'to',\n",
       "  '6',\n",
       "  'ft',\n",
       "  ')',\n",
       "  '.'],\n",
       " ['15',\n",
       "  'out',\n",
       "  'of',\n",
       "  'these',\n",
       "  '30',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'in',\n",
       "  'leisure',\n",
       "  'time',\n",
       "  '.'],\n",
       " ['Now',\n",
       "  ',',\n",
       "  'we',\n",
       "  'want',\n",
       "  'to',\n",
       "  'create',\n",
       "  'a',\n",
       "  'model',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'who',\n",
       "  'will',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'during',\n",
       "  'leisure',\n",
       "  'period',\n",
       "  '?'],\n",
       " ['In',\n",
       "  'this',\n",
       "  'problem',\n",
       "  ',',\n",
       "  'we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'segregate',\n",
       "  'students',\n",
       "  'who',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'in',\n",
       "  'their',\n",
       "  'leisure',\n",
       "  'time',\n",
       "  'based',\n",
       "  'on',\n",
       "  'highly',\n",
       "  'significant',\n",
       "  'input',\n",
       "  'variable',\n",
       "  'among',\n",
       "  'all',\n",
       "  'three',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'is',\n",
       "  'where',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'helps',\n",
       "  ',',\n",
       "  'it',\n",
       "  'will',\n",
       "  'segregate',\n",
       "  'the',\n",
       "  'students',\n",
       "  'based',\n",
       "  'on',\n",
       "  'all',\n",
       "  'values',\n",
       "  'of',\n",
       "  'three',\n",
       "  'variable',\n",
       "  'and',\n",
       "  'identify',\n",
       "  'the',\n",
       "  'variable',\n",
       "  ',',\n",
       "  'which',\n",
       "  'creates',\n",
       "  'the',\n",
       "  'best',\n",
       "  'homogeneous',\n",
       "  'sets',\n",
       "  'of',\n",
       "  'students',\n",
       "  '(',\n",
       "  'which',\n",
       "  'are',\n",
       "  'heterogeneous',\n",
       "  'to',\n",
       "  'each',\n",
       "  'other',\n",
       "  ')',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'the',\n",
       "  'snapshot',\n",
       "  'below',\n",
       "  ',',\n",
       "  'you',\n",
       "  'can',\n",
       "  'see',\n",
       "  'that',\n",
       "  'variable',\n",
       "  'Gender',\n",
       "  'is',\n",
       "  'able',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'best',\n",
       "  'homogeneous',\n",
       "  'sets',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'the',\n",
       "  'other',\n",
       "  'two',\n",
       "  'variables',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'tree',\n",
       "  'identifies',\n",
       "  'the',\n",
       "  'most',\n",
       "  'significant',\n",
       "  'variable',\n",
       "  'and',\n",
       "  'its',\n",
       "  'value',\n",
       "  'that',\n",
       "  'gives',\n",
       "  'best',\n",
       "  'homogeneous',\n",
       "  'sets',\n",
       "  'of',\n",
       "  'population',\n",
       "  '.'],\n",
       " ['To',\n",
       "  'identify',\n",
       "  'the',\n",
       "  'variable',\n",
       "  'and',\n",
       "  'the',\n",
       "  'split',\n",
       "  ',',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'uses',\n",
       "  'various',\n",
       "  'algorithms',\n",
       "  '.'],\n",
       " ['Types',\n",
       "  'of',\n",
       "  'Decision',\n",
       "  'Trees',\n",
       "  'Types',\n",
       "  'of',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'type',\n",
       "  'of',\n",
       "  'target',\n",
       "  'variable',\n",
       "  'we',\n",
       "  'have',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'can',\n",
       "  'be',\n",
       "  'of',\n",
       "  'two',\n",
       "  'types',\n",
       "  ':',\n",
       "  'Categorical',\n",
       "  'Variable',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  ':',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  'which',\n",
       "  'has',\n",
       "  'categorical',\n",
       "  'target',\n",
       "  'variable',\n",
       "  'then',\n",
       "  'it',\n",
       "  'called',\n",
       "  'as',\n",
       "  'categorical',\n",
       "  'variable',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['E.g', '.'],\n",
       " [':',\n",
       "  '-',\n",
       "  'In',\n",
       "  'above',\n",
       "  'scenario',\n",
       "  'of',\n",
       "  'student',\n",
       "  'problem',\n",
       "  ',',\n",
       "  'where',\n",
       "  'the',\n",
       "  'target',\n",
       "  'variable',\n",
       "  'was',\n",
       "  '“',\n",
       "  'Student',\n",
       "  'will',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'or',\n",
       "  'not',\n",
       "  '”',\n",
       "  'i.e',\n",
       "  '.'],\n",
       " ['YES', 'or', 'NO', '.'],\n",
       " ['Continuous',\n",
       "  'Variable',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  ':',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  'has',\n",
       "  'continuous',\n",
       "  'target',\n",
       "  'variable',\n",
       "  'then',\n",
       "  'it',\n",
       "  'is',\n",
       "  'called',\n",
       "  'as',\n",
       "  'Continuous',\n",
       "  'Variable',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  '.'],\n",
       " ['E.g', '.'],\n",
       " [':',\n",
       "  '-',\n",
       "  'Let',\n",
       "  '’',\n",
       "  's',\n",
       "  'say',\n",
       "  'we',\n",
       "  'have',\n",
       "  'a',\n",
       "  'problem',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'whether',\n",
       "  'a',\n",
       "  'customer',\n",
       "  'will',\n",
       "  'pay',\n",
       "  'his',\n",
       "  'renewal',\n",
       "  'premium',\n",
       "  'with',\n",
       "  'an',\n",
       "  'insurance',\n",
       "  'company',\n",
       "  '(',\n",
       "  'yes/',\n",
       "  'no',\n",
       "  ')',\n",
       "  '.'],\n",
       " ['Here',\n",
       "  'we',\n",
       "  'know',\n",
       "  'that',\n",
       "  'income',\n",
       "  'of',\n",
       "  'customer',\n",
       "  'is',\n",
       "  'a',\n",
       "  'significant',\n",
       "  'variable',\n",
       "  'but',\n",
       "  'insurance',\n",
       "  'company',\n",
       "  'does',\n",
       "  'not',\n",
       "  'have',\n",
       "  'income',\n",
       "  'details',\n",
       "  'for',\n",
       "  'all',\n",
       "  'customers',\n",
       "  '.'],\n",
       " ['Now',\n",
       "  ',',\n",
       "  'as',\n",
       "  'we',\n",
       "  'know',\n",
       "  'this',\n",
       "  'is',\n",
       "  'an',\n",
       "  'important',\n",
       "  'variable',\n",
       "  ',',\n",
       "  'then',\n",
       "  'we',\n",
       "  'can',\n",
       "  'build',\n",
       "  'a',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'customer',\n",
       "  'income',\n",
       "  'based',\n",
       "  'on',\n",
       "  'occupation',\n",
       "  ',',\n",
       "  'product',\n",
       "  'and',\n",
       "  'various',\n",
       "  'other',\n",
       "  'variables',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'this',\n",
       "  'case',\n",
       "  ',',\n",
       "  'we',\n",
       "  'are',\n",
       "  'predicting',\n",
       "  'values',\n",
       "  'for',\n",
       "  'continuous',\n",
       "  'variable',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'algorithm',\n",
       "  'tries',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'the',\n",
       "  'problem',\n",
       "  ',',\n",
       "  'by',\n",
       "  'using',\n",
       "  'tree',\n",
       "  'representation',\n",
       "  '.'],\n",
       " ['Each',\n",
       "  'internal',\n",
       "  'node',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'corresponds',\n",
       "  'to',\n",
       "  'an',\n",
       "  'attribute',\n",
       "  ',',\n",
       "  'and',\n",
       "  'each',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'corresponds',\n",
       "  'to',\n",
       "  'a',\n",
       "  'class',\n",
       "  'label',\n",
       "  '.'],\n",
       " ['Place',\n",
       "  'the',\n",
       "  'best',\n",
       "  'attribute',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dataset',\n",
       "  'at',\n",
       "  'the',\n",
       "  'root',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['Split', 'the', 'training', 'set', 'into', 'subsets', '.'],\n",
       " ['Subsets',\n",
       "  'should',\n",
       "  'be',\n",
       "  'made',\n",
       "  'in',\n",
       "  'such',\n",
       "  'a',\n",
       "  'way',\n",
       "  'that',\n",
       "  'each',\n",
       "  'subset',\n",
       "  'contains',\n",
       "  'data',\n",
       "  'with',\n",
       "  'the',\n",
       "  'same',\n",
       "  'value',\n",
       "  'for',\n",
       "  'an',\n",
       "  'attribute',\n",
       "  '.'],\n",
       " ['Repeat',\n",
       "  'step',\n",
       "  '1',\n",
       "  'and',\n",
       "  'step',\n",
       "  '2',\n",
       "  'on',\n",
       "  'each',\n",
       "  'subset',\n",
       "  'until',\n",
       "  'you',\n",
       "  'find',\n",
       "  'leaf',\n",
       "  'nodes',\n",
       "  'in',\n",
       "  'all',\n",
       "  'the',\n",
       "  'branches',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'decision',\n",
       "  'trees',\n",
       "  ',',\n",
       "  'for',\n",
       "  'predicting',\n",
       "  'a',\n",
       "  'class',\n",
       "  'label',\n",
       "  'for',\n",
       "  'a',\n",
       "  'record',\n",
       "  'we',\n",
       "  'start',\n",
       "  'from',\n",
       "  'the',\n",
       "  'root',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['We',\n",
       "  'compare',\n",
       "  'the',\n",
       "  'values',\n",
       "  'of',\n",
       "  'the',\n",
       "  'root',\n",
       "  'attribute',\n",
       "  'with',\n",
       "  'record',\n",
       "  '’',\n",
       "  's',\n",
       "  'attribute',\n",
       "  '.'],\n",
       " ['On',\n",
       "  'the',\n",
       "  'basis',\n",
       "  'of',\n",
       "  'comparison',\n",
       "  ',',\n",
       "  'we',\n",
       "  'follow',\n",
       "  'the',\n",
       "  'branch',\n",
       "  'corresponding',\n",
       "  'to',\n",
       "  'that',\n",
       "  'value',\n",
       "  'and',\n",
       "  'jump',\n",
       "  'to',\n",
       "  'the',\n",
       "  'next',\n",
       "  'node',\n",
       "  '.'],\n",
       " ['We',\n",
       "  'continue',\n",
       "  'comparing',\n",
       "  'our',\n",
       "  'record',\n",
       "  '’',\n",
       "  's',\n",
       "  'attribute',\n",
       "  'values',\n",
       "  'with',\n",
       "  'other',\n",
       "  'internal',\n",
       "  'nodes',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'until',\n",
       "  'we',\n",
       "  'reach',\n",
       "  'a',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'with',\n",
       "  'predicted',\n",
       "  'class',\n",
       "  'value',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'modeled',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'can',\n",
       "  'be',\n",
       "  'used',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'the',\n",
       "  'target',\n",
       "  'class',\n",
       "  'or',\n",
       "  'the',\n",
       "  'value',\n",
       "  '.'],\n",
       " ['Assumptions',\n",
       "  'while',\n",
       "  'creating',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  'Some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'assumptions',\n",
       "  'we',\n",
       "  'make',\n",
       "  'while',\n",
       "  'using',\n",
       "  'Decision',\n",
       "  'tree',\n",
       "  ':',\n",
       "  'At',\n",
       "  'the',\n",
       "  'beginning',\n",
       "  ',',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'training',\n",
       "  'set',\n",
       "  'is',\n",
       "  'considered',\n",
       "  'as',\n",
       "  'the',\n",
       "  'root',\n",
       "  '.'],\n",
       " ['Feature', 'values', 'are', 'preferred', 'to', 'be', 'categorical', '.'],\n",
       " ['If',\n",
       "  'the',\n",
       "  'values',\n",
       "  'are',\n",
       "  'continuous',\n",
       "  'then',\n",
       "  'they',\n",
       "  'are',\n",
       "  'discretized',\n",
       "  'prior',\n",
       "  'to',\n",
       "  'building',\n",
       "  'the',\n",
       "  'model',\n",
       "  '.'],\n",
       " ['Records',\n",
       "  'are',\n",
       "  'distributed',\n",
       "  'recursively',\n",
       "  'on',\n",
       "  'the',\n",
       "  'basis',\n",
       "  'of',\n",
       "  'attribute',\n",
       "  'values',\n",
       "  '.'],\n",
       " ['Order',\n",
       "  'to',\n",
       "  'placing',\n",
       "  'attributes',\n",
       "  'as',\n",
       "  'root',\n",
       "  'or',\n",
       "  'internal',\n",
       "  'node',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'done',\n",
       "  'by',\n",
       "  'using',\n",
       "  'some',\n",
       "  'statistical',\n",
       "  'approach',\n",
       "  '.'],\n",
       " ['Advantages',\n",
       "  'of',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  ':',\n",
       "  'Easy',\n",
       "  'to',\n",
       "  'Understand',\n",
       "  ':',\n",
       "  'Decision',\n",
       "  'tree',\n",
       "  'output',\n",
       "  'is',\n",
       "  'very',\n",
       "  'easy',\n",
       "  'to',\n",
       "  'understand',\n",
       "  'even',\n",
       "  'for',\n",
       "  'people',\n",
       "  'from',\n",
       "  'non-analytical',\n",
       "  'background',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'does',\n",
       "  'not',\n",
       "  'require',\n",
       "  'any',\n",
       "  'statistical',\n",
       "  'knowledge',\n",
       "  'to',\n",
       "  'read',\n",
       "  'and',\n",
       "  'interpret',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['Its',\n",
       "  'graphical',\n",
       "  'representation',\n",
       "  'is',\n",
       "  'very',\n",
       "  'intuitive',\n",
       "  'and',\n",
       "  'users',\n",
       "  'can',\n",
       "  'easily',\n",
       "  'relate',\n",
       "  'their',\n",
       "  'hypothesis',\n",
       "  '.'],\n",
       " ['Useful',\n",
       "  'in',\n",
       "  'Data',\n",
       "  'exploration',\n",
       "  ':',\n",
       "  'Decision',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'fastest',\n",
       "  'way',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'most',\n",
       "  'significant',\n",
       "  'variables',\n",
       "  'and',\n",
       "  'relation',\n",
       "  'between',\n",
       "  'two',\n",
       "  'or',\n",
       "  'more',\n",
       "  'variables',\n",
       "  '.'],\n",
       " ['With',\n",
       "  'the',\n",
       "  'help',\n",
       "  'of',\n",
       "  'decision',\n",
       "  'trees',\n",
       "  ',',\n",
       "  'we',\n",
       "  'can',\n",
       "  'create',\n",
       "  'new',\n",
       "  'variables',\n",
       "  '/',\n",
       "  'features',\n",
       "  'that',\n",
       "  'has',\n",
       "  'better',\n",
       "  'power',\n",
       "  'to',\n",
       "  'predict',\n",
       "  'target',\n",
       "  'variable',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'can',\n",
       "  'also',\n",
       "  'be',\n",
       "  'used',\n",
       "  'in',\n",
       "  'data',\n",
       "  'exploration',\n",
       "  'stage',\n",
       "  '.'],\n",
       " ['For',\n",
       "  'e.g.',\n",
       "  ',',\n",
       "  'we',\n",
       "  'are',\n",
       "  'working',\n",
       "  'on',\n",
       "  'a',\n",
       "  'problem',\n",
       "  'where',\n",
       "  'we',\n",
       "  'have',\n",
       "  'information',\n",
       "  'available',\n",
       "  'in',\n",
       "  'hundreds',\n",
       "  'of',\n",
       "  'variables',\n",
       "  ',',\n",
       "  'there',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'will',\n",
       "  'help',\n",
       "  'to',\n",
       "  'identify',\n",
       "  'most',\n",
       "  'significant',\n",
       "  'variable',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'trees',\n",
       "  'implicitly',\n",
       "  'perform',\n",
       "  'variable',\n",
       "  'screening',\n",
       "  'or',\n",
       "  'feature',\n",
       "  'selection',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'trees',\n",
       "  'require',\n",
       "  'relatively',\n",
       "  'little',\n",
       "  'effort',\n",
       "  'from',\n",
       "  'users',\n",
       "  'for',\n",
       "  'data',\n",
       "  'preparation',\n",
       "  '.'],\n",
       " ['Less',\n",
       "  'data',\n",
       "  'cleaning',\n",
       "  'required',\n",
       "  ':',\n",
       "  'It',\n",
       "  'requires',\n",
       "  'less',\n",
       "  'data',\n",
       "  'cleaning',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'some',\n",
       "  'other',\n",
       "  'modeling',\n",
       "  'techniques',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'is',\n",
       "  'not',\n",
       "  'influenced',\n",
       "  'by',\n",
       "  'outliers',\n",
       "  'and',\n",
       "  'missing',\n",
       "  'values',\n",
       "  'to',\n",
       "  'a',\n",
       "  'fair',\n",
       "  'degree',\n",
       "  '.'],\n",
       " ['Data',\n",
       "  'type',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'constraint',\n",
       "  ':',\n",
       "  'It',\n",
       "  'can',\n",
       "  'handle',\n",
       "  'both',\n",
       "  'numerical',\n",
       "  'and',\n",
       "  'categorical',\n",
       "  'variables',\n",
       "  '.'],\n",
       " ['Can', 'also', 'handle', 'multi-output', 'problems', '.'],\n",
       " ['Non-Parametric',\n",
       "  'Method',\n",
       "  ':',\n",
       "  'Decision',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'considered',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'non-parametric',\n",
       "  'method',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'means',\n",
       "  'that',\n",
       "  'decision',\n",
       "  'trees',\n",
       "  'have',\n",
       "  'no',\n",
       "  'assumptions',\n",
       "  'about',\n",
       "  'the',\n",
       "  'space',\n",
       "  'distribution',\n",
       "  'and',\n",
       "  'the',\n",
       "  'classifier',\n",
       "  'structure',\n",
       "  '.'],\n",
       " ['Non-linear',\n",
       "  'relationships',\n",
       "  'between',\n",
       "  'parameters',\n",
       "  'do',\n",
       "  'not',\n",
       "  'affect',\n",
       "  'tree',\n",
       "  'performance',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'number',\n",
       "  'of',\n",
       "  'hyper-parameters',\n",
       "  'to',\n",
       "  'be',\n",
       "  'tuned',\n",
       "  'is',\n",
       "  'almost',\n",
       "  'null',\n",
       "  '.'],\n",
       " ['Disadvantages',\n",
       "  'of',\n",
       "  'Decision',\n",
       "  'Tree',\n",
       "  ':',\n",
       "  'Over',\n",
       "  'fitting',\n",
       "  ':',\n",
       "  'Decision-tree',\n",
       "  'learners',\n",
       "  'can',\n",
       "  'create',\n",
       "  'over-complex',\n",
       "  'trees',\n",
       "  'that',\n",
       "  'do',\n",
       "  'not',\n",
       "  'generalize',\n",
       "  'the',\n",
       "  'data',\n",
       "  'well',\n",
       "  '.'],\n",
       " ['This', 'is', 'called', 'overfitting', '.'],\n",
       " ['Over',\n",
       "  'fitting',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'most',\n",
       "  'practical',\n",
       "  'difficulty',\n",
       "  'for',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'models',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'problem',\n",
       "  'gets',\n",
       "  'solved',\n",
       "  'by',\n",
       "  'setting',\n",
       "  'constraints',\n",
       "  'on',\n",
       "  'model',\n",
       "  'parameters',\n",
       "  'and',\n",
       "  'pruning',\n",
       "  '.'],\n",
       " ['Not',\n",
       "  'fit',\n",
       "  'for',\n",
       "  'continuous',\n",
       "  'variables',\n",
       "  ':',\n",
       "  'While',\n",
       "  'working',\n",
       "  'with',\n",
       "  'continuous',\n",
       "  'numerical',\n",
       "  'variables',\n",
       "  ',',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'loses',\n",
       "  'information',\n",
       "  ',',\n",
       "  'when',\n",
       "  'it',\n",
       "  'categorizes',\n",
       "  'variables',\n",
       "  'in',\n",
       "  'different',\n",
       "  'categories',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'trees',\n",
       "  'can',\n",
       "  'be',\n",
       "  'unstable',\n",
       "  'because',\n",
       "  'small',\n",
       "  'variations',\n",
       "  'in',\n",
       "  'the',\n",
       "  'data',\n",
       "  'might',\n",
       "  'result',\n",
       "  'in',\n",
       "  'a',\n",
       "  'completely',\n",
       "  'different',\n",
       "  'tree',\n",
       "  'being',\n",
       "  'generated',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'is',\n",
       "  'called',\n",
       "  'variance',\n",
       "  ',',\n",
       "  'which',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'be',\n",
       "  'lowered',\n",
       "  'by',\n",
       "  'methods',\n",
       "  'like',\n",
       "  'bagging',\n",
       "  'and',\n",
       "  'boosting',\n",
       "  '.'],\n",
       " ['Greedy',\n",
       "  'algorithms',\n",
       "  'can',\n",
       "  'not',\n",
       "  'guarantee',\n",
       "  'to',\n",
       "  'return',\n",
       "  'the',\n",
       "  'globally',\n",
       "  'optimal',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'can',\n",
       "  'be',\n",
       "  'mitigated',\n",
       "  'by',\n",
       "  'training',\n",
       "  'multiple',\n",
       "  'trees',\n",
       "  ',',\n",
       "  'where',\n",
       "  'the',\n",
       "  'features',\n",
       "  'and',\n",
       "  'samples',\n",
       "  'are',\n",
       "  'randomly',\n",
       "  'sampled',\n",
       "  'with',\n",
       "  'replacement',\n",
       "  '.'],\n",
       " ['Decision',\n",
       "  'tree',\n",
       "  'learners',\n",
       "  'create',\n",
       "  'biased',\n",
       "  'trees',\n",
       "  'if',\n",
       "  'some',\n",
       "  'classes',\n",
       "  'dominate',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'is',\n",
       "  'therefore',\n",
       "  'recommended',\n",
       "  'to',\n",
       "  'balance',\n",
       "  'the',\n",
       "  'data',\n",
       "  'set',\n",
       "  'prior',\n",
       "  'to',\n",
       "  'fitting',\n",
       "  'with',\n",
       "  'the',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['Information',\n",
       "  'gain',\n",
       "  'in',\n",
       "  'a',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  'with',\n",
       "  'categorical',\n",
       "  'variables',\n",
       "  'gives',\n",
       "  'a',\n",
       "  'biased',\n",
       "  'response',\n",
       "  'for',\n",
       "  'attributes',\n",
       "  'with',\n",
       "  'greater',\n",
       "  'no',\n",
       "  '.'],\n",
       " ['of', 'categories', '.'],\n",
       " ['Generally',\n",
       "  ',',\n",
       "  'it',\n",
       "  'gives',\n",
       "  'low',\n",
       "  'prediction',\n",
       "  'accuracy',\n",
       "  'for',\n",
       "  'a',\n",
       "  'dataset',\n",
       "  'as',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'other',\n",
       "  'machine',\n",
       "  'learning',\n",
       "  'algorithms',\n",
       "  '.'],\n",
       " ['Calculations',\n",
       "  'can',\n",
       "  'become',\n",
       "  'complex',\n",
       "  'when',\n",
       "  'there',\n",
       "  'are',\n",
       "  'many',\n",
       "  'class',\n",
       "  'label',\n",
       "  '.'],\n",
       " ['Regression',\n",
       "  'Trees',\n",
       "  'vs',\n",
       "  'Classification',\n",
       "  'Trees',\n",
       "  'The',\n",
       "  'terminal',\n",
       "  'nodes',\n",
       "  '(',\n",
       "  'or',\n",
       "  'leaves',\n",
       "  ')',\n",
       "  'lies',\n",
       "  'at',\n",
       "  'the',\n",
       "  'bottom',\n",
       "  'of',\n",
       "  'the',\n",
       "  'decision',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'means',\n",
       "  'that',\n",
       "  'decision',\n",
       "  'trees',\n",
       "  'are',\n",
       "  'typically',\n",
       "  'drawn',\n",
       "  'upside',\n",
       "  'down',\n",
       "  'such',\n",
       "  'that',\n",
       "  'leaves',\n",
       "  'are',\n",
       "  'the',\n",
       "  'bottom',\n",
       "  '&',\n",
       "  'roots',\n",
       "  'are',\n",
       "  'the',\n",
       "  'tops',\n",
       "  '.'],\n",
       " ['Both',\n",
       "  'the',\n",
       "  'trees',\n",
       "  'work',\n",
       "  'almost',\n",
       "  'similar',\n",
       "  'to',\n",
       "  'each',\n",
       "  'other',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'primary',\n",
       "  'differences',\n",
       "  'and',\n",
       "  'similarities',\n",
       "  'between',\n",
       "  'Classification',\n",
       "  'and',\n",
       "  'Regression',\n",
       "  'Trees',\n",
       "  'are',\n",
       "  ':',\n",
       "  'Regression',\n",
       "  'trees',\n",
       "  'are',\n",
       "  'used',\n",
       "  'when',\n",
       "  'dependent',\n",
       "  'variable',\n",
       "  'is',\n",
       "  'continuous',\n",
       "  '.'],\n",
       " ['Classification',\n",
       "  'Trees',\n",
       "  'are',\n",
       "  'used',\n",
       "  'when',\n",
       "  'dependent',\n",
       "  'variable',\n",
       "  'is',\n",
       "  'categorical',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'case',\n",
       "  'of',\n",
       "  'Regression',\n",
       "  'Tree',\n",
       "  ',',\n",
       "  'the',\n",
       "  'value',\n",
       "  'obtained',\n",
       "  'by',\n",
       "  'terminal',\n",
       "  'nodes',\n",
       "  'in',\n",
       "  'the',\n",
       "  'training',\n",
       "  'data',\n",
       "  'is',\n",
       "  'the',\n",
       "  'mean',\n",
       "  'response',\n",
       "  'of',\n",
       "  'observation',\n",
       "  'falling',\n",
       "  'in',\n",
       "  'that',\n",
       "  'region',\n",
       "  '.'],\n",
       " ['Thus',\n",
       "  ',',\n",
       "  'if',\n",
       "  'an',\n",
       "  'unseen',\n",
       "  'data',\n",
       "  'observation',\n",
       "  'falls',\n",
       "  'in',\n",
       "  'that',\n",
       "  'region',\n",
       "  ',',\n",
       "  'we',\n",
       "  '’',\n",
       "  'll',\n",
       "  'make',\n",
       "  'its',\n",
       "  'prediction',\n",
       "  'with',\n",
       "  'mean',\n",
       "  'value',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'case',\n",
       "  'of',\n",
       "  'Classification',\n",
       "  'Tree',\n",
       "  ',',\n",
       "  'the',\n",
       "  'value',\n",
       "  '(',\n",
       "  'class',\n",
       "  ')',\n",
       "  'obtained',\n",
       "  'by',\n",
       "  'terminal',\n",
       "  'node',\n",
       "  'in',\n",
       "  'the',\n",
       "  'training',\n",
       "  'data',\n",
       "  'is',\n",
       "  'the',\n",
       "  'mode',\n",
       "  'of',\n",
       "  'observations',\n",
       "  'falling',\n",
       "  'in',\n",
       "  'that',\n",
       "  'region',\n",
       "  '.'],\n",
       " ['Thus',\n",
       "  ',',\n",
       "  'if',\n",
       "  'an',\n",
       "  'unseen',\n",
       "  'data',\n",
       "  'observation',\n",
       "  'falls',\n",
       "  'in',\n",
       "  'that',\n",
       "  'region',\n",
       "  ',',\n",
       "  'we',\n",
       "  '’',\n",
       "  'll',\n",
       "  'make',\n",
       "  'its',\n",
       "  'prediction',\n",
       "  'with',\n",
       "  'mode',\n",
       "  'value',\n",
       "  '.'],\n",
       " ['Both',\n",
       "  'the',\n",
       "  'trees',\n",
       "  'divide',\n",
       "  'the',\n",
       "  'predictor',\n",
       "  'space',\n",
       "  '(',\n",
       "  'independent',\n",
       "  'variables',\n",
       "  ')',\n",
       "  'into',\n",
       "  'distinct',\n",
       "  'and',\n",
       "  'non-overlapping',\n",
       "  'regions',\n",
       "  '.'],\n",
       " ['Both',\n",
       "  'the',\n",
       "  'trees',\n",
       "  'follow',\n",
       "  'a',\n",
       "  'top-down',\n",
       "  'greedy',\n",
       "  'approach',\n",
       "  'known',\n",
       "  'as',\n",
       "  'recursive',\n",
       "  'binary',\n",
       "  'splitting',\n",
       "  '.'],\n",
       " ['We',\n",
       "  'call',\n",
       "  'it',\n",
       "  'as',\n",
       "  '‘',\n",
       "  'top-down',\n",
       "  '’',\n",
       "  'because',\n",
       "  'it',\n",
       "  'begins',\n",
       "  'from',\n",
       "  'the',\n",
       "  'top',\n",
       "  'of',\n",
       "  'tree',\n",
       "  'when',\n",
       "  'all',\n",
       "  'the',\n",
       "  'observations',\n",
       "  'are',\n",
       "  'available',\n",
       "  'in',\n",
       "  'a',\n",
       "  'single',\n",
       "  'region',\n",
       "  'and',\n",
       "  'successively',\n",
       "  'splits',\n",
       "  'the',\n",
       "  'predictor',\n",
       "  'space',\n",
       "  'into',\n",
       "  'two',\n",
       "  'new',\n",
       "  'branches',\n",
       "  'down',\n",
       "  'the',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'is',\n",
       "  'known',\n",
       "  'as',\n",
       "  '‘',\n",
       "  'greedy',\n",
       "  '’',\n",
       "  'because',\n",
       "  ',',\n",
       "  'the',\n",
       "  'algorithm',\n",
       "  'cares',\n",
       "  '(',\n",
       "  'looks',\n",
       "  'for',\n",
       "  'best',\n",
       "  'variable',\n",
       "  'available',\n",
       "  ')',\n",
       "  'about',\n",
       "  'only',\n",
       "  'the',\n",
       "  'current',\n",
       "  'split',\n",
       "  ',',\n",
       "  'and',\n",
       "  'not',\n",
       "  'about',\n",
       "  'future',\n",
       "  'splits',\n",
       "  'which',\n",
       "  'will',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'a',\n",
       "  'better',\n",
       "  'tree',\n",
       "  '.'],\n",
       " ['This',\n",
       "  'splitting',\n",
       "  'process',\n",
       "  'is',\n",
       "  'continued',\n",
       "  'until',\n",
       "  'a',\n",
       "  'user',\n",
       "  'defined',\n",
       "  'stopping',\n",
       "  'criteria',\n",
       "  'is',\n",
       "  'reached',\n",
       "  '.'],\n",
       " ['For', 'e.g', '.'],\n",
       " [':',\n",
       "  'we',\n",
       "  'can',\n",
       "  'tell',\n",
       "  'the',\n",
       "  'algorithm',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'once',\n",
       "  'the',\n",
       "  'number',\n",
       "  'of',\n",
       "  'observations',\n",
       "  'per',\n",
       "  'node',\n",
       "  'becomes',\n",
       "  'less',\n",
       "  'than',\n",
       "  '50',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'both',\n",
       "  'the',\n",
       "  'cases',\n",
       "  ',',\n",
       "  'the',\n",
       "  'splitting',\n",
       "  'process',\n",
       "  'results',\n",
       "  'in',\n",
       "  'fully',\n",
       "  'grown',\n",
       "  'trees',\n",
       "  'until',\n",
       "  'the',\n",
       "  'stopping',\n",
       "  'criteria',\n",
       "  'is',\n",
       "  'reached',\n",
       "  '.'],\n",
       " ['But',\n",
       "  ',',\n",
       "  'the',\n",
       "  'fully',\n",
       "  'grown',\n",
       "  'tree',\n",
       "  'is',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'over',\n",
       "  'fit',\n",
       "  'data',\n",
       "  ',',\n",
       "  'leading',\n",
       "  'to',\n",
       "  'poor',\n",
       "  'accuracy',\n",
       "  'on',\n",
       "  'unseen',\n",
       "  'data',\n",
       "  '.'],\n",
       " ['This', 'bring', '‘', 'pruning', '’', '.'],\n",
       " ['Pruning',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'technique',\n",
       "  'used',\n",
       "  'tackle',\n",
       "  'overfitting',\n",
       "  '.']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sentence=[]\n",
    "for i in sentences:\n",
    "    for j in i:\n",
    "        word_sentence.append(word_tokenize(j))\n",
    "word_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removal of stop words\n",
    "stop_words = set(stopwords.words('english')) \n",
    "line=[]\n",
    "filtered_sentence=[]\n",
    "\n",
    "for i in word_sentence:\n",
    "    for j in i:\n",
    "        if not j in stop_words:\n",
    "            line.append(j)\n",
    "    filtered_sentence.append(line)\n",
    "    line=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'decision',\n",
       " 'tree',\n",
       " 'decision',\n",
       " 'support',\n",
       " 'tool',\n",
       " 'uses',\n",
       " 'tree-like',\n",
       " 'graph',\n",
       " 'model',\n",
       " 'decisions',\n",
       " 'possible',\n",
       " 'consequences',\n",
       " ',',\n",
       " 'including',\n",
       " 'chance',\n",
       " 'event',\n",
       " 'outcomes',\n",
       " ',',\n",
       " 'resource',\n",
       " 'costs',\n",
       " ',',\n",
       " 'utility',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming the words\n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer()\n",
    "stemmed_sentences=[]\n",
    "line=[]\n",
    "for i in filtered_sentence:\n",
    "    for j in i:\n",
    "       line.append(ps.stem(j))\n",
    "    stemmed_sentences.append(line)\n",
    "    line=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations, numbers and special characters\n",
    "alphabetic_sentences=[]\n",
    "line=[]\n",
    "for i in stemmed_sentences:\n",
    "    line.append(pd.Series(i).str.replace(\"[^a-zA-Z]\", \" \"))\n",
    "    \n",
    "    \n",
    "    alphabetic_sentences.append(line)\n",
    "    line=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'decis',\n",
       "  'support',\n",
       "  'tool',\n",
       "  'use',\n",
       "  'tree lik',\n",
       "  'graph',\n",
       "  'model',\n",
       "  'decis',\n",
       "  'possibl',\n",
       "  'consequ',\n",
       "  'includ',\n",
       "  'chanc',\n",
       "  'event',\n",
       "  'outcom',\n",
       "  'resourc',\n",
       "  'cost',\n",
       "  'util'],\n",
       " ['it',\n",
       "  'one',\n",
       "  'way',\n",
       "  'display',\n",
       "  'algorithm',\n",
       "  'contain',\n",
       "  'condit',\n",
       "  'control',\n",
       "  'statement'],\n",
       " ['a',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'flowchart lik',\n",
       "  'structur',\n",
       "  'intern',\n",
       "  'node',\n",
       "  'repres',\n",
       "  'test',\n",
       "  'attribut',\n",
       "  'e g'],\n",
       " ['whether',\n",
       "  'coin',\n",
       "  'flip',\n",
       "  'come',\n",
       "  'head',\n",
       "  'tail',\n",
       "  'branch',\n",
       "  'repres',\n",
       "  'outcom',\n",
       "  'test',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'repres',\n",
       "  'class',\n",
       "  'label',\n",
       "  'decis',\n",
       "  'taken',\n",
       "  'comput',\n",
       "  'attribut'],\n",
       " ['the', 'path', 'root', 'leaf', 'repres', 'classif', 'rule'],\n",
       " ['tree',\n",
       "  'base',\n",
       "  'learn',\n",
       "  'algorithm',\n",
       "  'consid',\n",
       "  'one',\n",
       "  'best',\n",
       "  'mostli',\n",
       "  'use',\n",
       "  'supervis',\n",
       "  'learn',\n",
       "  'method'],\n",
       " ['tree',\n",
       "  'base',\n",
       "  'method',\n",
       "  'empow',\n",
       "  'predict',\n",
       "  'model',\n",
       "  'high',\n",
       "  'accuraci',\n",
       "  'stabil',\n",
       "  'eas',\n",
       "  'interpret'],\n",
       " ['unlik',\n",
       "  'linear',\n",
       "  'model',\n",
       "  'map',\n",
       "  'non linear',\n",
       "  'relationship',\n",
       "  'quit',\n",
       "  'well'],\n",
       " ['they', 'adapt', 'solv', 'kind', 'problem', 'hand', 'classif', 'regress'],\n",
       " ['decis', 'tree', 'algorithm', 'refer', 'cart', 'classif', 'regress', 'tree'],\n",
       " ['the',\n",
       "  'possibl',\n",
       "  'solut',\n",
       "  'given',\n",
       "  'problem',\n",
       "  'emerg',\n",
       "  'leav',\n",
       "  'tree',\n",
       "  'node',\n",
       "  'repres',\n",
       "  'point',\n",
       "  'deliber',\n",
       "  'decision ',\n",
       "  'niklau',\n",
       "  'wirth',\n",
       "  '    ',\n",
       "  'program',\n",
       "  'languag',\n",
       "  'design',\n",
       "  'method',\n",
       "  'like',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'random',\n",
       "  'forest',\n",
       "  'gradient',\n",
       "  'boost',\n",
       "  'popularli',\n",
       "  'use',\n",
       "  'kind',\n",
       "  'data',\n",
       "  'scienc',\n",
       "  'problem'],\n",
       " ['common',\n",
       "  'term',\n",
       "  'use',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'root',\n",
       "  'node',\n",
       "  'it',\n",
       "  'repres',\n",
       "  'entir',\n",
       "  'popul',\n",
       "  'sampl',\n",
       "  'get',\n",
       "  'divid',\n",
       "  'two',\n",
       "  'homogen',\n",
       "  'set'],\n",
       " ['split', 'it', 'process', 'divid', 'node', 'two', 'sub nod'],\n",
       " ['decis',\n",
       "  'node',\n",
       "  'when',\n",
       "  'sub nod',\n",
       "  'split',\n",
       "  'sub nod',\n",
       "  'call',\n",
       "  'decis',\n",
       "  'node'],\n",
       " ['leaf ',\n",
       "  'termin',\n",
       "  'node',\n",
       "  'node',\n",
       "  'split',\n",
       "  'call',\n",
       "  'leaf',\n",
       "  'termin',\n",
       "  'node'],\n",
       " ['prune',\n",
       "  'when',\n",
       "  'remov',\n",
       "  'sub nod',\n",
       "  'decis',\n",
       "  'node',\n",
       "  'process',\n",
       "  'call',\n",
       "  'prune'],\n",
       " ['you', 'say', 'opposit', 'process', 'split'],\n",
       " ['branch',\n",
       "  'sub tre',\n",
       "  'a',\n",
       "  'sub',\n",
       "  'section',\n",
       "  'entir',\n",
       "  'tree',\n",
       "  'call',\n",
       "  'branch',\n",
       "  'sub tre'],\n",
       " ['parent',\n",
       "  'child',\n",
       "  'node',\n",
       "  'a',\n",
       "  'node',\n",
       "  'divid',\n",
       "  'sub nod',\n",
       "  'call',\n",
       "  'parent',\n",
       "  'node',\n",
       "  'sub nod',\n",
       "  'wherea',\n",
       "  'sub nod',\n",
       "  'child',\n",
       "  'parent',\n",
       "  'node'],\n",
       " ['applic',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'natur',\n",
       "  'els',\n",
       "  'construct',\n",
       "  'make',\n",
       "  'fit',\n",
       "  'easili',\n",
       "  'programmat',\n",
       "  'structur'],\n",
       " ['they',\n",
       "  'also',\n",
       "  'well',\n",
       "  'suit',\n",
       "  'categor',\n",
       "  'problem',\n",
       "  'attribut',\n",
       "  'featur',\n",
       "  'systemat',\n",
       "  'check',\n",
       "  'determin',\n",
       "  'final',\n",
       "  'categori'],\n",
       " ['for',\n",
       "  'exampl',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'could',\n",
       "  'use',\n",
       "  'effect',\n",
       "  'determin',\n",
       "  'speci',\n",
       "  'anim'],\n",
       " ['as',\n",
       "  'result',\n",
       "  'decis',\n",
       "  'make',\n",
       "  'tree',\n",
       "  'one',\n",
       "  'popular',\n",
       "  'classif',\n",
       "  'algorithm',\n",
       "  'use',\n",
       "  'data',\n",
       "  'mine',\n",
       "  'machin',\n",
       "  'learn'],\n",
       " ['exampl',\n",
       "  'applic',\n",
       "  'includ',\n",
       "  'evalu',\n",
       "  'brand',\n",
       "  'expans',\n",
       "  'opportun',\n",
       "  'busi',\n",
       "  'use',\n",
       "  'histor',\n",
       "  'sale',\n",
       "  'data',\n",
       "  'determin',\n",
       "  'like',\n",
       "  'buyer',\n",
       "  'product',\n",
       "  'use',\n",
       "  'demograph',\n",
       "  'data',\n",
       "  'enabl',\n",
       "  'target',\n",
       "  'limit',\n",
       "  'advertis',\n",
       "  'budget',\n",
       "  'predict',\n",
       "  'likelihood',\n",
       "  'default',\n",
       "  'applic',\n",
       "  'borrow',\n",
       "  'use',\n",
       "  'predict',\n",
       "  'model',\n",
       "  'gener',\n",
       "  'histor',\n",
       "  'data',\n",
       "  'help',\n",
       "  'priorit',\n",
       "  'emerg',\n",
       "  'room',\n",
       "  'patient',\n",
       "  'treatment',\n",
       "  'use',\n",
       "  'predict',\n",
       "  'model',\n",
       "  'base',\n",
       "  'factor',\n",
       "  'age',\n",
       "  'blood',\n",
       "  'pressur',\n",
       "  'gender',\n",
       "  'locat',\n",
       "  'sever',\n",
       "  'pain',\n",
       "  'measur',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'commonli',\n",
       "  'use',\n",
       "  'oper',\n",
       "  'research',\n",
       "  'specif',\n",
       "  'decis',\n",
       "  'analysi',\n",
       "  'help',\n",
       "  'identifi',\n",
       "  'strategi',\n",
       "  'like',\n",
       "  'reach',\n",
       "  'goal'],\n",
       " ['becaus',\n",
       "  'simplic',\n",
       "  'tree',\n",
       "  'diagram',\n",
       "  'use',\n",
       "  'broad',\n",
       "  'rang',\n",
       "  'industri',\n",
       "  'disciplin',\n",
       "  'includ',\n",
       "  'civil',\n",
       "  'plan',\n",
       "  'energi',\n",
       "  'financi',\n",
       "  'engin',\n",
       "  'healthcar',\n",
       "  'pharmaceut',\n",
       "  'educ',\n",
       "  'law',\n",
       "  'busi'],\n",
       " ['how', 'decis', 'tree', 'work'],\n",
       " ['decis',\n",
       "  'tree',\n",
       "  'type',\n",
       "  'supervis',\n",
       "  'learn',\n",
       "  'algorithm',\n",
       "  'pre defin',\n",
       "  'target',\n",
       "  'variabl',\n",
       "  'mostli',\n",
       "  'use',\n",
       "  'classif',\n",
       "  'problem'],\n",
       " ['it', 'work', 'categor', 'continu', 'input', 'output', 'variabl'],\n",
       " ['in',\n",
       "  'techniqu',\n",
       "  'split',\n",
       "  'popul',\n",
       "  'sampl',\n",
       "  'two',\n",
       "  'homogen',\n",
       "  'set',\n",
       "  'sub popul',\n",
       "  'base',\n",
       "  'signific',\n",
       "  'splitter',\n",
       "  'differenti',\n",
       "  'input',\n",
       "  'variabl'],\n",
       " ['exampl',\n",
       "  'let',\n",
       "  'say',\n",
       "  'sampl',\n",
       "  '  ',\n",
       "  'student',\n",
       "  'three',\n",
       "  'variabl',\n",
       "  'gender',\n",
       "  'boy ',\n",
       "  'girl',\n",
       "  'class',\n",
       "  'ix ',\n",
       "  'x',\n",
       "  'height',\n",
       "  'ft'],\n",
       " ['  ', '  ', 'play', 'cricket', 'leisur', 'time'],\n",
       " ['now',\n",
       "  'want',\n",
       "  'creat',\n",
       "  'model',\n",
       "  'predict',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'leisur',\n",
       "  'period'],\n",
       " ['in',\n",
       "  'problem',\n",
       "  'need',\n",
       "  'segreg',\n",
       "  'student',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'leisur',\n",
       "  'time',\n",
       "  'base',\n",
       "  'highli',\n",
       "  'signific',\n",
       "  'input',\n",
       "  'variabl',\n",
       "  'among',\n",
       "  'three'],\n",
       " ['thi',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'help',\n",
       "  'segreg',\n",
       "  'student',\n",
       "  'base',\n",
       "  'valu',\n",
       "  'three',\n",
       "  'variabl',\n",
       "  'identifi',\n",
       "  'variabl',\n",
       "  'creat',\n",
       "  'best',\n",
       "  'homogen',\n",
       "  'set',\n",
       "  'student',\n",
       "  'heterogen'],\n",
       " ['in',\n",
       "  'snapshot',\n",
       "  'see',\n",
       "  'variabl',\n",
       "  'gender',\n",
       "  'abl',\n",
       "  'identifi',\n",
       "  'best',\n",
       "  'homogen',\n",
       "  'set',\n",
       "  'compar',\n",
       "  'two',\n",
       "  'variabl'],\n",
       " ['decis',\n",
       "  'tree',\n",
       "  'identifi',\n",
       "  'signific',\n",
       "  'variabl',\n",
       "  'valu',\n",
       "  'give',\n",
       "  'best',\n",
       "  'homogen',\n",
       "  'set',\n",
       "  'popul'],\n",
       " ['to',\n",
       "  'identifi',\n",
       "  'variabl',\n",
       "  'split',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'use',\n",
       "  'variou',\n",
       "  'algorithm'],\n",
       " ['type',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'type',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'base',\n",
       "  'type',\n",
       "  'target',\n",
       "  'variabl'],\n",
       " ['it',\n",
       "  'two',\n",
       "  'type',\n",
       "  'categor',\n",
       "  'variabl',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'categor',\n",
       "  'target',\n",
       "  'variabl',\n",
       "  'call',\n",
       "  'categor',\n",
       "  'variabl',\n",
       "  'decis',\n",
       "  'tree'],\n",
       " ['e g'],\n",
       " ['in',\n",
       "  'scenario',\n",
       "  'student',\n",
       "  'problem',\n",
       "  'target',\n",
       "  'variabl',\n",
       "  'student',\n",
       "  'play',\n",
       "  'cricket',\n",
       "  'i e'],\n",
       " ['ye', 'no'],\n",
       " ['continu',\n",
       "  'variabl',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'continu',\n",
       "  'target',\n",
       "  'variabl',\n",
       "  'call',\n",
       "  'continu',\n",
       "  'variabl',\n",
       "  'decis',\n",
       "  'tree'],\n",
       " ['e g'],\n",
       " ['let',\n",
       "  'say',\n",
       "  'problem',\n",
       "  'predict',\n",
       "  'whether',\n",
       "  'custom',\n",
       "  'pay',\n",
       "  'renew',\n",
       "  'premium',\n",
       "  'insur',\n",
       "  'compani',\n",
       "  'yes '],\n",
       " ['here',\n",
       "  'know',\n",
       "  'incom',\n",
       "  'custom',\n",
       "  'signific',\n",
       "  'variabl',\n",
       "  'insur',\n",
       "  'compani',\n",
       "  'incom',\n",
       "  'detail',\n",
       "  'custom'],\n",
       " ['now',\n",
       "  'know',\n",
       "  'import',\n",
       "  'variabl',\n",
       "  'build',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'predict',\n",
       "  'custom',\n",
       "  'incom',\n",
       "  'base',\n",
       "  'occup',\n",
       "  'product',\n",
       "  'variou',\n",
       "  'variabl'],\n",
       " ['in', 'case', 'predict', 'valu', 'continu', 'variabl'],\n",
       " ['the',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'algorithm',\n",
       "  'tri',\n",
       "  'solv',\n",
       "  'problem',\n",
       "  'use',\n",
       "  'tree',\n",
       "  'represent'],\n",
       " ['each',\n",
       "  'intern',\n",
       "  'node',\n",
       "  'tree',\n",
       "  'correspond',\n",
       "  'attribut',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'correspond',\n",
       "  'class',\n",
       "  'label'],\n",
       " ['place', 'best', 'attribut', 'dataset', 'root', 'tree'],\n",
       " ['split', 'train', 'set', 'subset'],\n",
       " ['subset', 'made', 'way', 'subset', 'contain', 'data', 'valu', 'attribut'],\n",
       " ['repeat',\n",
       "  'step',\n",
       "  'step',\n",
       "  'subset',\n",
       "  'find',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'branch',\n",
       "  'tree'],\n",
       " ['in',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'predict',\n",
       "  'class',\n",
       "  'label',\n",
       "  'record',\n",
       "  'start',\n",
       "  'root',\n",
       "  'tree'],\n",
       " ['we', 'compar', 'valu', 'root', 'attribut', 'record', 'attribut'],\n",
       " ['on',\n",
       "  'basi',\n",
       "  'comparison',\n",
       "  'follow',\n",
       "  'branch',\n",
       "  'correspond',\n",
       "  'valu',\n",
       "  'jump',\n",
       "  'next',\n",
       "  'node'],\n",
       " ['we',\n",
       "  'continu',\n",
       "  'compar',\n",
       "  'record',\n",
       "  'attribut',\n",
       "  'valu',\n",
       "  'intern',\n",
       "  'node',\n",
       "  'tree',\n",
       "  'reach',\n",
       "  'leaf',\n",
       "  'node',\n",
       "  'predict',\n",
       "  'class',\n",
       "  'valu'],\n",
       " ['the',\n",
       "  'model',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'use',\n",
       "  'predict',\n",
       "  'target',\n",
       "  'class',\n",
       "  'valu'],\n",
       " ['assumpt',\n",
       "  'creat',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'some',\n",
       "  'assumpt',\n",
       "  'make',\n",
       "  'use',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'at',\n",
       "  'begin',\n",
       "  'whole',\n",
       "  'train',\n",
       "  'set',\n",
       "  'consid',\n",
       "  'root'],\n",
       " ['featur', 'valu', 'prefer', 'categor'],\n",
       " ['if', 'valu', 'continu', 'discret', 'prior', 'build', 'model'],\n",
       " ['record', 'distribut', 'recurs', 'basi', 'attribut', 'valu'],\n",
       " ['order',\n",
       "  'place',\n",
       "  'attribut',\n",
       "  'root',\n",
       "  'intern',\n",
       "  'node',\n",
       "  'tree',\n",
       "  'done',\n",
       "  'use',\n",
       "  'statist',\n",
       "  'approach'],\n",
       " ['advantag',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'easi',\n",
       "  'understand',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'output',\n",
       "  'easi',\n",
       "  'understand',\n",
       "  'even',\n",
       "  'peopl',\n",
       "  'non analyt',\n",
       "  'background'],\n",
       " ['it', 'requir', 'statist', 'knowledg', 'read', 'interpret'],\n",
       " ['it',\n",
       "  'graphic',\n",
       "  'represent',\n",
       "  'intuit',\n",
       "  'user',\n",
       "  'easili',\n",
       "  'relat',\n",
       "  'hypothesi'],\n",
       " ['use',\n",
       "  'data',\n",
       "  'explor',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'one',\n",
       "  'fastest',\n",
       "  'way',\n",
       "  'identifi',\n",
       "  'signific',\n",
       "  'variabl',\n",
       "  'relat',\n",
       "  'two',\n",
       "  'variabl'],\n",
       " ['with',\n",
       "  'help',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'creat',\n",
       "  'new',\n",
       "  'variabl',\n",
       "  'featur',\n",
       "  'better',\n",
       "  'power',\n",
       "  'predict',\n",
       "  'target',\n",
       "  'variabl'],\n",
       " ['it', 'also', 'use', 'data', 'explor', 'stage'],\n",
       " ['for',\n",
       "  'e g ',\n",
       "  'work',\n",
       "  'problem',\n",
       "  'inform',\n",
       "  'avail',\n",
       "  'hundr',\n",
       "  'variabl',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'help',\n",
       "  'identifi',\n",
       "  'signific',\n",
       "  'variabl'],\n",
       " ['decis',\n",
       "  'tree',\n",
       "  'implicitli',\n",
       "  'perform',\n",
       "  'variabl',\n",
       "  'screen',\n",
       "  'featur',\n",
       "  'select'],\n",
       " ['decis',\n",
       "  'tree',\n",
       "  'requir',\n",
       "  'rel',\n",
       "  'littl',\n",
       "  'effort',\n",
       "  'user',\n",
       "  'data',\n",
       "  'prepar'],\n",
       " ['less',\n",
       "  'data',\n",
       "  'clean',\n",
       "  'requir',\n",
       "  'it',\n",
       "  'requir',\n",
       "  'less',\n",
       "  'data',\n",
       "  'clean',\n",
       "  'compar',\n",
       "  'model',\n",
       "  'techniqu'],\n",
       " ['it', 'influenc', 'outlier', 'miss', 'valu', 'fair', 'degre'],\n",
       " ['data', 'type', 'constraint', 'it', 'handl', 'numer', 'categor', 'variabl'],\n",
       " ['can', 'also', 'handl', 'multi output', 'problem'],\n",
       " ['non parametr',\n",
       "  'method',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'consid',\n",
       "  'non parametr',\n",
       "  'method'],\n",
       " ['thi',\n",
       "  'mean',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'assumpt',\n",
       "  'space',\n",
       "  'distribut',\n",
       "  'classifi',\n",
       "  'structur'],\n",
       " ['non linear', 'relationship', 'paramet', 'affect', 'tree', 'perform'],\n",
       " ['the', 'number', 'hyper paramet', 'tune', 'almost', 'null'],\n",
       " ['disadvantag',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'over',\n",
       "  'fit',\n",
       "  'decision tre',\n",
       "  'learner',\n",
       "  'creat',\n",
       "  'over complex',\n",
       "  'tree',\n",
       "  'gener',\n",
       "  'data',\n",
       "  'well'],\n",
       " ['thi', 'call', 'overfit'],\n",
       " ['over', 'fit', 'one', 'practic', 'difficulti', 'decis', 'tree', 'model'],\n",
       " ['thi',\n",
       "  'problem',\n",
       "  'get',\n",
       "  'solv',\n",
       "  'set',\n",
       "  'constraint',\n",
       "  'model',\n",
       "  'paramet',\n",
       "  'prune'],\n",
       " ['not',\n",
       "  'fit',\n",
       "  'continu',\n",
       "  'variabl',\n",
       "  'while',\n",
       "  'work',\n",
       "  'continu',\n",
       "  'numer',\n",
       "  'variabl',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'lose',\n",
       "  'inform',\n",
       "  'categor',\n",
       "  'variabl',\n",
       "  'differ',\n",
       "  'categori'],\n",
       " ['decis',\n",
       "  'tree',\n",
       "  'unstabl',\n",
       "  'small',\n",
       "  'variat',\n",
       "  'data',\n",
       "  'might',\n",
       "  'result',\n",
       "  'complet',\n",
       "  'differ',\n",
       "  'tree',\n",
       "  'gener'],\n",
       " ['thi', 'call', 'varianc', 'need', 'lower', 'method', 'like', 'bag', 'boost'],\n",
       " ['greedi',\n",
       "  'algorithm',\n",
       "  'guarante',\n",
       "  'return',\n",
       "  'global',\n",
       "  'optim',\n",
       "  'decis',\n",
       "  'tree'],\n",
       " ['thi',\n",
       "  'mitig',\n",
       "  'train',\n",
       "  'multipl',\n",
       "  'tree',\n",
       "  'featur',\n",
       "  'sampl',\n",
       "  'randomli',\n",
       "  'sampl',\n",
       "  'replac'],\n",
       " ['decis', 'tree', 'learner', 'creat', 'bias', 'tree', 'class', 'domin'],\n",
       " ['it',\n",
       "  'therefor',\n",
       "  'recommend',\n",
       "  'balanc',\n",
       "  'data',\n",
       "  'set',\n",
       "  'prior',\n",
       "  'fit',\n",
       "  'decis',\n",
       "  'tree'],\n",
       " ['inform',\n",
       "  'gain',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'categor',\n",
       "  'variabl',\n",
       "  'give',\n",
       "  'bias',\n",
       "  'respons',\n",
       "  'attribut',\n",
       "  'greater'],\n",
       " ['categori'],\n",
       " ['gener',\n",
       "  'give',\n",
       "  'low',\n",
       "  'predict',\n",
       "  'accuraci',\n",
       "  'dataset',\n",
       "  'compar',\n",
       "  'machin',\n",
       "  'learn',\n",
       "  'algorithm'],\n",
       " ['calcul', 'becom', 'complex', 'mani', 'class', 'label'],\n",
       " ['regress',\n",
       "  'tree',\n",
       "  'vs',\n",
       "  'classif',\n",
       "  'tree',\n",
       "  'the',\n",
       "  'termin',\n",
       "  'node',\n",
       "  'leav',\n",
       "  'lie',\n",
       "  'bottom',\n",
       "  'decis',\n",
       "  'tree'],\n",
       " ['thi',\n",
       "  'mean',\n",
       "  'decis',\n",
       "  'tree',\n",
       "  'typic',\n",
       "  'drawn',\n",
       "  'upsid',\n",
       "  'leav',\n",
       "  'bottom',\n",
       "  'root',\n",
       "  'top'],\n",
       " ['both', 'tree', 'work', 'almost', 'similar'],\n",
       " ['the',\n",
       "  'primari',\n",
       "  'differ',\n",
       "  'similar',\n",
       "  'classif',\n",
       "  'regress',\n",
       "  'tree',\n",
       "  'regress',\n",
       "  'tree',\n",
       "  'use',\n",
       "  'depend',\n",
       "  'variabl',\n",
       "  'continu'],\n",
       " ['classif', 'tree', 'use', 'depend', 'variabl', 'categor'],\n",
       " ['in',\n",
       "  'case',\n",
       "  'regress',\n",
       "  'tree',\n",
       "  'valu',\n",
       "  'obtain',\n",
       "  'termin',\n",
       "  'node',\n",
       "  'train',\n",
       "  'data',\n",
       "  'mean',\n",
       "  'respons',\n",
       "  'observ',\n",
       "  'fall',\n",
       "  'region'],\n",
       " ['thu',\n",
       "  'unseen',\n",
       "  'data',\n",
       "  'observ',\n",
       "  'fall',\n",
       "  'region',\n",
       "  'make',\n",
       "  'predict',\n",
       "  'mean',\n",
       "  'valu'],\n",
       " ['in',\n",
       "  'case',\n",
       "  'classif',\n",
       "  'tree',\n",
       "  'valu',\n",
       "  'class',\n",
       "  'obtain',\n",
       "  'termin',\n",
       "  'node',\n",
       "  'train',\n",
       "  'data',\n",
       "  'mode',\n",
       "  'observ',\n",
       "  'fall',\n",
       "  'region'],\n",
       " ['thu',\n",
       "  'unseen',\n",
       "  'data',\n",
       "  'observ',\n",
       "  'fall',\n",
       "  'region',\n",
       "  'make',\n",
       "  'predict',\n",
       "  'mode',\n",
       "  'valu'],\n",
       " ['both',\n",
       "  'tree',\n",
       "  'divid',\n",
       "  'predictor',\n",
       "  'space',\n",
       "  'independ',\n",
       "  'variabl',\n",
       "  'distinct',\n",
       "  'non overlap',\n",
       "  'region'],\n",
       " ['both',\n",
       "  'tree',\n",
       "  'follow',\n",
       "  'top down',\n",
       "  'greedi',\n",
       "  'approach',\n",
       "  'known',\n",
       "  'recurs',\n",
       "  'binari',\n",
       "  'split'],\n",
       " ['we',\n",
       "  'call',\n",
       "  'top down',\n",
       "  'begin',\n",
       "  'top',\n",
       "  'tree',\n",
       "  'observ',\n",
       "  'avail',\n",
       "  'singl',\n",
       "  'region',\n",
       "  'success',\n",
       "  'split',\n",
       "  'predictor',\n",
       "  'space',\n",
       "  'two',\n",
       "  'new',\n",
       "  'branch',\n",
       "  'tree'],\n",
       " ['it',\n",
       "  'known',\n",
       "  'greedi',\n",
       "  'algorithm',\n",
       "  'care',\n",
       "  'look',\n",
       "  'best',\n",
       "  'variabl',\n",
       "  'avail',\n",
       "  'current',\n",
       "  'split',\n",
       "  'futur',\n",
       "  'split',\n",
       "  'lead',\n",
       "  'better',\n",
       "  'tree'],\n",
       " ['thi',\n",
       "  'split',\n",
       "  'process',\n",
       "  'continu',\n",
       "  'user',\n",
       "  'defin',\n",
       "  'stop',\n",
       "  'criteria',\n",
       "  'reach'],\n",
       " ['for', 'e g'],\n",
       " ['tell',\n",
       "  'algorithm',\n",
       "  'stop',\n",
       "  'number',\n",
       "  'observ',\n",
       "  'per',\n",
       "  'node',\n",
       "  'becom',\n",
       "  'less',\n",
       "  '  '],\n",
       " ['in',\n",
       "  'case',\n",
       "  'split',\n",
       "  'process',\n",
       "  'result',\n",
       "  'fulli',\n",
       "  'grown',\n",
       "  'tree',\n",
       "  'stop',\n",
       "  'criteria',\n",
       "  'reach'],\n",
       " ['but',\n",
       "  'fulli',\n",
       "  'grown',\n",
       "  'tree',\n",
       "  'like',\n",
       "  'fit',\n",
       "  'data',\n",
       "  'lead',\n",
       "  'poor',\n",
       "  'accuraci',\n",
       "  'unseen',\n",
       "  'data'],\n",
       " ['thi', 'bring', 'prune'],\n",
       " ['prune', 'one', 'techniqu', 'use', 'tackl', 'overfit']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = []\n",
    "\n",
    "for i in alphabetic_sentences:\n",
    "   \n",
    "    for j in i:\n",
    "        l=[]\n",
    "        for x in j.values:\n",
    "            if not x ==' ':\n",
    "                l.append(x.lower())\n",
    "        line.append(l)\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "words=[y for x in line for y in x ]\n",
    "\n",
    "#Taking all distinct words in an array\n",
    "Distinct_Words=[y for y in set(words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Distinct_Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1239"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visulaizaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train\n",
      "1 analysi\n",
      "2 decision tre\n",
      "3 section\n",
      "4 remov\n",
      "5 varianc\n",
      "6 come\n",
      "7 result\n",
      "8 it\n",
      "9 fall\n",
      "10 model\n",
      "11 fulli\n",
      "12 boy \n",
      "13 industri\n",
      "14 languag\n",
      "15 scenario\n",
      "16 lie\n",
      "17 tackl\n",
      "18 diagram\n",
      "19 when\n",
      "20 demograph\n",
      "21 multi output\n",
      "22 comparison\n",
      "23 hand\n",
      "24 e g \n",
      "25 repres\n",
      "26 product\n",
      "27 rule\n",
      "28 design\n",
      "29 stabil\n",
      "30 greater\n",
      "31 wherea\n",
      "32 import\n",
      "33 respons\n",
      "34 kind\n",
      "35 law\n",
      "36 e g\n",
      "37 problem\n",
      "38 better\n",
      "39 call\n",
      "40 expans\n",
      "41 segreg\n",
      "42 opportun\n",
      "43 eas\n",
      "44 chanc\n",
      "45 space\n",
      "46 almost\n",
      "47 identifi\n",
      "48 pay\n",
      "49 flowchart lik\n",
      "50 read\n",
      "51 with\n",
      "52 forest\n",
      "53 in\n",
      "54 degre\n",
      "55 check\n",
      "56 sampl\n",
      "57 two\n",
      "58 screen\n",
      "59 correspond\n",
      "60 leav\n",
      "61 speci\n",
      "62 method\n",
      "63 factor\n",
      "64 repeat\n",
      "65 strategi\n",
      "66 effort\n",
      "67 easi\n",
      "68 exampl\n",
      "69 while\n",
      "70 independ\n",
      "71 tri\n",
      "72 affect\n",
      "73 return\n",
      "74 regress\n",
      "75 way\n",
      "76 balanc\n",
      "77 overfit\n",
      "78 poor\n",
      "79 randomli\n",
      "80 valu\n",
      "81 fastest\n",
      "82 path\n",
      "83 leaf\n",
      "84 mani\n",
      "85 you\n",
      "86 step\n",
      "87 renew\n",
      "88 might\n",
      "89 contain\n",
      "90 case\n",
      "91 programmat\n",
      "92 wirth\n",
      "93 consid\n",
      "94 littl\n",
      "95 tell\n",
      "96 power\n",
      "97 three\n",
      "98 practic\n",
      "99 make\n",
      "100 variabl\n",
      "101 control\n",
      "102 over complex\n",
      "103 child\n",
      "104 mostli\n",
      "105 to\n",
      "106 becaus\n",
      "107 differenti\n",
      "108 upsid\n",
      "109 top down\n",
      "110 top\n",
      "111 highli\n",
      "112 mode\n",
      "113 event\n",
      "114 map\n",
      "115 user\n",
      "116 whether\n",
      "117 techniqu\n",
      "118 pharmaceut\n",
      "119 constraint\n",
      "120 pressur\n",
      "121 each\n",
      "122 understand\n",
      "123 made\n",
      "124 one\n",
      "125 yes \n",
      "126 accuraci\n",
      "127 select\n",
      "128 borrow\n",
      "129 quit\n",
      "130 predictor\n",
      "131 distribut\n",
      "132 pre defin\n",
      "133 difficulti\n",
      "134 clean\n",
      "135 therefor\n",
      "136 natur\n",
      "137 termin\n",
      "138 gain\n",
      "139 non linear\n",
      "140 also\n",
      "141 goal\n",
      "142 sub tre\n",
      "143 a\n",
      "144 paramet\n",
      "145 label\n",
      "146 energi\n",
      "147 dataset\n",
      "148 for\n",
      "149 data\n",
      "150 variou\n",
      "151 complet\n",
      "152 statement\n",
      "153 well\n",
      "154 financi\n",
      "155 coin\n",
      "156 categori\n",
      "157 measur\n",
      "158 but\n",
      "159 priorit\n",
      "160 lose\n",
      "161 given\n",
      "162 tool\n",
      "163 scienc\n",
      "164 default\n",
      "165 order\n",
      "166 success\n",
      "167 stop\n",
      "168 predict\n",
      "169 calcul\n",
      "170 pain\n",
      "171 prior\n",
      "172 commonli\n",
      "173 classifi\n",
      "174 among\n",
      "175 cart\n",
      "176 prefer\n",
      "177 target\n",
      "178 futur\n",
      "179 deliber\n",
      "180 boost\n",
      "181 signific\n",
      "182   \n",
      "183 record\n",
      "184 cost\n",
      "185 fair\n",
      "186 non parametr\n",
      "187 get\n",
      "188 fit\n",
      "189 help\n",
      "190 split\n",
      "191 advantag\n",
      "192 hypothesi\n",
      "193 patient\n",
      "194 buyer\n",
      "195 use\n",
      "196 hundr\n",
      "197 requir\n",
      "198 whole\n",
      "199 complex\n",
      "200 splitter\n",
      "201 defin\n",
      "202 program\n",
      "203 gradient\n",
      "204 algorithm\n",
      "205 sub nod\n",
      "206 niklau\n",
      "207 divid\n",
      "208 outcom\n",
      "209 decis\n",
      "210 oper\n",
      "211 occup\n",
      "212 possibl\n",
      "213 els\n",
      "214 decision \n",
      "215 insur\n",
      "216 background\n",
      "217 process\n",
      "218 now\n",
      "219 if\n",
      "220 systemat\n",
      "221 low\n",
      "222 empow\n",
      "223 mine\n",
      "224 say\n",
      "225 at\n",
      "226 healthcar\n",
      "227 drawn\n",
      "228 advertis\n",
      "229 play\n",
      "230 height\n",
      "231 featur\n",
      "232 build\n",
      "233 test\n",
      "234 determin\n",
      "235 girl\n",
      "236 per\n",
      "237 like\n",
      "238 ft\n",
      "239 condit\n",
      "240 gender\n",
      "241 distinct\n",
      "242 anim\n",
      "243 relat\n",
      "244 relationship\n",
      "245 root\n",
      "246 classif\n",
      "247 x\n",
      "248 high\n",
      "249 consequ\n",
      "250 want\n",
      "251 common\n",
      "252 simplic\n",
      "253 no\n",
      "254 snapshot\n",
      "255 budget\n",
      "256 we\n",
      "257 unseen\n",
      "258 thi\n",
      "259 educ\n",
      "260 support\n",
      "261 unlik\n",
      "262 util\n",
      "263 statist\n",
      "264 reach\n",
      "265 thu\n",
      "266 rel\n",
      "267 taken\n",
      "268 not\n",
      "269 supervis\n",
      "270 effect\n",
      "271 work\n",
      "272 suit\n",
      "273 class\n",
      "274 how\n",
      "275 popularli\n",
      "276 output\n",
      "277 becom\n",
      "278 learn\n",
      "279 premium\n",
      "280 student\n",
      "281 broad\n",
      "282 implicitli\n",
      "283 inform\n",
      "284 bring\n",
      "285 start\n",
      "286 mitig\n",
      "287 enabl\n",
      "288 guarante\n",
      "289 base\n",
      "290 includ\n",
      "291 obtain\n",
      "292 gener\n",
      "293 represent\n",
      "294 resourc\n",
      "295 creat\n",
      "296 compani\n",
      "297 could\n",
      "298 attribut\n",
      "299 give\n",
      "300 current\n",
      "301 busi\n",
      "302 bias\n",
      "303 bottom\n",
      "304 treatment\n",
      "305 civil\n",
      "306 singl\n",
      "307 opposit\n",
      "308 time\n",
      "309 avail\n",
      "310 mean\n",
      "311 homogen\n",
      "312 adapt\n",
      "313 bag\n",
      "314 final\n",
      "315 on\n",
      "316 as\n",
      "317 intern\n",
      "318 cricket\n",
      "319 emerg\n",
      "320 disadvantag\n",
      "321 see\n",
      "322 continu\n",
      "323 basi\n",
      "324 primari\n",
      "325 easili\n",
      "326 observ\n",
      "327 grown\n",
      "328 knowledg\n",
      "329 compar\n",
      "330 subset\n",
      "331 evalu\n",
      "332 variat\n",
      "333 popul\n",
      "334 machin\n",
      "335 both\n",
      "336 they\n",
      "337 set\n",
      "338 next\n",
      "339 prepar\n",
      "340 popular\n",
      "341 number\n",
      "342 disciplin\n",
      "343 brand\n",
      "344 known\n",
      "345 age\n",
      "346 look\n",
      "347 point\n",
      "348 room\n",
      "349 interpret\n",
      "350 ix \n",
      "351 hyper paramet\n",
      "352 tree lik\n",
      "353 comput\n",
      "354 learner\n",
      "355 construct\n",
      "356 rang\n",
      "357 input\n",
      "358 handl\n",
      "359 branch\n",
      "360 perform\n",
      "361 some\n",
      "362 null\n",
      "363 abl\n",
      "364 find\n",
      "365 begin\n",
      "366 term\n",
      "367 let\n",
      "368 place\n",
      "369 intuit\n",
      "370 locat\n",
      "371 heterogen\n",
      "372 need\n",
      "373 binari\n",
      "374 i e\n",
      "375 graphic\n",
      "376 new\n",
      "377 structur\n",
      "378 sub popul\n",
      "379 explor\n",
      "380 less\n",
      "381 unstabl\n",
      "382 sever\n",
      "383 here\n",
      "384 stage\n",
      "385 best\n",
      "386 assumpt\n",
      "387 display\n",
      "388 flip\n",
      "389 depend\n",
      "390 head\n",
      "391 engin\n",
      "392 know\n",
      "393 node\n",
      "394 jump\n",
      "395 ye\n",
      "396 region\n",
      "397 research\n",
      "398 lower\n",
      "399 refer\n",
      "400 discret\n",
      "401 similar\n",
      "402 limit\n",
      "403 graph\n",
      "404 vs\n",
      "405 entir\n",
      "406 tail\n",
      "407 peopl\n",
      "408 lead\n",
      "409 incom\n",
      "410 recommend\n",
      "411 domin\n",
      "412 blood\n",
      "413 sale\n",
      "414 differ\n",
      "415 categor\n",
      "416 sub\n",
      "417 over\n",
      "418 detail\n",
      "419 type\n",
      "420 the\n",
      "421 linear\n",
      "422 recurs\n",
      "423 tree\n",
      "424 parent\n",
      "425 numer\n",
      "426 specif\n",
      "427 non overlap\n",
      "428 prune\n",
      "429 period\n",
      "430 histor\n",
      "431 replac\n",
      "432 optim\n",
      "433 custom\n",
      "434 global\n",
      "435 small\n",
      "436 criteria\n",
      "437 can\n",
      "438 solut\n",
      "439 non analyt\n",
      "440 plan\n",
      "441 miss\n",
      "442 random\n",
      "443 leaf \n",
      "444 approach\n",
      "445 done\n",
      "446 outlier\n",
      "447 care\n",
      "448 leisur\n",
      "449 solv\n",
      "450 tune\n",
      "451 multipl\n",
      "452 typic\n",
      "453 even\n",
      "454 likelihood\n",
      "455 follow\n",
      "456 influenc\n",
      "457     \n",
      "458 greedi\n",
      "459 applic\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(Distinct_Words)):\n",
    "    print (i,Distinct_Words[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_Count_matrix=np.empty(shape=(len(line),len(Distinct_Words)))\n",
    "word_Count_matrix.fill(0)\n",
    "\n",
    "for i in range(len(line)):\n",
    "    for j in range(len(line[i])):\n",
    "        for x in range(len(Distinct_Words)):\n",
    "            if (Distinct_Words[x]==line[i][j]):\n",
    "                word_Count_matrix[i][x] = word_Count_matrix[i][x] +1\n",
    "                continue\n",
    "                \n",
    "word_Count_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM_25_weight=np.empty(shape=(len(line),len(Distinct_Words)))\n",
    "BM_25_weight.fill(0)\n",
    "    \n",
    "    \n",
    "avg_length=np.mean(word_Count_matrix.sum(axis=1))\n",
    "    \n",
    "length_size=np.array(1.5*word_Count_matrix.sum(axis=1)/avg_length)\n",
    "    \n",
    "isf=np.array(np.log(len(line)/np.count_nonzero(word_Count_matrix,axis=0)))\n",
    "\n",
    "denominator=np.empty(shape=(len(line),len(Distinct_Words)))\n",
    "for i in range(len(line)):\n",
    "    denominator[i,:]=(word_Count_matrix[i,:]+length_size[i]+0.5)\n",
    "    \n",
    "BM_25_weight=(word_Count_matrix*isf)/(denominator)\n",
    "BM_25_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_weight=np.empty(shape=(len(line),len(Distinct_Words)))\n",
    "tfidf_weight.fill(0)\n",
    "\n",
    "tfidf_weight = word_Count_matrix*isf\n",
    "tfidf_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_binary_matrix=np.empty(shape=(len(line),len(Distinct_Words)))\n",
    "word_binary_matrix.fill(0)\n",
    "\n",
    "for i in range(len(line)):\n",
    "    for j in range(len(line[i])):\n",
    "        for x in range(len(Distinct_Words)):\n",
    "            if (Distinct_Words[x]==line[i][j]):\n",
    "                word_binary_matrix[i][x] = 1\n",
    "                continue\n",
    "word_binary_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.09698036 0.22188399 ... 0.14395208 0.19859701 0.16649267]\n",
      " [0.09698036 1.         0.15848007 ... 0.11287815 0.16630175 0.16424629]\n",
      " [0.22188399 0.15848007 1.         ... 0.20945314 0.26859172 0.22354598]\n",
      " ...\n",
      " [0.14395208 0.11287815 0.20945314 ... 1.         0.21655412 0.17434256]\n",
      " [0.19859701 0.16630175 0.26859172 ... 0.21655412 1.         0.31453428]\n",
      " [0.16649267 0.16424629 0.22354598 ... 0.17434256 0.31453428 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "euclidean_bm25 =euclidean_distances(BM_25_weight)\n",
    "euclidean_bm25 = (1-(euclidean_bm25/np.max(euclidean_bm25)))\n",
    "print(euclidean_bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine with BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.07716111, ..., 0.00185534, 0.        ,\n",
       "        0.02179388],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.08534227],\n",
       "       [0.07716111, 0.        , 1.        , ..., 0.00309712, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.00185534, 0.        , 0.00309712, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.20468351],\n",
       "       [0.02179388, 0.08534227, 0.        , ..., 0.        , 0.20468351,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_bm25=np.empty(shape=(len(line),len(line)))\n",
    "\n",
    "for i in range(len(line)):\n",
    "    for j in range(len(line)):\n",
    "        dot_product = np.dot(BM_25_weight[i], BM_25_weight[j])\n",
    "        norm_i = np.linalg.norm(BM_25_weight[i])\n",
    "        norm_j = np.linalg.norm(BM_25_weight[j])\n",
    "        cosine_bm25[i, j] = dot_product/(norm_i*norm_j)\n",
    "cosine_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.50875844 0.54453759 ... 0.49966453 0.56724457 0.54941814]\n",
      " [0.50875844 1.         0.63325454 ... 0.59779666 0.68650326 0.67134303]\n",
      " [0.54453759 0.63325454 1.         ... 0.62116027 0.71634312 0.68411107]\n",
      " ...\n",
      " [0.49966453 0.59779666 0.62116027 ... 1.         0.67178282 0.6435577 ]\n",
      " [0.56724457 0.68650326 0.71634312 ... 0.67178282 1.         0.77379396]\n",
      " [0.54941814 0.67134303 0.68411107 ... 0.6435577  0.77379396 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "euclidean_tfidf =euclidean_distances(tfidf_weight)\n",
    "euclidean_tfidf = (1-(euclidean_tfidf/np.max(euclidean_tfidf)))\n",
    "print(euclidean_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.08177021, ..., 0.00180392, 0.        ,\n",
       "        0.02162267],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.08534227],\n",
       "       [0.08177021, 0.        , 1.        , ..., 0.00303513, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.00180392, 0.        , 0.00303513, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.20468351],\n",
       "       [0.02162267, 0.08534227, 0.        , ..., 0.        , 0.20468351,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_tfidf=np.empty(shape=(len(line),len(line)))\n",
    "\n",
    "for i in range(len(line)):\n",
    "    for j in range(len(line)):\n",
    "        dot_product = np.dot(tfidf_weight[i], tfidf_weight[j])\n",
    "        norm_i = np.linalg.norm(tfidf_weight[i])\n",
    "        norm_j = np.linalg.norm(tfidf_weight[j])\n",
    "        cosine_tfidf[i, j] = dot_product/(norm_i*norm_j)\n",
    "cosine_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean with count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.52480904 0.58263499 ... 0.50486235 0.56745315 0.56005865]\n",
      " [0.52480904 1.         0.6407894  ... 0.61478954 0.72175666 0.71039515]\n",
      " [0.58263499 0.6407894  1.         ... 0.61478954 0.69946285 0.66882419]\n",
      " ...\n",
      " [0.50486235 0.61478954 0.61478954 ... 1.         0.66882419 0.6407894 ]\n",
      " [0.56745315 0.72175666 0.69946285 ... 0.66882419 1.         0.78748814]\n",
      " [0.56005865 0.71039515 0.66882419 ... 0.6407894  0.78748814 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "euclidean_count =euclidean_distances(word_Count_matrix)\n",
    "euclidean_count = (1-(euclidean_count/np.max(euclidean_count)))\n",
    "print(euclidean_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine with count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.2956562 , ..., 0.05241424, 0.        ,\n",
       "        0.08006408],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.13608276],\n",
       "       [0.2956562 , 0.        , 1.        , ..., 0.0805823 , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.05241424, 0.        , 0.0805823 , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.23570226],\n",
       "       [0.08006408, 0.13608276, 0.        , ..., 0.        , 0.23570226,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_count=np.empty(shape=(len(line),len(line)))\n",
    "\n",
    "for i in range(len(line)):\n",
    "    for j in range(len(line)):\n",
    "        dot_product = np.dot(word_Count_matrix[i], word_Count_matrix[j])\n",
    "        norm_i = np.linalg.norm(word_Count_matrix[i])\n",
    "        norm_j = np.linalg.norm(word_Count_matrix[j])\n",
    "        cosine_count[i, j] = dot_product/(norm_i*norm_j)\n",
    "cosine_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean with binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.39595955 0.44249591 ... 0.39595955 0.4672864  0.45475024]\n",
      " [0.39595955 1.         0.48012476 ... 0.48012476 0.59730637 0.58086318]\n",
      " [0.44249591 0.48012476 1.         ... 0.48012476 0.56504116 0.52069871]\n",
      " ...\n",
      " [0.39595955 0.48012476 0.48012476 ... 1.         0.56504116 0.52069871]\n",
      " [0.4672864  0.59730637 0.56504116 ... 0.56504116 1.         0.69243766]\n",
      " [0.45475024 0.58086318 0.52069871 ... 0.52069871 0.69243766 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "euclidean_binary =euclidean_distances(word_binary_matrix)\n",
    "euclidean_binary = (1-(euclidean_binary/np.max(euclidean_binary)))\n",
    "print(euclidean_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine with binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.21320072, ..., 0.07106691, 0.        ,\n",
       "        0.09622504],\n",
       "       [0.        , 1.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.13608276],\n",
       "       [0.21320072, 0.        , 1.        , ..., 0.09090909, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.07106691, 0.        , 0.09090909, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.23570226],\n",
       "       [0.09622504, 0.13608276, 0.        , ..., 0.        , 0.23570226,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_binary=np.empty(shape=(len(line),len(line)))\n",
    "\n",
    "for i in range(len(line)):\n",
    "    for j in range(len(line)):\n",
    "        dot_product = np.dot(word_binary_matrix[i], word_binary_matrix[j])\n",
    "        norm_i = np.linalg.norm(word_binary_matrix[i])\n",
    "        norm_j = np.linalg.norm(word_binary_matrix[j])\n",
    "        cosine_binary[i, j] = dot_product/(norm_i*norm_j)\n",
    "cosine_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard with binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_jaccard(X):\n",
    "    \"\"\"Computes the Jaccard distance between the rows of `X`.\n",
    "    \"\"\"\n",
    "    X = X.astype(bool).astype(int)\n",
    "\n",
    "    intrsct = X.dot(X.T)\n",
    "    row_sums = intrsct.diagonal()\n",
    "    unions = row_sums[:,None] + row_sums - intrsct\n",
    "    dist = intrsct / unions\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.11538462 ... 0.03571429 0.         0.04347826]\n",
      " [0.         1.         0.         ... 0.         0.         0.07142857]\n",
      " [0.11538462 0.         1.         ... 0.04761905 0.         0.        ]\n",
      " ...\n",
      " [0.03571429 0.         0.04761905 ... 1.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         1.         0.125     ]\n",
      " [0.04347826 0.07142857 0.         ... 0.         0.125      1.        ]]\n"
     ]
    }
   ],
   "source": [
    "jaccard_binary = pairwise_jaccard(word_binary_matrix)\n",
    "print(jaccard_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_func(similarity_matrix):\n",
    "    summary=\"\"\n",
    "    n_clusters = int(np.ceil(len(similarity_matrix)**0.5))\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans = kmeans.fit(similarity_matrix)\n",
    "    avg = []\n",
    "    closest = []\n",
    "    for j in range(n_clusters):\n",
    "        idx = np.where(kmeans.labels_ == j)[0]\n",
    "        avg.append(np.mean(idx))\n",
    "    closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_,similarity_matrix)\n",
    "    ordering = sorted(range(n_clusters), key=lambda k: avg[k])\n",
    "    summary = ' '.join([sentences[closest[idx]][0] for idx in ordering])\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## euclidean BM25 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 out of these 30 play cricket in leisure time. Advantages of Decision Tree:\n",
      "Easy to Understand: Decision tree output is very easy to understand even for people from non-analytical background. To identify the variable and the split, decision tree uses various algorithms. Repeat step 1 and step 2 on each subset until you find leaf nodes in all the branches of the tree. :- Let’s say we have a problem to predict whether a customer will pay his renewal premium with an insurance company (yes/ no). Decision Tree algorithms are referred to as CART (Classification and Regression Trees). It can be of two types:\n",
      "Categorical Variable Decision Tree: Decision Tree which has categorical target variable then it called as categorical variable decision tree. Less data cleaning required: It requires less data cleaning compared to some other modeling techniques. Over fitting is one of the most practical difficulty for decision tree models. This means that decision trees have no assumptions about the space distribution and the classifier structure. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mean value.\n"
     ]
    }
   ],
   "source": [
    "euclidean_BM25_summary=summary_func(euclidean_bm25)\n",
    "print(euclidean_BM25_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine BM25 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this problem, we need to segregate students who play cricket in their leisure time based on highly significant input variable among all three. Splitting: It is a process of dividing a node into two or more sub-nodes. E.g. We compare the values of the root attribute with record’s attribute. Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. For e.g., we are working on a problem where we have information available in hundreds of variables, there decision tree will help to identify most significant variable. If the values are continuous then they are discretized prior to building the model. This means that decision trees are typically drawn upside down such that leaves are the bottom & roots are the tops. It is known as ‘greedy’ because, the algorithm cares (looks for best variable available) about only the current split, and not about future splits which will lead to a better tree. In case of Classification Tree, the value (class) obtained by terminal node in the training data is the mode of observations falling in that region.\n"
     ]
    }
   ],
   "source": [
    "cosine_BM25_summary=summary_func(cosine_bm25)\n",
    "print(cosine_BM25_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## euclidean tfidf summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The possible solutions to a given problem emerge as the leaves of a tree, each node representing a point of deliberation and decision.”\n",
      "- Niklaus Wirth (1934 — ), Programming language designer\n",
      "Methods like decision trees, random forest, gradient boosting are being popularly used in all kinds of data science problems. Parent and Child Node: A node, which is divided into sub-nodes is called parent node of sub-nodes whereas sub-nodes are the child of parent node. Example applications include:\n",
      "· Evaluation of brand expansion opportunities for a business using historical sales data\n",
      "· Determination of likely buyers of a product using demographic data to enable targeting of limited advertisement budget\n",
      "· Prediction of likelihood of default for applicant borrowers using predictive models generated from historical data\n",
      "· Help with prioritization of emergency room patient treatment using a predictive model based on factors such as age, blood pressure, gender, location and severity of pain, and other measurements\n",
      "· Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal. Because of their simplicity, tree diagrams have been used in a broad range of industries and disciplines including civil planning, energy, financial, engineering, healthcare, pharmaceutical, education, law, and business. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). Each internal node of the tree corresponds to an attribute, and each leaf node corresponds to a class label. Now, as we know this is an important variable, then we can build a decision tree to predict customer income based on occupation, product and various other variables. It can also be used in data exploration stage. This is called variance, which needs to be lowered by methods like bagging and boosting. Decision trees implicitly perform variable screening or feature selection. For e.g.\n"
     ]
    }
   ],
   "source": [
    "euclidean_tfidf_summary=summary_func(euclidean_tfidf)\n",
    "print(euclidean_tfidf_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine tfidf summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Node: When a sub-node splits into further sub-nodes, then it is called decision node. Decision tree identifies the most significant variable and its value that gives best homogeneous sets of population. “The possible solutions to a given problem emerge as the leaves of a tree, each node representing a point of deliberation and decision.”\n",
      "- Niklaus Wirth (1934 — ), Programming language designer\n",
      "Methods like decision trees, random forest, gradient boosting are being popularly used in all kinds of data science problems. Types of Decision Trees\n",
      "Types of decision tree is based on the type of target variable we have. E.g. Not fit for continuous variables: While working with continuous numerical variables, decision tree loses information, when it categorizes variables in different categories. We compare the values of the root attribute with record’s attribute. The primary differences and similarities between Classification and Regression Trees are:\n",
      "Regression trees are used when dependent variable is continuous. Pruning is one of the technique used tackle overfitting. Decision trees require relatively little effort from users for data preparation. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mode value.\n"
     ]
    }
   ],
   "source": [
    "cosine_tfidf_summary=summary_func(cosine_tfidf)\n",
    "print(cosine_tfidf_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## euclidean count summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent and Child Node: A node, which is divided into sub-nodes is called parent node of sub-nodes whereas sub-nodes are the child of parent node. Example applications include:\n",
      "· Evaluation of brand expansion opportunities for a business using historical sales data\n",
      "· Determination of likely buyers of a product using demographic data to enable targeting of limited advertisement budget\n",
      "· Prediction of likelihood of default for applicant borrowers using predictive models generated from historical data\n",
      "· Help with prioritization of emergency room patient treatment using a predictive model based on factors such as age, blood pressure, gender, location and severity of pain, and other measurements\n",
      "· Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal. Each internal node of the tree corresponds to an attribute, and each leaf node corresponds to a class label. It can be of two types:\n",
      "Categorical Variable Decision Tree: Decision Tree which has categorical target variable then it called as categorical variable decision tree. :- Let’s say we have a problem to predict whether a customer will pay his renewal premium with an insurance company (yes/ no). Advantages of Decision Tree:\n",
      "Easy to Understand: Decision tree output is very easy to understand even for people from non-analytical background. It does not require any statistical knowledge to read and interpret them. Decision tree learners create biased trees if some classes dominate. Unlike linear models, they map non-linear relationships quite well. YES or NO. Applications for Decision Tree - Decision trees have a natural “if … then … else …” construction that makes it fit easily into a programmatic structure.\n"
     ]
    }
   ],
   "source": [
    "euclidean_count_summary=summary_func(euclidean_count)\n",
    "print(euclidean_count_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine count summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent and Child Node: A node, which is divided into sub-nodes is called parent node of sub-nodes whereas sub-nodes are the child of parent node. In this problem, we need to segregate students who play cricket in their leisure time based on highly significant input variable among all three. A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. Records are distributed recursively on the basis of attribute values. With the help of decision trees, we can create new variables / features that has better power to predict target variable. Decision tree learners create biased trees if some classes dominate. YES or NO. E.g. Both the trees follow a top-down greedy approach known as recursive binary splitting. It can also be used in data exploration stage. In case of Regression Tree, the value obtained by terminal nodes in the training data is the mean response of observation falling in that region.\n"
     ]
    }
   ],
   "source": [
    "cosine_count_summary=summary_func(cosine_count)\n",
    "print(cosine_count_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## euclidean binary summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A decision tree is a decision support tool that uses a tree-like graph or model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. “The possible solutions to a given problem emerge as the leaves of a tree, each node representing a point of deliberation and decision.”\n",
      "- Niklaus Wirth (1934 — ), Programming language designer\n",
      "Methods like decision trees, random forest, gradient boosting are being popularly used in all kinds of data science problems. Example applications include:\n",
      "· Evaluation of brand expansion opportunities for a business using historical sales data\n",
      "· Determination of likely buyers of a product using demographic data to enable targeting of limited advertisement budget\n",
      "· Prediction of likelihood of default for applicant borrowers using predictive models generated from historical data\n",
      "· Help with prioritization of emergency room patient treatment using a predictive model based on factors such as age, blood pressure, gender, location and severity of pain, and other measurements\n",
      "· Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal. Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. In this technique, we split the population or sample into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables. Can also handle multi-output problems. Greedy algorithms cannot guarantee to return the globally optimal decision tree. Its graphical representation is very intuitive and users can easily relate their hypothesis. In case of Classification Tree, the value (class) obtained by terminal node in the training data is the mode of observations falling in that region. YES or NO. Advantages of Decision Tree:\n",
      "Easy to Understand: Decision tree output is very easy to understand even for people from non-analytical background.\n"
     ]
    }
   ],
   "source": [
    "euclidean_binary_summary=summary_func(euclidean_binary)\n",
    "print(euclidean_binary_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine binary summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaf/ Terminal Node: Nodes do not split is called Leaf or Terminal node. :- In above scenario of student problem, where the target variable was “Student will play cricket or not” i.e. Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. Its graphical representation is very intuitive and users can easily relate their hypothesis. Each internal node of the tree corresponds to an attribute, and each leaf node corresponds to a class label. Decision trees implicitly perform variable screening or feature selection. Decision tree learners create biased trees if some classes dominate. E.g. Records are distributed recursively on the basis of attribute values. Both the trees follow a top-down greedy approach known as recursive binary splitting. This bring ‘pruning’.\n"
     ]
    }
   ],
   "source": [
    "cosine_binary_summary=summary_func(cosine_binary)\n",
    "print(cosine_binary_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jaccard binary summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each internal node of the tree corresponds to an attribute, and each leaf node corresponds to a class label. 15 out of these 30 play cricket in leisure time. Splitting: It is a process of dividing a node into two or more sub-nodes. Decision Tree algorithms are referred to as CART (Classification and Regression Trees). Records are distributed recursively on the basis of attribute values. Data type is not a constraint: It can handle both numerical and categorical variables. Types of Decision Trees\n",
      "Types of decision tree is based on the type of target variable we have. This problem gets solved by setting constraints on model parameters and pruning. E.g. Applications for Decision Tree - Decision trees have a natural “if … then … else …” construction that makes it fit easily into a programmatic structure. Thus, if an unseen data observation falls in that region, we’ll make its prediction with mean value.\n"
     ]
    }
   ],
   "source": [
    "jaccard_binary_summary=summary_func(jaccard_binary)\n",
    "print(jaccard_binary_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=open(file_name[0]+\"_summary.\"+file_name[1],\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.write(\"euclidean BM25 summary\\n\\n\"+euclidean_BM25_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n cosine BM25 summary \\n\\n\"+cosine_BM25_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n euclidean tfidf summary \\n\\n\"+euclidean_tfidf_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n cosine tfidf summary \\n\\n\"+cosine_tfidf_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n euclidean count summary \\n\\n\"+euclidean_count_summary +\"\\n\\n\\n\\n\\n\\n\\n\\n cosine count summary \\n\\n\"+cosine_count_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n euclidean binary summary \\n\\n\"+euclidean_binary_summary +\"\\n\\n\\n\\n\\n\\n\\n\\n cosine binary summary \\n\\n\"+cosine_binary_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n jaccard binary summary \\n\\n\"+jaccard_binary_summary+\"\\n\\n\\n\\n\\n\\n\\n\\n\"+data[0])\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
